[(109条消息) VMware安装win10系统_渣渣苏的博客-CSDN博客](https://blog.csdn.net/su2231595742/article/details/123915481)

[(134条消息) VMware虚拟机部署k8s集群_异乡人hl的博客-CSDN博客_vmware部署k8s](https://blog.csdn.net/qq_41860461/article/details/122418639)

[(134条消息) Hadoop入门(一)——CentOS7下载+VM上安装（手动分区）图文步骤详解(2021)_哨哨可不苕的博客-CSDN博客](https://blog.csdn.net/m0_46413065/article/details/114667174)

# VMware网络配置参考：

[尚硅谷大数据Hadoop教程（Hadoop 3.x安装搭建到集群调优）_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Qp4y1n7EN?p=20)

## 2. 配置IP地址

1. **VMware ip**

   1. ![image-20220608151239251](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608151239251.png)
   2. ![image-20220608151331066](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608151331066.png)
   3. ![image-20220608151435062](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608151435062.png)
   4. ![image-20220608151629872](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608151629872.png)
   5. ![image-20220608151701212](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608151701212.png)

2. **win10 ip**

   1. ![image-20220608151834210](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608151834210.png)

3. **虚拟机系统 ip**

   1. 查看默认使用的网卡

      ![image-20220608163223347](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608163223347.png)

      使用的是ens33

   2. 修改ip地址

      1. vi /etc/sysconfig/network-scripts/ifcfg-ens33

         ![image-20220608152411520](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608152411520.png)

      2. 配置主机名称 vi /etc/hostname

         1. ![image-20220608152550381](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608152550381.png)

      3. 主机名称映射

         1. ip地址：192.168.10.100  

            1. 之后写代码的时候，任何需要使用ip地址的地方都要用192.168.10.100，如果有一天ip地址发生变化，则系统中全部的都要修改
            2. 使用k8s-node01代替 192.168.10.100 程序中直接使用k8s-node01

         2. vi /etc/hosts

            ![image-20220608152926586](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608152926586.png)

         

4. 重启系统 reboot

   1. ip addr查看ip地址

      ![image-20220608153231867](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608153231867.png)

   2. ping www.baidu.com 查看是否配置成功

      ![image-20220608153323748](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220608153323748.png)

## 3. 配置K8s

[Java项目《谷粒商城》Java架构师 | 微服务 | 大型电商项目_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1np4y1C7Yf?p=346&spm_id_from=pageDriver)

### 1. 安装docker

[Linux开发环境配置（Docker） · 语雀 (yuque.com)](https://www.yuque.com/zhangshuaiyin/guli-mall/lb4zw1)

#### 问题：

#### 1. yum - install yum-utils 安装失败

![image-20220609094031049](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609094031049.png)

[(134条消息) sudo yum install -y yum-utils 时出错_i小喇叭的博客-CSDN博客_yum-utils安装报错](https://blog.csdn.net/weixin_42230797/article/details/122909935)

![image-20220609093958524](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609093958524.png)

#### 2. This system is not registered with an entitlement server

![image-20220609100623026](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609100623026.png)

###  2. 安装kubeadm，kubelet和kubectl

```
yum list|grep kube
```

安装

```shell
yum install -y kubelet-1.17.3 kubeadm-1.17.3 kubectl-1.17.3
```

开机启动

```shell
systemctl enable kubelet # 开机启动
systemctl start kubelet # 启动kubelet
或者：systemctl enable kubelet && systemctl start kubelet # 同时执行两条命令
```

查看kubelet的状态：

```
systemctl status kubelet
```

![image-20220609103050467](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609103050467.png)

原因：未配置号。

查看kubelet版本：

```shell
[root@k8s-node2 ~]# kubelet --version
Kubernetes v1.17.3
```

### 3. 初始化master节点

#### 1. master需要用的docker镜像

**shell脚本**

```shell
#!/bin/bash

images=(
	kube-apiserver:v1.17.3
    kube-proxy:v1.17.3
	kube-controller-manager:v1.17.3
	kube-scheduler:v1.17.3
	coredns:1.6.5
	etcd:3.4.3-0
    pause:3.1
)

for imageName in ${images[@]} ; do
    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
#   docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName  k8s.gcr.io/$imageName
done
```

![image-20220609105059036](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609105059036.png)

rwx：可读，可写，可执行![image-20220609105132765](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609105132765.png)

运行shell脚本：`./master_images.sh `

#### 2. 初始化命令

1. **通过kubeadm初始化k8s**

```shell
执行以下命令：
kubeadm init --apiserver-advertise-address=192.168.10.100 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers --kubernetes-version   v1.17.3 --service-cidr=10.96.0.0/16  --pod-network-cidr=10.244.0.0/16
```

![image-20220609110832482](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609110832482.png)

相关命令解读：[kubeadm init | Kubernetes](https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/)

![image-20220609104457209](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609104457209.png)

pod是k8s的最小部署单元，一个机器有许多pod，pod与pod之间可能有联系，因此创建了一个pod的网络。

几个pod可以组成一个service，可以进行负载均衡操作，service与service之间也有通信，因此需要设置service网络。

![image-20220609113830781](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609113830781.png)

2. **用身份运行**

```shell
To start using your cluster, you need to run the following as a regular user:
要开始使用集群，您需要以常规用户的身份运行以下命令：
mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

3. **加入网络：**

可用的网络：[Installing Addons | Kubernetes](https://kubernetes.io/docs/concepts/cluster-administration/addons/)

使用![image-20220609111749887](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609111749887.png)

安装Pod网络插件（CNI）

```shell
kubectl apply -f \   # 应用flannel网络
https://raw.githubusercontent.com/coreos/flanne/master/Documentation/kube-flannel.yml

kubectl delete -f .........  #删除flannel网络
```

如果 下载kube-flanne.yml比较慢，可以直接使用下载好的文件

```she
# 运行以下命令
kubectl apply -f kube-flannel.yml
```

![image-20220609112808667](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609112808667.png)

网络运行完，暂时还不能使用

kube-flannel.yml

```yml
---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: psp.flannel.unprivileged
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default
    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default
    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
spec:
  privileged: false
  volumes:
    - configMap
    - secret
    - emptyDir
    - hostPath
  allowedHostPaths:
    - pathPrefix: "/etc/cni/net.d"
    - pathPrefix: "/etc/kube-flannel"
    - pathPrefix: "/run/flannel"
  readOnlyRootFilesystem: false
  # Users and groups
  runAsUser:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  # Privilege Escalation
  allowPrivilegeEscalation: false
  defaultAllowPrivilegeEscalation: false
  # Capabilities
  allowedCapabilities: ['NET_ADMIN']
  defaultAddCapabilities: []
  requiredDropCapabilities: []
  # Host namespaces
  hostPID: false
  hostIPC: false
  hostNetwork: true
  hostPorts:
  - min: 0
    max: 65535
  # SELinux
  seLinux:
    # SELinux is unused in CaaSP
    rule: 'RunAsAny'
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
rules:
  - apiGroups: ['extensions']
    resources: ['podsecuritypolicies']
    verbs: ['use']
    resourceNames: ['psp.flannel.unprivileged']
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - nodes/status
    verbs:
      - patch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flannel
  namespace: kube-system
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: kube-flannel-cfg
  namespace: kube-system
  labels:
    tier: node
    app: flannel
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-amd64
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - amd64
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-amd64
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-amd64
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
            add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-arm64
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - arm64
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-arm64
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-arm64
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-arm
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - arm
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-arm
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-arm
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-ppc64le
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - ppc64le
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-ppc64le
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-ppc64le
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-s390x
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - s390x
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-s390x
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-s390x
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
```

4. 获取pod

pod类似docker中的容器，pod有名称空间，获取pod时，需要指定获取某个空间的pod

```shell
[root@k8s-master k8s]# kubectl get pods
No resources found in default namespace.
```

查看名称空间：

```shell
kubectl get ns
```

![image-20220609113258023](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609113258023.png)

查看所有名称空间的pods

```shell
kubectl get pods --all-namespaces
```

![image-20220609113342797](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609113342797.png)

确定未running状态，再进行之后的操作。

5. 让其它所有节点加入master节点

```shell
# 查看所有节点
kubectl get nodes
```

![image-20220609113613449](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609113613449.png)

6. 让其它节点加入master节点，执行以下命令

在k8s-node1和k8s-node2分别执行以下语句

```shell
kubeadm join 192.168.10.100:6443 --token 6tfp14.d1uy5xy2mjy0q113 \
    --discovery-token-ca-cert-hash sha256:f0d96f0381301e0fd7a41bb1c3d04898f6f7926be3d06578dda19d2879aad26e
```

**node1**

![image-20220609114119544](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609114119544.png)

**master**

加入后，等1分钟左右状态会编程Ready

![image-20220609114200629](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609114200629.png)

**监控各个节点状态：**

```shell
watch kubectl get pod -n kube-system -o wide
```

![image-20220609114402287](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609114402287.png)

####  3. 创建容器

**以下操作在master操作**

创建一个tomcat pod

```shell
kubectl create deployment tomcat6 --image=tomcat:8.5.75-jre8
```

![image-20220609140602458](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609140602458.png)

获取k8s中的所有资源

```shell
[root@k8s-master k8s]# kubectl get all
NAME                           READY   STATUS              RESTARTS   AGE
pod/tomcat8-84d78f8f54-g4jdg   0/1     ContainerCreating   0          69s   

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   178m

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/tomcat8   0/1     1            0           71s  # 部署了一个tomcat8，但是还没有成功

NAME                                 DESIRED   CURRENT   READY   AGE
replicaset.apps/tomcat8-84d78f8f54   1         1         0       71s
[root@k8s-master k8s]# 

```

查看更详细的资源信息

```shell
[root@k8s-master k8s]# kubectl get all -o wide
NAME                           READY   STATUS    RESTARTS   AGE     IP           NODE        NOMINATED NODE   READINESS GATES
pod/tomcat8-84d78f8f54-g4jdg   1/1     Running   0          3m37s   10.244.2.2   k8s-node2   <none>           <none>

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   3h    <none>

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES               SELECTOR
deployment.apps/tomcat8   1/1     1            1           3m37s   tomcat       tomcat:8.5.75-jre8   app=tomcat8

NAME                                 DESIRED   CURRENT   READY   AGE     CONTAINERS   IMAGES               SELECTOR
replicaset.apps/tomcat8-84d78f8f54   1         1         1       3m37s   tomcat       tomcat:8.5.75-jre8   app=tomcat8,pod-template-hash=84d78f8f54

```

![image-20220609141004643](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609141004643.png)

发现部署到了k8s-node2节点

查看node2节点

发现有tomcat镜像，并有一个正在运行的容器

![image-20220609141259250](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609141259250.png)

在master上，查看pods信息

```shell
[root@k8s-master k8s]# kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
tomcat8-84d78f8f54-g4jdg   1/1     Running   0          9m33s
```

查看所有的命名空间

```shell
kubectl get pods --all-namespaces
```

![image-20220609141831916](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609141831916.png)

查看节点详情

![image-20220609141931339](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609141931339.png)

我们发现，我们的tomcat服务被k8s指定部署到了node2节点上，如果服务宕机了，会怎么样呢？

#### 4. 节点宕机

1. **情况1：停止node2的tomcat容器**

![image-20220609142431585](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609142431585.png)

2. **情况二：关闭node2服务**

此时只有主节点和node1节点存活

![image-20220609142653977](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609142653977.png)

查看节点状态：

![image-20220609143847335](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609143847335.png)

查看pod状态：

![image-20220609143516267](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609143516267.png)

发现node2的节点状态已经是Teminating终端了，而node1中又新建了一个容器，正在创建中，体现了容灾恢复功能。

查看node1节点的容器

![image-20220609143702820](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609143702820.png)

发现已经重新创建了一个tomcat容器

此时pod的状态：

![image-20220609143739061](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609143739061.png)

重新启动node2

在查看pod状态：

发现node2的Teaminating的READY变成了1，说明停止指令已传送给了node2.（之前node2直接关闭，k8s发送给node2的关闭指令node2没有收到。。个人理解）

![image-20220609144312787](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220609144312787.png)

#### 5. 暴露容器端口

将tomcat容器的端口暴露给外界，可供外界访问

```shell
kubectl expose deployment tomcat8 --port=80 --target-port=8080 --type=NodePort  
# port端口是80，target-port端口是8080  --type的类型是NodePort，表示将port当作服务使用。会随机分配service的端口号，也可以指定端口
kubectl get svc 
# 查看service服务
```

```shell
[root@k8s-master ~]# kubectl expose deployment tomcat8 --port=80 --target-port=8080 --type=NodePort  
service/tomcat8 exposed
[root@k8s-master ~]# kubectl get svc
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1      <none>        443/TCP        3h47m
tomcat8      NodePort    10.96.114.58   <none>        80:30254/TCP   9s
[root@k8s-master ~]# 
```

默认分配的service端口是30254




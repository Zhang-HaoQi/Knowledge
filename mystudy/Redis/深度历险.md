# Redis基础

## 1. Redis应用场景

1、记录帖子的点赞数、评论数和点击数 (hash)。

2、记录用户的帖子 ID 列表 (排序)，便于快速显示用户的帖子列表 (zset)。

3、记录帖子的标题、摘要、作者和封面信息，用于列表页展示 (hash)。

4、记录帖子的点赞用户 ID 列表，评论 ID 列表，用于显示和去重计数 (zset)。

5、缓存近期热帖内容 (帖子内容空间占用比较大)，减少数据库压力 (hash)。

6、记录帖子的相关文章 ID，根据内容推荐相关帖子 (list)。

7、如果帖子 ID 是整数自增的，可以使用 Redis 来分配帖子 ID(计数器)。

8、收藏集和帖子之间的关系 (zset)。

9、记录热榜帖子 ID 列表，总热榜和分类热榜 (zset)。

10、缓存用户行为历史，进行恶意行为过滤 (zset,hash)。

## 2. Redis数据结构

Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。

Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。

### String

![image-20221112093339578](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093339578.png)

![image-20221112093501306](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093501306.png)

Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的ArrayList，采用**预分配冗余空间**的方式来减少内存的频繁分配，如图中所示，**内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。**

用途：

1. 单一键值对存储
2. 批量键值对存储
3. int自增

### List

Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为

O(n)。当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。

Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。

用途：

添加数据：rpush books python java golang

1. 可作为队列使用，也可作为栈使用。

   1. 获取长度：  llen books  返回3
   2. 头部弹出数据： lpop books  返回python，队列操作
   3. 尾部弹出数据： rpop books  返回golang，栈操作

2. 慢操作：

   1. lindex books 1 ：获取books的list中索引为1的元素，返回java，复杂度O(n)

   2. lrange books 0 -1  ： 获取所有元素

   3.  ltrim books 1 -1 ：保留链表中第一个元素到倒数第一个元素，其他元素删除掉。返回 java golang

   4. ltrim books 1 0 ：清空元素，因为区间长度为负数

      ```java
      127.0.0.1:6379> rpush books python java golang
      (integer) 3
      127.0.0.1:6379> lrange books 0 -1
      1) "python"
      2) "java"
      3) "golang"
      127.0.0.1:6379> ltrim books 1 -1
      OK
      127.0.0.1:6379> lrange books 0 -1
      1) "java"
      2) "golang"
      127.0.0.1:6379> ltrim books 1 0
      OK
      127.0.0.1:6379> lrange books 0 -1
      (empty array)
      127.0.0.1:6379> 
      ```

3.  快速列表

   ![image-20221112100858789](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100858789.png)

   1. redis底层存储并不是一个简单的linkedlist，而是quicklist。
   2. 当元素较少时，将所有元素紧挨着存储，分配一块连续的内存空间，为压缩链表（ziplist）。
   3. 当元素较多时，将ziplist结合起来组成quicklist。ziplist之间使用双向链表串起来，满足快速插入和删除性能，不会出现太大的空间冗余。
      1. 如果元素与元素之间连接起来，指针占用内存空间，即浪费空间，又导致内存碎片化。

### Hash

类似Java的HashMap，数组+链表结构。

![image-20221112100956407](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100956407.png)

Redis 的字典的值只能是字符串，rehash 的方式不一样，因为Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 

为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。

![image-20221112143240585](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112143240585.png)

渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个hash 结构，然后在后续的定时任务中以及 hash 的子指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。

### Set

Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。

### ZSET（有序列表）

它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫着「跳跃列表」的数据结构。 

zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。

zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。

**跳跃列表**

zset 内部的排序功能是通过「跳跃列表」数据结构来实现的。

zset要支持随机插入和删除，数组不好表示。插入的元素要排序，要保证链表是有序的，可以通过二分查找快速找到插入点，但是二分查找只适用于数组。因此提出跳跃链表。

![image-20221112144321702](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112144321702.png)

跳跃链表：每个元素分为不同的等级，最低级是所有元素，之后依次向上挑选。

定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。

新插入的元素，采取随机策略来决定新元素可以兼职到第几层。

L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少Redis 数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。

### 数据类型通用规则

list/set/hash/zset 这四种数据结构是容器型数据结构，都满足一下规则：

1. 添加元素时，容器不存在则创建。
2. 删除元素时，容器中没有元素，立即删除元素。
3. 过期时间是以容器为单位的，而非容器中的某个元素。
   1. 如hash设置过期时间是整个hash的过期时间，而非其中一个key的过期时间。

注意：如果一个字符串设置了过期时间，如果再次修改他时，过期时间会失效。

```sql
127.0.0.1:6379> set name zhangsan ex 1000
OK
127.0.0.1:6379> ttl name
(integer) 993
127.0.0.1:6379> set name lisi
OK
127.0.0.1:6379> ttl name
(integer) -1
127.0.0.1:6379> 
127.0.0.1:6379> get name
"lisi"
```

# Redis应用

## 1. 分布式锁

### 分布式锁

使用set is not exits 命令占锁，占锁成功后执行业务，执行完成后释放锁del。

setnx lock true

问题：业务未执行完，发生异常，del没有执行，陷入死锁，锁永远得不到释放。

解决：为锁设置过期时间。

问题：业务时间过长，锁提前释放。业务再次执行时新添加锁，此时之前的业务执行完毕，将新业务的锁释放掉。

解决：

1. 分布式锁不要用于过长时间任务，如果出现了锁现象，数据小范围错乱人工干预。
2. 使用lua脚本，为每次加锁设置一个唯一的随机数，只能此随机数进行锁释放。（设置过期时间的话还有可能造成业务没执行完，锁提前释放问题-使用看门狗机制）

## 2. 异步消息队列

### 异步队列实现

**list实现队列**

对比消息中间件，redis队列没有非常多的高级特性，没有ack保证，如果对消息的可靠性要求较高，不建议使用。

Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用 lpop 和 rpop 来出队列。

![image-20221112151839587](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112151839587.png)

rpush入队，lpop出队。

lpush入队，rpop出队。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> lpop fruit
"apple"
127.0.0.1:6379> lpop fruit
"banana"
127.0.0.1:6379> lpop fruit
"pear"
127.0.0.1:6379> lpop fruit
"orange"
127.0.0.1:6379> lpop fruit
(nil)
```

使用pop获取消息后，进行处理，处理完毕后继续获取。while循环的方式。

如果队列为null，则进行一段睡眠后再pop，降低redis的qps和客户端的cpu占用。

**阻塞读**

问题：一个消费者延迟就是1s，如果是多个消费者，彼此的延迟都是岔开的，实际延迟可能不到1s就有消费者又尝试获取

解决：使用阻塞读 blpop/brpop

阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "apple"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "banana"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "pear"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "orange"
127.0.0.1:6379> blpop fruit 10   //10s后，如果还没有数据，则结束。
(nil)   
(10.07s)
```

注意：如果线程一直闲置在哪里，超过阻塞的时间，redis的客户端连接就成了闲置连接，服务器一端会主动断开链接，减少闲置资源占用，此时blpop/brpop会抛出异常。因此编写客户端要注意捕获异常和重试。

### 加锁失败的处理方式

1. 直接抛出异常，通知用户之后重试
2. sleep一会重试
   1. 如果请求过多，如果一个请求产生死锁，导致之后的请求都无法运行。
3. 请求移交到延时队列，过一会再试。

### 延时队列实现

延时队列可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。

详细实现参考书籍。

## 3. 位图

### 基本使用

开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。

Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下。

位图详解:[Redis bitmap位图操作（图解） (biancheng.net)](http://c.biancheng.net/redis/bitmap.html)

语法：SETBIT key 位 值（0或1）

位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。

**通过位图打印hello**

接下来我们使用位操作将字符串设置为 hello (不是直接使用 set 指令)，首先我们需要得到 hello 的 ASCII 码，用 Python 命令行可以很方便地得到每个字符的 ASCII 码的二进制值。

![image-20221112161807776](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112161807776.png)

```java
127.0.0.1:6379> setbit user:2 1 1
(integer) 0
127.0.0.1:6379> setbit user:2 2 1
(integer) 0
127.0.0.1:6379> setbit user:2 4 1
(integer) 0
127.0.0.1:6379> setbit user:2 9 1
(integer) 0
127.0.0.1:6379> setbit user:2 10 1
(integer) 0
127.0.0.1:6379> setbit user:2 13 1
(integer) 0
127.0.0.1:6379> setbit user:2 15 1
(integer) 0
127.0.0.1:6379> get user:2
"he"
```

如果对应位的字节是不可打印字符，redis-cli 会显示该字符的 16 进制形式。

```java
127.0.0.1:6379> setbit user:3 0 1
(integer) 0
127.0.0.1:6379> setbit user:3 2 1
(integer) 0
127.0.0.1:6379> get user:3
"\xa0"
```

### 统计查找

使用bitcount计算字节中1的个数（注意，bitcount是以字节为单位的）

```java
127.0.0.1:6379> bitcount user:2  key user:2中一共有7个1。
(integer) 7
127.0.0.1:6379> bitcount user:2 0 0 key user:2中第一个字节有3个1。
(integer) 3
127.0.0.1:6379> bitcount user:2 0 1  key user:2中前两个字节有7个1。
(integer) 7
```

使用bitpos 用来查找指定范围内出现的第一个 0 或 1

```java
127.0.0.1:6379> bitpos user:2 0  # 第一个 0 位
(integer) 0
127.0.0.1:6379> bitpos user:2 1 # 第一个 1 位
(integer) 1
127.0.0.1:6379> bitpos user:2 1 1 1 # 从第二个字符算起，第一个 1 位
(integer) 9
127.0.0.1:6379> bitpos user:2 1 2 2   # 从第三个字符算起，第一个 1 位
(integer) -1
```

### 魔数指令bitfield

看书

## 4. HyperLogLog

### 统计网站数据

统计**网站每个网页**一天的PV和UV数据。

PV：页面一天访问量（用户每访问一次加一次）  

**解决：**给每个网页设计一个redis计数器，接口请求一次，incrby一次即可。

UV：页面一天访客量（一个用户每天最多纪录一次）

**解决：**

分析：要去重，同一个用户一天之内的多次访问请求只能计数一次。每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一ID 来标识

实现：

为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。

问题：

如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。

另外这些数据不需要太精确，没有必要为这样一个去重功能浪费这么大的内存空间。

### HyperLogLog 

HyperLogLog 提供不精确的去重计数方案，标准误差是 0.81%，精确度已经可以满足上面的 UV 统计需求。

语法：

pfadd  key value  添加一个计数，如果不存在返回1，否则返回0（有误差，但很小）

pfcount key  计算添加的元素数量

pfmerge key1 key2 ...  将多个pf的值进行合并（注意：合并的时候，如果pf1和pf2有重复的，也会进行去重再计算）

```java
连续添加了两次重复的用户，最后计算的数量是5，正确。
127.0.0.1:6379> pfadd hotel user1
(integer) 1
127.0.0.1:6379> pfadd hotel user2
(integer) 1
127.0.0.1:6379> pfadd hotel user3
(integer) 1
127.0.0.1:6379> pfadd hotel user4
(integer) 1
127.0.0.1:6379> pfadd hotel user5
(integer) 1
127.0.0.1:6379> pfadd hotel user1
(integer) 0
127.0.0.1:6379> pfadd hotel user2
(integer) 0
127.0.0.1:6379> pfadd hotel user3
(integer) 0
127.0.0.1:6379> pfadd hotel user4
(integer) 0
127.0.0.1:6379> pfadd hotel user5
(integer) 0
127.0.0.1:6379> pfcount hotel
(integer) 5
```

注意：

该数据结构使用的时候，会占据一定12k的存储空间，并不是和统计单个用户相关的数据。适合流量比较大，对公共数据的统计。

相比set存储方案，HyperLogLog用的空间相对少很多。

Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。

### 实现原理

查看书籍。

## 5. 布隆过滤器

推荐文章：[布隆过滤器，这一篇给你讲的明明白白-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/773205#slide-14)

相关过滤器：布谷鸟过滤器：[布谷鸟过滤器（Cuckoo Filter） - 泰阁尔 - 博客园 (cnblogs.com)](https://www.cnblogs.com/zhaodongge/p/15067657.html)

### 布隆过滤器

判断一个元素是否存在于集合中，我们会存储这些元素然后进行判重操作，但是使用链表，树，hash这些数据结构，随着元素数量的增多，存储空间会直线增张，最终达到性能瓶颈。检索时间复杂度：$O(n)$，$O(logn)$，$O(1)$。

用于解决批量数据的判重问题，在去重的同时，空间能节省90%，但是有一定的误判概率。

**hash函数结构**

![image-20221112205746248](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205746248.png)

- 如果两个散列值是不相同的（根据同一函数)，那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为**单向散列函数**。
- 散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“**散列碰撞**（collision）”。

但是用 hash表存储大数据量时，空间效率还是很低，当只有一个 hash 函数时，还很容易发生哈希碰撞。

**布隆过滤器**

BloomFilter 是由一个固定大小的二进制向量或者位图（bitmap）和一系列映射函数组成的。

在初始状态时，对于长度为 m 的位数组，它的所有位都被置为0。

![image-20221112205840897](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205840897.png)

当有变量被加入集合时，通过 K 个映射函数将这个变量映射成位图中的 K 个点，把它们置为 1（假定有两个变量都通过 3 个映射函数）。

![image-20221112205904421](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205904421.png)

查询某个变量的时候我们只要看看这些点是不是都是 1 就可以大概率知道集合中有没有它了

**特性：**

- **一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在**。
- **布隆过滤器可以添加元素，但是不能删除元素**。因为删掉元素会导致误判率增加。

**添加元素步骤：**

1. 将要添加的元素给 k 个哈希函数
2. 得到对应于位数组上的 k 个位置
3. 将这k个位置设为 1

**查询元素步骤：**

1. 将要查询的元素给k个哈希函数
2. 得到对应于位数组上的k个位置
3. 如果k个位置有一个为 0，则肯定不在集合中
4. 如果k个位置全部为 1，则可能在集合中

**优点：**

1. 对比其他数据结构，时间和空间有巨大优势。插入/查询时间复杂度都是O（K）。

2. 散列函数相互之间没有关系，方便由硬件并行实现。

3. 不存储元素本身，对保密要求有严格的场合有优势。

**缺点：**

1. 误判，随着元素的增加，误算率也随之增加。如果元素数量较少，使用散列表足矣。
2. 不能删除元素。

### 使用场景

1. 已阅读文章/视频去重推荐
2. 缓存穿透，请求来的时候先经过布隆过滤器，如果布隆过滤器有数据，再去查redis，redis没有再去查库。如果布隆过滤器没有数据，直接拒绝。
3. WEB拦截器，如果相同请求则拦截，防止重复被攻击。用户第一次请求，将请求参数放入布隆过滤器中，当第二次请求时，先判断请求参数是否被布隆过滤器命中。
4. 爬虫去重，已经爬过的网页不再去爬
5. Nosql中，当用户来查询某个 row 时，可以先通过内存中的布隆过滤器过滤掉大量不存在的row 请求，然后再去磁盘进行查询。
6. 垃圾邮件的过滤功能。

### 布隆过滤器使用

#### redis布隆过滤器

```sql
docker run -p 6381:6379 \
--name redis-bloom \
-d --restart=always \
-e TZ="Asia/Shanghai" \
 -v /opt/dockers/docker_redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \
 -v /opt/dockers/docker_redis/data:/var/lib/redis \
 -v /opt/dockers/docker_redis/log:/var/log/redis \
 redislabs/rebloom:2.2.2 \
 /usr/local/bin/redis-server /usr/local/etc/redis/redis.conf \
 --appendonly yes\
 --requirepass "123456" \
 --loadmodule "/usr/lib/redis/modules/redisbloom.so"
 
 docker exec -it redis-bloom redis-cli
 
 auth
 
```

布隆过滤器基本指令：

- bf.add 添加元素到布隆过滤器
- bf.exists 判断元素是否在布隆过滤器
- bf.madd 添加多个元素到布隆过滤器，bf.add 只能添加一个
- bf.mexists 判断多个元素是否在布隆过滤器

```sql
# 添加元素
127.0.0.1:6379> bf.add user Tom
(integer) 1
127.0.0.1:6379> bf.add user Tom1
(integer) 1
127.0.0.1:6379> bf.add user Tom2
(integer) 1
127.0.0.1:6379> bf.add user Tom3
(integer) 1
# 重复添加元素
127.0.0.1:6379> bf.add user Tom1
(integer) 0
127.0.0.1:6379> bf.add user Tom
(integer) 0
# 判断元素是否存在
127.0.0.1:6379> bf.exists user Tom
(integer) 1
# 判断多个元素是否存在
127.0.0.1:6379> bf.mexists user Tom1 Tom2
1) (integer) 1
2) (integer) 1
127.0.0.1:6379> bf.mexists user Tom11 Tom12
1) (integer) 0
2) (integer) 0
```

问题：有一定的误判

Redis 还提供了自定义参数的布隆过滤器，`bf.reserve 过滤器名 error_rate initial_size`

- error_rate：允许布隆过滤器的错误率，这个值越低过滤器的位数组的大小越大，占用空间也就越大
- initial_size：布隆过滤器可以储存的元素个数，当实际存储的元素个数超过这个值之后，过滤器的准确率会下降

bf.reserve 需要在add之前显式创建，否则会报错。

```java
127.0.0.1:6379> bf.reserve user 0.01 100
(error) ERR item exists
127.0.0.1:6379> bf.reserve topic 0.01 1000
OK
```

通过Redisson使用过布隆滤器

```java
public class RedissonBloomFilterDemo {

    public static void main(String[] args) {

        Config config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");
        RedissonClient redisson = Redisson.create(config);

        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("user");
        // 初始化布隆过滤器，预计统计元素数量为55000000，期望误差率为0.03
        bloomFilter.tryInit(55000000L, 0.03);
        bloomFilter.add("Tom");
        bloomFilter.add("Jack");
        System.out.println(bloomFilter.count());   //2
        System.out.println(bloomFilter.contains("Tom"));  //true
        System.out.println(bloomFilter.contains("Linda"));  //false
    }
}
```

#### 自定义布隆过滤器

```java
public class MyBloomFilter {

    /**
     * 一个长度为10 亿的比特位
     */
    private static final int DEFAULT_SIZE = 256 << 22;

    /**
     * 为了降低错误率，使用加法hash算法，所以定义一个8个元素的质数数组
     */
    private static final int[] seeds = {3, 5, 7, 11, 13, 31, 37, 61};

    /**
     * 相当于构建 8 个不同的hash算法
     */
    private static HashFunction[] functions = new HashFunction[seeds.length];

    /**
     * 初始化布隆过滤器的 bitmap
     */
    private static BitSet bitset = new BitSet(DEFAULT_SIZE);

    /**
     * 添加数据
     *
     * @param value 需要加入的值
     */
    public static void add(String value) {
        if (value != null) {
            for (HashFunction f : functions) {
                //计算 hash 值并修改 bitmap 中相应位置为 true
                bitset.set(f.hash(value), true);
            }
        }
    }

    /**
     * 判断相应元素是否存在
     * @param value 需要判断的元素
     * @return 结果
     */
    public static boolean contains(String value) {
        if (value == null) {
            return false;
        }
        boolean ret = true;
        for (HashFunction f : functions) {
            ret = bitset.get(f.hash(value));
            //一个 hash 函数返回 false 则跳出循环
            if (!ret) {
                break;
            }
        }
        return ret;
    }

    /**
     * 模拟用户是不是会员，或用户在不在线。。。
     */
    public static void main(String[] args) {

        for (int i = 0; i < seeds.length; i++) {
            functions[i] = new HashFunction(DEFAULT_SIZE, seeds[i]);
        }

        // 添加1亿数据
        for (int i = 0; i < 100000000; i++) {
            add(String.valueOf(i));
        }
        String id = "123456789";
        add(id);

        System.out.println(contains(id));   // true
        System.out.println("" + contains("234567890"));  //false
    }
}

class HashFunction {

    private int size;
    private int seed;

    public HashFunction(int size, int seed) {
        this.size = size;
        this.seed = seed;
    }

    public int hash(String value) {
        int result = 0;
        int len = value.length();
        for (int i = 0; i < len; i++) {
            result = seed * result + value.charAt(i);
        }
        int r = (size - 1) & result;
        return (size - 1) & result;
    }
}
```

#### Guava 中的 BloomFilter

```java
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>23.0</version>
</dependency>

public class GuavaBloomFilterDemo {

    public static void main(String[] args) {
        //后边两个参数：预计包含的数据量，和允许的误差值
        BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), 100000, 0.01);
        for (int i = 0; i < 100000; i++) {
            bloomFilter.put(i);
        }
        System.out.println(bloomFilter.mightContain(1));
        System.out.println(bloomFilter.mightContain(2));
        System.out.println(bloomFilter.mightContain(3));
        System.out.println(bloomFilter.mightContain(100001));

        //bloomFilter.writeTo();
    }
}
```

#### SpringBoot

[(287条消息) SpringBoot + Redis实现布隆过滤器拦截无效请求_Toner_唐纳的博客-CSDN博客_布隆过滤器拦截](https://blog.csdn.net/qq_37012496/article/details/106375261)

## 6. 限流

限流目的：

1. 系统处理能力有限，阻止计划外的请求对系统施压。
2. 控制用户行为，避免垃圾请求。

### Redis实现限流

限定用户的某个行为在指定的时间里只能允许发生 N 次。

使用ZSET，通过滑动窗口的形式来计算指定时间内请求的次数。

![image-20221112221255697](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112221255697.png)

通过score的range可以查看单位时间内用户操作的次数。

```java
public Response limitFlow(){
 Long currentTime = new Date().getTime();
 System.out.println(currentTime);
 if(redisTemplate.hasKey("1001")) {
 Integer count = redisTemplate.opsForZSet().rangeByScore("1001", currentTime -  intervalTime, currentTime).size();        // intervalTime是限流的时间 
 System.out.println(count);
 if (count != null && count > 5) {
 return Response.ok("每分钟最多只能访问5次");
 }
 }
 redisTemplate.opsForZSet().add("limit",UUID.randomUUID().toString(),currentTime);
 return Response.ok("访问成功");
 }

```








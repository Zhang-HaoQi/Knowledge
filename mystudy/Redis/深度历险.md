# Redis基础

## 0. 学习资源

阿里云文档（进阶操作）：[性能排查与调优 (aliyun.com)](https://help.aliyun.com/document_detail/265988.html)

redis深度历险

## 1. Redis应用场景

1、记录帖子的点赞数、评论数和点击数 (hash)。

2、记录用户的帖子 ID 列表 (排序)，便于快速显示用户的帖子列表 (zset)。

3、记录帖子的标题、摘要、作者和封面信息，用于列表页展示 (hash)。

4、记录帖子的点赞用户 ID 列表，评论 ID 列表，用于显示和去重计数 (zset)。

5、缓存近期热帖内容 (帖子内容空间占用比较大)，减少数据库压力 (hash)。

6、记录帖子的相关文章 ID，根据内容推荐相关帖子 (list)。

7、如果帖子 ID 是整数自增的，可以使用 Redis 来分配帖子 ID(计数器)。

8、收藏集和帖子之间的关系 (zset)。

9、记录热榜帖子 ID 列表，总热榜和分类热榜 (zset)。

10、缓存用户行为历史，进行恶意行为过滤 (zset,hash)。

## 2. Redis数据结构

Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。

Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。

### String

![image-20221112093339578](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093339578.png)

![image-20221112093501306](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093501306.png)

Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的ArrayList，采用**预分配冗余空间**的方式来减少内存的频繁分配，如图中所示，**内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。**

用途：

1. 单一键值对存储
2. 批量键值对存储
3. int自增

### List

Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为

O(n)。当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。

Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。

用途：

添加数据：rpush books python java golang

1. 可作为队列使用，也可作为栈使用。

   1. 获取长度：  llen books  返回3
   2. 头部弹出数据： lpop books  返回python，队列操作
   3. 尾部弹出数据： rpop books  返回golang，栈操作

2. 慢操作：

   1. lindex books 1 ：获取books的list中索引为1的元素，返回java，复杂度O(n)

   2. lrange books 0 -1  ： 获取所有元素

   3.  ltrim books 1 -1 ：保留链表中第一个元素到倒数第一个元素，其他元素删除掉。返回 java golang

   4. ltrim books 1 0 ：清空元素，因为区间长度为负数

      ```java
      127.0.0.1:6379> rpush books python java golang
      (integer) 3
      127.0.0.1:6379> lrange books 0 -1
      1) "python"
      2) "java"
      3) "golang"
      127.0.0.1:6379> ltrim books 1 -1
      OK
      127.0.0.1:6379> lrange books 0 -1
      1) "java"
      2) "golang"
      127.0.0.1:6379> ltrim books 1 0
      OK
      127.0.0.1:6379> lrange books 0 -1
      (empty array)
      127.0.0.1:6379> 
      ```

3.  快速列表

   ![image-20221112100858789](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100858789.png)

   1. redis底层存储并不是一个简单的linkedlist，而是quicklist。
   2. 当元素较少时，将所有元素紧挨着存储，分配一块连续的内存空间，为压缩链表（ziplist）。
   3. 当元素较多时，将ziplist结合起来组成quicklist。ziplist之间使用双向链表串起来，满足快速插入和删除性能，不会出现太大的空间冗余。
      1. 如果元素与元素之间连接起来，指针占用内存空间，即浪费空间，又导致内存碎片化。

### Hash

类似Java的HashMap，数组+链表结构。

![image-20221112100956407](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100956407.png)

Redis 的字典的值只能是字符串，rehash 的方式不一样，因为Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 

为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。

![image-20221112143240585](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112143240585.png)

渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个hash 结构，然后在后续的定时任务中以及 hash 的子指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。

### Set

Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。

### ZSET（有序列表）

它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫着「跳跃列表」的数据结构。 

zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。

zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。

**跳跃列表**

zset 内部的排序功能是通过「跳跃列表」数据结构来实现的。

zset要支持随机插入和删除，数组不好表示。插入的元素要排序，要保证链表是有序的，可以通过二分查找快速找到插入点，但是二分查找只适用于数组。因此提出跳跃链表。

![image-20221112144321702](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112144321702.png)

跳跃链表：每个元素分为不同的等级，最低级是所有元素，之后依次向上挑选。

定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。

新插入的元素，采取随机策略来决定新元素可以兼职到第几层。

L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少Redis 数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。

### 数据类型通用规则

list/set/hash/zset 这四种数据结构是容器型数据结构，都满足一下规则：

1. 添加元素时，容器不存在则创建。
2. 删除元素时，容器中没有元素，立即删除元素。
3. 过期时间是以容器为单位的，而非容器中的某个元素。
   1. 如hash设置过期时间是整个hash的过期时间，而非其中一个key的过期时间。

注意：如果一个字符串设置了过期时间，如果再次修改他时，过期时间会失效。

```sql
127.0.0.1:6379> set name zhangsan ex 1000
OK
127.0.0.1:6379> ttl name
(integer) 993
127.0.0.1:6379> set name lisi
OK
127.0.0.1:6379> ttl name
(integer) -1
127.0.0.1:6379> 
127.0.0.1:6379> get name
"lisi"
```

# Redis应用

## 1. 分布式锁

### 分布式锁

使用set is not exits 命令占锁，占锁成功后执行业务，执行完成后释放锁del。

setnx lock true

问题：业务未执行完，发生异常，del没有执行，陷入死锁，锁永远得不到释放。

解决：为锁设置过期时间。

问题：业务时间过长，锁提前释放。业务再次执行时新添加锁，此时之前的业务执行完毕，将新业务的锁释放掉。

解决：

1. 分布式锁不要用于过长时间任务，如果出现了锁现象，数据小范围错乱人工干预。
2. 使用lua脚本，为每次加锁设置一个唯一的随机数，只能此随机数进行锁释放。（设置过期时间的话还有可能造成业务没执行完，锁提前释放问题-使用看门狗机制）

## 2. 异步消息队列

### 异步队列实现

**list实现队列**

对比消息中间件，redis队列没有非常多的高级特性，没有ack保证，如果对消息的可靠性要求较高，不建议使用。

Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用 lpop 和 rpop 来出队列。

![image-20221112151839587](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112151839587.png)

rpush入队，lpop出队。

lpush入队，rpop出队。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> lpop fruit
"apple"
127.0.0.1:6379> lpop fruit
"banana"
127.0.0.1:6379> lpop fruit
"pear"
127.0.0.1:6379> lpop fruit
"orange"
127.0.0.1:6379> lpop fruit
(nil)
```

使用pop获取消息后，进行处理，处理完毕后继续获取。while循环的方式。

如果队列为null，则进行一段睡眠后再pop，降低redis的qps和客户端的cpu占用。

**阻塞读**

问题：一个消费者延迟就是1s，如果是多个消费者，彼此的延迟都是岔开的，实际延迟可能不到1s就有消费者又尝试获取

解决：使用阻塞读 blpop/brpop

阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "apple"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "banana"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "pear"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "orange"
127.0.0.1:6379> blpop fruit 10   //10s后，如果还没有数据，则结束。
(nil)   
(10.07s)
```

注意：如果线程一直闲置在哪里，超过阻塞的时间，redis的客户端连接就成了闲置连接，服务器一端会主动断开链接，减少闲置资源占用，此时blpop/brpop会抛出异常。因此编写客户端要注意捕获异常和重试。

### 加锁失败的处理方式

1. 直接抛出异常，通知用户之后重试
2. sleep一会重试
   1. 如果请求过多，如果一个请求产生死锁，导致之后的请求都无法运行。
3. 请求移交到延时队列，过一会再试。

### 延时队列实现

延时队列可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。

详细实现参考书籍。

## 3. 位图

### 基本使用

开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。

Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下。

位图详解:[Redis bitmap位图操作（图解） (biancheng.net)](http://c.biancheng.net/redis/bitmap.html)

语法：SETBIT key 位 值（0或1）

位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。

**通过位图打印hello**

接下来我们使用位操作将字符串设置为 hello (不是直接使用 set 指令)，首先我们需要得到 hello 的 ASCII 码，用 Python 命令行可以很方便地得到每个字符的 ASCII 码的二进制值。

![image-20221112161807776](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112161807776.png)

```java
127.0.0.1:6379> setbit user:2 1 1
(integer) 0
127.0.0.1:6379> setbit user:2 2 1
(integer) 0
127.0.0.1:6379> setbit user:2 4 1
(integer) 0
127.0.0.1:6379> setbit user:2 9 1
(integer) 0
127.0.0.1:6379> setbit user:2 10 1
(integer) 0
127.0.0.1:6379> setbit user:2 13 1
(integer) 0
127.0.0.1:6379> setbit user:2 15 1
(integer) 0
127.0.0.1:6379> get user:2
"he"
```

如果对应位的字节是不可打印字符，redis-cli 会显示该字符的 16 进制形式。

```java
127.0.0.1:6379> setbit user:3 0 1
(integer) 0
127.0.0.1:6379> setbit user:3 2 1
(integer) 0
127.0.0.1:6379> get user:3
"\xa0"
```

### 统计查找

使用bitcount计算字节中1的个数（注意，bitcount是以字节为单位的）

```java
127.0.0.1:6379> bitcount user:2  key user:2中一共有7个1。
(integer) 7
127.0.0.1:6379> bitcount user:2 0 0 key user:2中第一个字节有3个1。
(integer) 3
127.0.0.1:6379> bitcount user:2 0 1  key user:2中前两个字节有7个1。
(integer) 7
```

使用bitpos 用来查找指定范围内出现的第一个 0 或 1

```java
127.0.0.1:6379> bitpos user:2 0  # 第一个 0 位
(integer) 0
127.0.0.1:6379> bitpos user:2 1 # 第一个 1 位
(integer) 1
127.0.0.1:6379> bitpos user:2 1 1 1 # 从第二个字符算起，第一个 1 位
(integer) 9
127.0.0.1:6379> bitpos user:2 1 2 2   # 从第三个字符算起，第一个 1 位
(integer) -1
```

### 魔数指令bitfield

看书

## 4. HyperLogLog

### 统计网站数据

统计**网站每个网页**一天的PV和UV数据。

PV：页面一天访问量（用户每访问一次加一次）  

**解决：**给每个网页设计一个redis计数器，接口请求一次，incrby一次即可。

UV：页面一天访客量（一个用户每天最多纪录一次）

**解决：**

分析：要去重，同一个用户一天之内的多次访问请求只能计数一次。每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一ID 来标识

实现：

为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。

问题：

如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。

另外这些数据不需要太精确，没有必要为这样一个去重功能浪费这么大的内存空间。

### HyperLogLog 

HyperLogLog 提供不精确的去重计数方案，标准误差是 0.81%，精确度已经可以满足上面的 UV 统计需求。

语法：

pfadd  key value  添加一个计数，如果不存在返回1，否则返回0（有误差，但很小）

pfcount key  计算添加的元素数量

pfmerge key1 key2 ...  将多个pf的值进行合并（注意：合并的时候，如果pf1和pf2有重复的，也会进行去重再计算）

```java
连续添加了两次重复的用户，最后计算的数量是5，正确。
127.0.0.1:6379> pfadd hotel user1
(integer) 1
127.0.0.1:6379> pfadd hotel user2
(integer) 1
127.0.0.1:6379> pfadd hotel user3
(integer) 1
127.0.0.1:6379> pfadd hotel user4
(integer) 1
127.0.0.1:6379> pfadd hotel user5
(integer) 1
127.0.0.1:6379> pfadd hotel user1
(integer) 0
127.0.0.1:6379> pfadd hotel user2
(integer) 0
127.0.0.1:6379> pfadd hotel user3
(integer) 0
127.0.0.1:6379> pfadd hotel user4
(integer) 0
127.0.0.1:6379> pfadd hotel user5
(integer) 0
127.0.0.1:6379> pfcount hotel
(integer) 5
```

注意：

该数据结构使用的时候，会占据一定12k的存储空间，并不是和统计单个用户相关的数据。适合流量比较大，对公共数据的统计。

相比set存储方案，HyperLogLog用的空间相对少很多。

Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。

### 实现原理

查看书籍。

## 5. 布隆过滤器

推荐文章：[布隆过滤器，这一篇给你讲的明明白白-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/773205#slide-14)

相关过滤器：布谷鸟过滤器：[布谷鸟过滤器（Cuckoo Filter） - 泰阁尔 - 博客园 (cnblogs.com)](https://www.cnblogs.com/zhaodongge/p/15067657.html)

### 布隆过滤器

判断一个元素是否存在于集合中，我们会存储这些元素然后进行判重操作，但是使用链表，树，hash这些数据结构，随着元素数量的增多，存储空间会直线增张，最终达到性能瓶颈。检索时间复杂度：$O(n)$，$O(logn)$，$O(1)$。

用于解决批量数据的判重问题，在去重的同时，空间能节省90%，但是有一定的误判概率。

**hash函数结构**

![image-20221112205746248](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205746248.png)

- 如果两个散列值是不相同的（根据同一函数)，那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为**单向散列函数**。
- 散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“**散列碰撞**（collision）”。

但是用 hash表存储大数据量时，空间效率还是很低，当只有一个 hash 函数时，还很容易发生哈希碰撞。

**布隆过滤器**

BloomFilter 是由一个固定大小的二进制向量或者位图（bitmap）和一系列映射函数组成的。

在初始状态时，对于长度为 m 的位数组，它的所有位都被置为0。

![image-20221112205840897](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205840897.png)

当有变量被加入集合时，通过 K 个映射函数将这个变量映射成位图中的 K 个点，把它们置为 1（假定有两个变量都通过 3 个映射函数）。

![image-20221112205904421](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205904421.png)

查询某个变量的时候我们只要看看这些点是不是都是 1 就可以大概率知道集合中有没有它了

**特性：**

- **一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在**。
- **布隆过滤器可以添加元素，但是不能删除元素**。因为删掉元素会导致误判率增加。

**添加元素步骤：**

1. 将要添加的元素给 k 个哈希函数
2. 得到对应于位数组上的 k 个位置
3. 将这k个位置设为 1

**查询元素步骤：**

1. 将要查询的元素给k个哈希函数
2. 得到对应于位数组上的k个位置
3. 如果k个位置有一个为 0，则肯定不在集合中
4. 如果k个位置全部为 1，则可能在集合中

**优点：**

1. 对比其他数据结构，时间和空间有巨大优势。插入/查询时间复杂度都是O（K）。

2. 散列函数相互之间没有关系，方便由硬件并行实现。

3. 不存储元素本身，对保密要求有严格的场合有优势。

**缺点：**

1. 误判，随着元素的增加，误算率也随之增加。如果元素数量较少，使用散列表足矣。
2. 不能删除元素。

### 使用场景

1. 已阅读文章/视频去重推荐
2. 缓存穿透，请求来的时候先经过布隆过滤器，如果布隆过滤器有数据，再去查redis，redis没有再去查库。如果布隆过滤器没有数据，直接拒绝。
3. WEB拦截器，如果相同请求则拦截，防止重复被攻击。用户第一次请求，将请求参数放入布隆过滤器中，当第二次请求时，先判断请求参数是否被布隆过滤器命中。
4. 爬虫去重，已经爬过的网页不再去爬
5. Nosql中，当用户来查询某个 row 时，可以先通过内存中的布隆过滤器过滤掉大量不存在的row 请求，然后再去磁盘进行查询。
6. 垃圾邮件的过滤功能。

### 布隆过滤器使用

#### redis布隆过滤器

```sql
docker run -p 6381:6379 \
--name redis-bloom \
-d --restart=always \
-e TZ="Asia/Shanghai" \
 -v /opt/dockers/docker_redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \
 -v /opt/dockers/docker_redis/data:/var/lib/redis \
 -v /opt/dockers/docker_redis/log:/var/log/redis \
 redislabs/rebloom:2.2.2 \
 /usr/local/bin/redis-server /usr/local/etc/redis/redis.conf \
 --appendonly yes\
 --requirepass "123456" \
 --loadmodule "/usr/lib/redis/modules/redisbloom.so"
 
 docker exec -it redis-bloom redis-cli
 
 auth
 
```

布隆过滤器基本指令：

- bf.add 添加元素到布隆过滤器
- bf.exists 判断元素是否在布隆过滤器
- bf.madd 添加多个元素到布隆过滤器，bf.add 只能添加一个
- bf.mexists 判断多个元素是否在布隆过滤器

```sql
# 添加元素
127.0.0.1:6379> bf.add user Tom
(integer) 1
127.0.0.1:6379> bf.add user Tom1
(integer) 1
127.0.0.1:6379> bf.add user Tom2
(integer) 1
127.0.0.1:6379> bf.add user Tom3
(integer) 1
# 重复添加元素
127.0.0.1:6379> bf.add user Tom1
(integer) 0
127.0.0.1:6379> bf.add user Tom
(integer) 0
# 判断元素是否存在
127.0.0.1:6379> bf.exists user Tom
(integer) 1
# 判断多个元素是否存在
127.0.0.1:6379> bf.mexists user Tom1 Tom2
1) (integer) 1
2) (integer) 1
127.0.0.1:6379> bf.mexists user Tom11 Tom12
1) (integer) 0
2) (integer) 0
```

问题：有一定的误判

Redis 还提供了自定义参数的布隆过滤器，`bf.reserve 过滤器名 error_rate initial_size`

- error_rate：允许布隆过滤器的错误率，这个值越低过滤器的位数组的大小越大，占用空间也就越大
- initial_size：布隆过滤器可以储存的元素个数，当实际存储的元素个数超过这个值之后，过滤器的准确率会下降

bf.reserve 需要在add之前显式创建，否则会报错。

```java
127.0.0.1:6379> bf.reserve user 0.01 100
(error) ERR item exists
127.0.0.1:6379> bf.reserve topic 0.01 1000
OK
```

通过Redisson使用过布隆滤器

```java
public class RedissonBloomFilterDemo {

    public static void main(String[] args) {

        Config config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");
        RedissonClient redisson = Redisson.create(config);

        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("user");
        // 初始化布隆过滤器，预计统计元素数量为55000000，期望误差率为0.03
        bloomFilter.tryInit(55000000L, 0.03);
        bloomFilter.add("Tom");
        bloomFilter.add("Jack");
        System.out.println(bloomFilter.count());   //2
        System.out.println(bloomFilter.contains("Tom"));  //true
        System.out.println(bloomFilter.contains("Linda"));  //false
    }
}
```

#### 自定义布隆过滤器

```java
public class MyBloomFilter {

    /**
     * 一个长度为10 亿的比特位
     */
    private static final int DEFAULT_SIZE = 256 << 22;

    /**
     * 为了降低错误率，使用加法hash算法，所以定义一个8个元素的质数数组
     */
    private static final int[] seeds = {3, 5, 7, 11, 13, 31, 37, 61};

    /**
     * 相当于构建 8 个不同的hash算法
     */
    private static HashFunction[] functions = new HashFunction[seeds.length];

    /**
     * 初始化布隆过滤器的 bitmap
     */
    private static BitSet bitset = new BitSet(DEFAULT_SIZE);

    /**
     * 添加数据
     *
     * @param value 需要加入的值
     */
    public static void add(String value) {
        if (value != null) {
            for (HashFunction f : functions) {
                //计算 hash 值并修改 bitmap 中相应位置为 true
                bitset.set(f.hash(value), true);
            }
        }
    }

    /**
     * 判断相应元素是否存在
     * @param value 需要判断的元素
     * @return 结果
     */
    public static boolean contains(String value) {
        if (value == null) {
            return false;
        }
        boolean ret = true;
        for (HashFunction f : functions) {
            ret = bitset.get(f.hash(value));
            //一个 hash 函数返回 false 则跳出循环
            if (!ret) {
                break;
            }
        }
        return ret;
    }

    /**
     * 模拟用户是不是会员，或用户在不在线。。。
     */
    public static void main(String[] args) {

        for (int i = 0; i < seeds.length; i++) {
            functions[i] = new HashFunction(DEFAULT_SIZE, seeds[i]);
        }

        // 添加1亿数据
        for (int i = 0; i < 100000000; i++) {
            add(String.valueOf(i));
        }
        String id = "123456789";
        add(id);

        System.out.println(contains(id));   // true
        System.out.println("" + contains("234567890"));  //false
    }
}

class HashFunction {

    private int size;
    private int seed;

    public HashFunction(int size, int seed) {
        this.size = size;
        this.seed = seed;
    }

    public int hash(String value) {
        int result = 0;
        int len = value.length();
        for (int i = 0; i < len; i++) {
            result = seed * result + value.charAt(i);
        }
        int r = (size - 1) & result;
        return (size - 1) & result;
    }
}
```

#### Guava 中的 BloomFilter

```java
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>23.0</version>
</dependency>

public class GuavaBloomFilterDemo {

    public static void main(String[] args) {
        //后边两个参数：预计包含的数据量，和允许的误差值
        BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), 100000, 0.01);
        for (int i = 0; i < 100000; i++) {
            bloomFilter.put(i);
        }
        System.out.println(bloomFilter.mightContain(1));
        System.out.println(bloomFilter.mightContain(2));
        System.out.println(bloomFilter.mightContain(3));
        System.out.println(bloomFilter.mightContain(100001));

        //bloomFilter.writeTo();
    }
}
```

#### SpringBoot

[(287条消息) SpringBoot + Redis实现布隆过滤器拦截无效请求_Toner_唐纳的博客-CSDN博客_布隆过滤器拦截](https://blog.csdn.net/qq_37012496/article/details/106375261)

## 6. 限流

限流目的：

1. 系统处理能力有限，阻止计划外的请求对系统施压。
2. 控制用户行为，避免垃圾请求。

### Redis实现限流

限定用户的某个行为在指定的时间里只能允许发生 N 次。

使用ZSET，通过滑动窗口的形式来计算指定时间内请求的次数。

![image-20221114092907767](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114092907767.png)

通过score的range可以查看单位时间内用户操作的次数。

```java
public Response limitFlow(){
 Long currentTime = new Date().getTime();
 System.out.println(currentTime);
 if(redisTemplate.hasKey("1001")) {
 Integer count = redisTemplate.opsForZSet().rangeByScore("1001", currentTime -  intervalTime, currentTime).size();        // intervalTime是限流的时间 
 System.out.println(count);
 if (count != null && count > 5) {
 return Response.ok("每分钟最多只能访问5次");
 }
 }
 redisTemplate.opsForZSet().add("limit",UUID.randomUUID().toString(),currentTime);
 return Response.ok("访问成功");
 }

```

其他实现方式：[Redis的三种限流方法_fking86的博客-CSDN博客_redis限流](https://fking.blog.csdn.net/article/details/109967406?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-109967406-blog-107744599.pc_relevant_multi_platform_whitelistv4&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-109967406-blog-107744599.pc_relevant_multi_platform_whitelistv4&utm_relevant_index=1)

### 漏斗限流

#### Java实现

![image-20221114095843081](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114095843081.png)

```java
package redis.限流算法;

import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * 漏斗限流算法
 */
public class FunnelRateLimiter {
    private Map<String, Funnel> funnelMap = new ConcurrentHashMap<>();

    public static void main(String[] args) throws InterruptedException {
        FunnelRateLimiter limiter = new FunnelRateLimiter();
        int testAccessCount = 30;//测试次数
        int capacity = 5;//漏斗容量
        int allowQuota = 5;//漏斗流动比率
        int perSecond = 30;//流动速率
        int allowCount = 0;//允许次数
        int denyCount = 0;//拒绝次数
        for (int i = 0; i < testAccessCount; i++) {
            boolean isAllow = limiter.isActionAllowed("dadiyang", "doSomething", 5, 5, 30);
            if (isAllow) {
                allowCount++;
            } else {
                denyCount++;
            }
            System.out.println("访问权限：" + isAllow);
            Thread.sleep(1000);
        }
        System.out.println("报告：");
        System.out.println("漏斗容量：" + capacity);
        System.out.println("漏斗流动速率：" + allowQuota + "次/" + perSecond + "秒");
        System.out.println("测试次数=" + testAccessCount);
        System.out.println("允许次数=" + allowCount);
        System.out.println("拒绝次数=" + denyCount);
    }

    /**
     * 根据给定的漏斗参数检查是否允许访问
     *
     * @param username   用户名
     * @param action     操作
     * @param capacity   漏斗容量
     * @param allowQuota 每单个单位时间允许的流量
     * @param perSecond  单位时间（秒）
     * @return 是否允许访问
     */
    public boolean isActionAllowed(String username, String action, int capacity, int allowQuota, int perSecond) {
        String key = "funnel:" + action + ":" + username;
        if (!funnelMap.containsKey(key)) {
            funnelMap.put(key, new Funnel(capacity, allowQuota, perSecond));
        }
        Funnel funnel = funnelMap.get(key);
        return funnel.watering(1);
    }

    private static class Funnel {
        private int capacity;
        private float leakingRate;
        private int leftQuota;
        private long leakingTs;

        public Funnel(int capacity, int count, int perSecond) {
            this.capacity = capacity;
            // 因为计算使用毫秒为单位的
            perSecond *= 1000;
            this.leakingRate = (float) count / perSecond;
        }

        /**
         * 根据上次水流动的时间，腾出已流出的空间
         */
        private void makeSpace() {
            long now = System.currentTimeMillis();
            long time = now - leakingTs;
            int leaked = (int) (time * leakingRate);
            if (leaked < 1) {
                return;
            }
            leftQuota += leaked;
            // 如果剩余大于容量，则剩余等于容量
            if (leftQuota > capacity) {
                leftQuota = capacity;
            }
            leakingTs = now;
        }

        /**
         * 漏斗漏水
         *
         * @param quota 流量
         * @return 是否有足够的水可以流出（是否允许访问）
         */
        public boolean watering(int quota) {
            makeSpace();
            int left = leftQuota - quota;
            if (left >= 0) {
                leftQuota = left;
                return true;
            }
            return false;
        }
    }
}
 
```

Funnel 对象的 make_space 方法是漏斗算法的核心，其在每次灌水前都会被调用以触发漏水，给漏斗腾出空间来。能腾出多少空间取决于过去了多久以及流水的速率。Funnel 对象占据的空间大小不再和行为的频率成正比，它的空间占用是一个常量。

#### redis实现

将 Funnel 对象的内容按字段存储到一个hash结构中，灌水的时候将 hash 结构的字段取出来进行逻辑运算后，再将新值回填到hash 结构中就完成了一次行为频度的检测。但是有个问题，我们无法保证整个过程的原子性。从 hash 结构中取值，然后在内存里运算，再回填到 hash 结构，这三个过程无法原子化，意味着需要进行适当的加锁控制。而一旦加锁，就意味着会有加锁失败，加锁失败就需要选择重试或者放弃。

如果重试的话，就会导致性能下降。如果放弃的话，就会影响用户体验。同时，代码的复杂度也跟着升高很多。

**redis4.0提供漏斗算法 4.0以上版本**

Redis 4.0 提供了一个限流 Redis 模块，它叫 redis-cell。该模块也使用了漏斗算法，并**提供了原子的限流指令**。

> 命令格式：cl.throttle  key名字   令牌桶容量-1   令牌产生个数   令牌产生时间 本次取走的令牌数 （不写时默认1，负值表放入令牌）
>
> 返回格式：
>
>  cl.throttle user 15 30 60 1
>
> > 1) (integer) 0    # 0 表示允许，1表示拒绝
> > 2) (integer) 16   # 漏斗总容量+1
> > 3) (integer) 15   # 漏斗剩余空间
> > 4) (integer) -1   # 如果拒绝了，需要多长时间后再试(漏斗有空间了，单位秒)
> > 5) (integer) 2    # 表示多久后令牌桶中的令牌会存满(单位秒)

频率为每 60s 最多 30 次(漏水速率)，漏斗的初始容量为 15，也就是说一开始可以连续回复 15 个帖子，然后才开始受漏水速率的影响。我们看到这个指令中漏水速率变成了 2 个参数，替代了之前的单个浮点数。

在执行限流指令时，如果被拒绝了，就需要丢弃或重试。cl.throttle 指令考虑的非常周到，连重试时间都帮你算好了，直接取返回结果数组的第四个值进行 sleep 即可，如果不想阻塞线程，也可以异步定时任务来重试。

**安装：**

redis-cell是一个插件，需要下载安装。

[Releases · brandur/redis-cell (github.com)](https://github.com/brandur/redis-cell/releases)

![image-20221114121720249](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114121720249.png)

解压：tar -zxvf redis-cell-v0.3.0-x86_64-unknown-linux-gnu.tar.gz          

配置conf文件，添加以下内容（loadmodule libredis_cell.so的路径）：loadmodule /data/plus/libredis_cell.so                 

重启redis即可。

查看是否安装成功：cli进入redis后，执行module list，可看到redis-cell模块。

### 令牌桶算法

每访问一次请求的时候，可以从Redis中获取一个令牌，如果拿到令牌了，那就说明没超出限制，而如果拿不到，则结果相反。

令牌桶算法提及到输入速率和输出速率，当输出速率大于输入速率，那么就是超出流量限制了。

可以在filter或者aop中配置策略。

```java
   // 输出令牌
   public Response limitFlow2(Long id){
        Object result = redisTemplate.opsForList().leftPop("limit_list");
        if(result == null){
            return Response.ok("当前令牌桶中无令牌");
        }
        return Response.ok(articleDescription2);
    } 


    // 10S的速率往令牌桶中添加UUID，只为保证唯一性
    @Scheduled(fixedDelay = 10_000,initialDelay = 0)
    public void setIntervalTimeTask(){
        redisTemplate.opsForList().rightPush("limit_list",UUID.randomUUID().toString());
    } 
```

![image-20221114163113470](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114163113470.png)

1、判断有没有被限流惩罚，有则直接返回，无则进入下一步。

2、判断令牌桶是否存在，不存在则先创建令牌桶，然后扣减令牌返回，存在则进入下一步。

3、判断是否需要投放令牌，不需要则直接扣减令牌，需要则先投放令牌再扣减令牌。

4、判断扣减后的令牌数，如果小于0则返回限流，同时设置限流惩罚，如果大于等于0则进入下一步。

5、更新桶中的令牌数到Redis。

## 7. GeoHash

Redis 在 3.2 版本以后增加了地理位置 GEO 模块。

计算周围的人;

![image-20221114163847768](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114163847768.png)

使用关系数据库：select id from positions where x0-r < x < x0+r and y0-r < y < y0+r

需要在经纬度坐标加上双向复合索引 (x, y)，可以最大优化查询性能。

问题：数据库性能有限，在高并发场合，如果请求的人非常多，效率比较低。

**GeoHash实现：**

它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘。所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。然后对这些方格进行整数编码，越是靠近的方格编码越是接近。那如何编码呢？一个最简单的方案就是切蛋糕法。设想一个正方形的蛋糕摆在你面前，二刀下去均分分成四块小正方形，这四个小正方形可以分别标记为 00,01,10,11 四个二进制整数。然后对每一个小正方形继续用二刀法切割一下，这时每个小小正方形就可以使用 4bit 的二进制整数予以表示。然后继续切下去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。

编码之后，每个地图元素的坐标都将变成一个整数，通过这个整数可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程度就越小。对于「附近的人」这个功能而言，损失的一点精确度可以忽略不计。

详情参考文章：https://blog.csdn.net/usher_ou/article/details/122716877

## 8. Scan：筛选海量数据

### 字符串匹配

需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除 key。

**使用字符串匹配**

u1:userid，c1:courseId；

学生的选课信息：

```java
127.0.0.1:6379> set u1-c1 1
OK
127.0.0.1:6379> set u1-c2 1
OK
127.0.0.1:6379> set u1-c3 1
OK
127.0.0.1:6379> set u1-c4 1
OK
127.0.0.1:6379> set u2-c1 1
OK
127.0.0.1:6379> set u2-c3 1
OK
127.0.0.1:6379> set u3-c1 1
OK
127.0.0.1:6379> set u4-c1 1
//获取选u1的选课信息
127.0.0.1:6379> keys u1-c*
1) "u1-c1"
2) "u1-c3"
3) "u1-c4"
4) "u1-c2"
//获取选择c1课程用户信息
127.0.0.1:6379> keys u*c1
1) "u4-c1"
2) "u3-c1"
3) "u1-c1"
4) "u2-c1"
```

**问题：**

1. 没有 offset、limit 参数，一次性吐出所有满足条件的 key,如果满足的key比较多，降低传输速率。
2. keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错，因为Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续

### scan基本使用

**特点：**scan 相比keys 具备有以下特点:

1、复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;

**2、提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少;**

3、同 keys 一样，它也提供模式匹配功能;

4、服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数;

5、**返回的结果可能会有重复，需要客户端去重复，这点非常重要;**

6、遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;

7、单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;

scan 参数提供了三个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三个是遍历的 limit hint。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。

 scan 0 match key99* count 1000

**使用：**

批量添加数据：https://blog.csdn.net/weixin_41677422/article/details/108626587

```java
 Map<String,Integer> keys = new HashMap<>();
        for (int i = 1; i <=10000; i++) {
            String str1 = "user1-c"+i;
            String str2 = "user2-c"+i;
            keys.put(str1,1);
            keys.put(str2,1);
        }
        redisTemplate.opsForValue().multiSet(keys);
```

**命令：**

 scan 0 match user1-c* count 1000

```java
1) "32208"
2)   1) "user1-c8506"
     2) "user1-c8657"
     3) "user1-c3984"
     4) "user1-c7815"
     5) "user1-c6278"
     6) "user1-c6254"
     7) "user1-c8514"
     8) "user1-c264"
     9) "user1-c7740"
```

scan 32008 match user1-c* count 1000                                                                                                                                                                                                                        

```java
1) "1464"                                                                                                                                                                                                                                                                   
2) 1) "user1-c7383"                                                                                                                                                                                                                                                       
   2) "user1-c7729"                                                                                                                                                                                                                                      
   3) "user1-c3169"                                                                                                                                                                                                                                                       
   4) "user1-c6614"                                                                                                                                                                                                                                                       
   5) "user1-c8633"                                                                                                                                                                                                                                                       
   6) "user1-c7440"                                                                                                                                                                                                                                                       
   7) "user1-c1604"                                                                                                                                                                                                                                                       
   8) "user1-c4434"                                                                                                                                                                                                                                                       
   9) "user1-c6236"                                                                                                                                                                                                                                                       
   10) "user1-c2290"                                                                                                                                                                                                                                                       
   11) "user1-c1856"                                                                                                                                                                                                                                                       
   12) "user1-c888"                                                                                                                                                                                                                                                        
   13) "user1-c8608"    
```

从上面的过程可以看到虽然提供的 limit 是 1000，但是返回的结果只有 10 个左右。因为这个 limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量(约等于)。如果将 limit 设置为 10，你会发现返回结果是空的，但是游标值不为零，意味着遍历还没结束。

### 字典结构

scan是通过hash的形式查找的

![image-20221114202955771](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114202955771.png)

scan 指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽 (slot)。。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。

**scan的遍历顺序**

scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。

**普通加法和高位进位加法的区别**

高位进位法从左边加，进位往右边移动，同普通加法正好相反。但是最终它们都会遍历所有的槽位并且没有重复。

**针对其他数据结构同样适用**

scan 指令是一系列指令，除了可以遍历所有的 key 之外，还可以对指定的容器集合进行遍历。比如 zscan 遍历 zset 集合元素，hscan 遍历 hash 字典的元素、sscan 遍历 set 集合的元素

### 大key 检测

进入redis容器（非直接进入redis-cli），使用：redis-cli -h 127.0.0.1 -p 6379 -a PASSWORD --bigkeys   

| 名称      | 说明                  |
| :-------- | :-------------------- |
| -h        | 指定Redis的连接地址。 |
| -a        | 指定Redis的认证密码。 |
| --hotkeys | 用来查询热点Key。     |
| --bigkeys | 用来查询大Key。       |

推荐文章：

[Redis 4.0热点Key查询方法 (aliyun.com)](https://help.aliyun.com/document_detail/101108.html)

[发现并处理Redis的大Key和热Key (aliyun.com)](https://help.aliyun.com/document_detail/353223.html)

# Redis原理

## 1. 操作系统的IO模型

redis是单线程，nginx，node.js都是单线程。

**redis单线程还这么快的原因**

redis速度快原因在于redis操作的是内存，因为是单线程的，因此对于复杂度为O（n）的指令要谨慎执行。

**Redis** **单线程如何处理那么多的并发客户端连接？**

redis使用的是非阻塞IO，通过多路复用来处理多个客户端发送的链接。

### 同步阻塞 IO 模型

假设应用程序的进程发起 **IO 调用**，但是如果**内核的数据还没准备好**的话，那应用程序进程就一直在**阻塞等待**，一直等到内核数据准备好，直到内核拷贝到用户空间，才返回成功提示，此次 IO 操作，称之为**阻塞 IO**。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071111906.webp)](https://mynotepicture.oss-cn-hangzhou.aliyuncs.com/img/202211071111906.webp)

> - 阻塞 IO 比较经典的应用就是**阻塞 socket、Java BIO**。
> - 阻塞 IO 的缺点就是：如果内核数据一直没准备好，那用户进程将一直阻塞，**浪费性能**，可以使用**非阻塞 IO** 优化。

### 同步非阻塞 IO 模型

如果内核数据还没准备好，可以先返回错误信息给用户进程，让它不需要等待，通过轮询的方式再来请求，这就是非阻塞 IO，流程图如下：

![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071114171.webp)

非阻塞 IO 的流程如下：

- 应用进程向操作系统内核，发起 `recvfrom` 读取数据。
- 操作系统内核数据没有准备好，立即返回 `EWOULDBLOCK` 错误码。
- 应用程序轮询调用，继续向操作系统内核发起 `recvfrom` 读取数据。
- 操作系统内核数据准备好了，从内核缓冲区拷贝到用户空间。
- 完成调用，返回成功提示。

非阻塞 IO 模型，简称 **NIO**，`Non-Blocking IO`。它相对于阻塞 IO，虽然大幅提升了性能，但是它依然存在**性能问题**，即**频繁的轮询**，导致频繁的系统调用，同样会消耗大量的 CPU 资源。可以考虑 **IO 复用模型**，去解决这个问题。

### IO 多路复用模型

IO 复用模型核心思路：系统给我们提供**一类函数**（如我们耳濡目染的 **select、poll、epoll** 函数），它们可以同时监控多个文件描述符的操作，并在其中某个文件描述符可读写时由操作系统唤醒阻塞等待的线程。

> I/O 复用其实复用的不是 I/O 连接，而是复用线程，让线程能够监听多个连接（I/O 事件）。
>
> 文件描述符（fd）：它是计算机科学中的一个术语，形式上是一个非负整数。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

#### IO 多路复用之 select

应用进程通过调用 select 函数，可以同时监控多个 `fd`，当有 fd 准备就绪时，select 返回数据可读状态，应用程序再调用 recvfrom 读取数据。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071138127.webp)](https://mynotepicture.oss-cn-hangzhou.aliyuncs.com/img/202211071138127.webp)

非阻塞 IO 模型（NIO）中，需要 `N`（N>=1）次轮询系统调用，然而借助 `select` 的 IO 多路复用模型，只需要发起一次系统调用就够了，大大优化了性能。

但是呢，`select` 有几个缺点：

- 监听的 IO 最大连接数有限，在 Linux 系统上一般为 1024。
- select 函数返回后，是通过遍历 `fdset`，找到就绪的描述符 `fd`。

因为**存在连接数限制**，所以后来又提出了 **poll**。与 select 相比，**poll** 解决了**连接数限制问题**。但是呢，select 和 poll 一样，还是需要通过遍历文件描述符来获取已经就绪的 `socket`。如果同时连接的大量客户端在一时刻可能只有极少处于就绪状态，伴随着监视的描述符数量的增长，**效率也会线性下降**。

因此经典的多路复用模型 `epoll` 诞生。

#### IO 多路复用之 epoll

为了解决 `select/poll` 存在的问题，多路复用模型 `epoll` 诞生，它采用事件驱动来实现，流程图如下：

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071139505.webp)

**epoll** 先通过 `epoll_ctl()` 来注册一个 `fd`（文件描述符），一旦基于某个 `fd` 就绪时，内核会采用回调机制，迅速激活这个 `fd`，当进程调用 `epoll_wait()` 时便得到通知。这里去掉了**遍历文件描述符**的坑爹操作，而是采用**监听事件回调**的的机制。这就是 epoll 的亮点。

select、poll、epoll 的区别：

|               | **select**                                              | **poll**                                              | **epoll**                                                    |
| ------------- | ------------------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| 底层数据结构  | 数组                                                    | 链表                                                  | 红黑树和双链表                                               |
| 获取就绪的 fd | 遍历                                                    | 遍历                                                  | 事件回调                                                     |
| 事件复杂度    | O(n)                                                    | O(n)                                                  | O(1)                                                         |
| 最大连接数    | 1024                                                    | 无限制                                                | 无限制                                                       |
| fd 数据拷贝   | 每次调用 select，需要将 fd 数据从用户空间拷贝到内核空间 | 每次调用 poll，需要将 fd 数据从用户空间拷贝到内核空间 | 使用内存映射 (mmap)，不需要从用户空间频繁拷贝 fd 数据到内核空间 |

**epoll** 明显优化了 IO 的执行效率，但在进程调用 `epoll_wait()` 时，仍然可能被阻塞的。能不能这样：不用我老是去问你数据是否准备就绪，等我发出请求后，你数据准备好了通知我就行了，这就诞生了**信号驱动 IO 模型**。

### IO 模型之信号驱动模型

信号驱动 IO 不再用主动询问的方式去确认数据是否就绪，而是向内核发送一个信号（调用 `sigaction` 的时候建立一个 `SIGIO` 的信号），然后应用用户进程可以去做别的事，不用阻塞。当内核数据准备好后，再通过 `SIGIO` 信号通知应用进程。应用用户进程收到信号之后，立即调用 `recvfrom`，去读取数据。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071141603.webp)

信号驱动 IO 模型，在应用进程发出信号后，是立即返回的，不会阻塞进程。它已经有异步操作的感觉了。但是你细看上面的流程图，**发现数据复制到应用缓冲的时候**，应用进程还是阻塞的。回过头来看下，不管是 BIO，还是 NIO，还是信号驱动，在数据从内核复制到应用缓冲的时候，都是阻塞的。还有没有优化方案呢？**AIO**（真正的异步 IO）！

### IO 模型之异步 IO (AIO)

前面讲的 `BIO，NIO和信号驱动`，在数据从内核复制到应用缓冲的时候，都是**阻塞**的，因此都不是真正的异步。`AIO` 实现了 IO 全流程的非阻塞，就是应用进程发出系统调用后，是立即返回的，但是**立即返回的不是处理结果，而是表示提交成功类似的意思**。等内核数据准备好，将数据拷贝到用户进程缓冲区，发送信号通知用户进程 IO 操作执行完毕。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071142114.webp)](https://mynotepicture.oss-cn-hangzhou.aliyuncs.com/img/202211071142114.webp)



异步 IO 的优化思路很简单，只需要向内核发送一次请求，就可以完成数据状态询问和数据拷贝的所有操作，并且不用阻塞等待结果。日常开发中，有类似的业务场景：

> 比如发起一笔批量转账，但是转账处理比较耗时，这时候后端可以先告知前端转账提交成功，等到结果处理完，再通知前端结果即可。

总结：

- 阻塞 IO 就是那种[ recv](https://www.zhihu.com/search?q=recv&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A14413599}), read，一直等，等到有了数据才返回；
- 非阻塞 IO 就是立即返回，设置描述符为非阻塞，但是要进程自己一直检查是否可读；
- IO 复用其实也是阻塞的，不过可以用来等很多描述符，比起阻塞有了进步，可以算有点异步了，但需要阻塞着检查是否可读。**对同一个描述符的 IO 操作也是有序的。**
- 信号驱动采用[信号机制](https://www.zhihu.com/search?q=信号机制&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A14413599})等待，有了更多的进步，不用监视描述符了，而且不用阻塞着等待数据到来，被动等待信号通知，由[信号处理程序](https://www.zhihu.com/search?q=信号处理程序&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A14413599})处理。**但对同一个描述符的 IO 操作还是有序的。**
- 异步 IO，发送 IO 请求后，不用等了，也不再需要发送 IO 请求获取结果了。等到通知后，其实是系统帮你把数据读取好了的，**你等到的通知也不再是要求你去读写 IO 了，而是告诉你 IO 请求过程已经结束了**。你要做的就是可以处理数据了。且同一个描述符上可能同时存在很多请求。

#### 指令队列和响应队列

指令队列：Redis 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。

响应队列：Redis 同样也会为每个客户端套接字关联一个响应队列。Redis 服务器通过响应队列来将指令的返回结果回复给客户端。 如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符从 write_fds 里面移出来。等到队列有数据了，再将描述符放进去。避免 select 系统调用立即返回写事件，结果发现没什么数据可以写。出这种情况的线程会飙高 CPU。

## 2. 持久化

两种持久化机制：RDB和AOF。

**RDB：**快照，全量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑。

**AOF: **增量备份，记录的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。

### RDB

快照，全量备份。

记录内存中的数据在某一时刻的状态，进行全量快照，会将内存中所有的数据都记录到磁盘中。即使服务器宕机，快照文件也不会丢失，恢复时只需要将文件读到内存即可。

在进行快照的时候是全量快照，会将内存中所有的数据都记录到磁盘中，这就有可能会阻塞主线程的执行。

Redis提供了两个命令来生成RDB文件，分别是**save**和**bgsave**：

- save：在主线程中执行，会导致阻塞；

- bgsave：会创建一个子进程，该进程专门用于写入RDB文件，可以避免主线程的阻塞，也是默认的方式。

可以采用bgsave的命令来执行全量快照，提供了数据的可靠性保证，也避免了对Redis的性能影响

问题：执行快照期间数据能不能修改呢?

如果不能修改，快照过程中如果有新的写操作，数据就会不一致，这肯定是不符合预期的。Redis借用了操作系统的**写时复制**，在执行快照的期间，正常处理写操作。

主要流程：

- bgsave子进程是由主线程fork出来的，可以共享主线程的所有内存数据。

- bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入RDB文件中。

- 如果主线程对这些数据都是读操作，例如A，那么主线程和bgsave子进程互不影响。

- 如果主线程需要修改一块数据，如C，这块数据会被复制一份，生成数据的副本，然主线程在这个副本上进行修改；bgsave子进程可以把原来的数据C写入RDB文件。

![image-20221115150441025](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115150441025.png)

**多久进行一次快照？**

理论上来说快照时间间隔越短越好，可以减少数据的丢失，毕竟fork的子进程不会阻塞主线程，但是频繁的将数据写入磁盘，会给磁盘带来很多压力，也可能会存在多个快照竞争磁盘带宽（当前快照没结束，下一个就开始了）。另一方面，虽然fork出的子进程不会阻塞，但fork这个创建过程是会阻塞主线程的，当主线程需要的内存越大，阻塞时间越长。

**增量快照**

在做一次全量快照后，后续的快照只对修改的数据进行记录，需要记住哪些数据被修改了，可以避免全量快照带来的开销。

### AOF

AOF日志是写后日志，也就是Redis先执行命令，然后将数据写入内存，最后才记录日志。

AOF日志中记录的是Redis收到的每一条命令，这些命令都是以文本的形式保存的。

AOF为了避免额外的检查开销，并不会检查命令的正确性，因此需要先执行命令，再写日志。执行命令后再写日志，不会阻塞当前写操作。

**风险：**

1. 命令执行后，redis宕机了，日志没有写入。
2. AOF可以避免对当前命令的阻塞（因为是先写入再记录日志），但有可能会对下一次操作带来阻塞风险（可能存在写入磁盘较慢的情况）

**写入磁盘的机制**

![image-20221115142422728](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115142422728.png)

- Always可靠性较高，数据基本不丢失，但是对性能的影响较大。

- Everysec性能适中，即使宕机也只会丢失1秒的数据。

- No性能好，但是如果宕机丢失的数据较多。

问题：

1. AOF是通过文件的形式记录所写的命令，指令越多，文件会越来越大，最后超过文件的限制。
2. 文件较大时，写入命令效率会降低，如果发生宕机，AOF所有命令需要重新执行，数据越大恢复时间越长。

AOF提供了重写机制，可以解决文件过大问题。

#### **AOF的重写机制**

AOF重写就是根据所有的键值对创建一个新的AOF文件，可以减少大量的文件空间。

减少的原因是：AOF对于命令的添加是追加的方式，逐一记录命令，但有可能存在某个键值被反复更改，产生了一些冗余数据，这样在重写的时候就可以过滤掉这些指令，从而更新当前的最新状态。

Redis 提供了 bgrewriteaof 指令用于AOF重写。可以避免阻塞主进程导致性能下降。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中（重写的过程中，发生数据的写或修改操作，会先把数据写入缓冲区，最后追加到新的AOF中），追加完毕后就立即替代旧的 AOF 日志文件了。

#### fsync

AOF写日志时，实际将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核将日志刷新到磁盘。

问题：

如果redis突然宕机，内存中的内容还没来得及刷新磁盘，此时会出现日志丢失。

解决：

Linux 的 glibc 提供了 fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个

磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。

在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能

使得数据少丢失。Redis 同样也提供了另外两种策略，一个是永不 fsync——让操作系统来决定合适同步磁盘，很不安全，另一个是来一个指令就 fsync 一次——非常慢。

### 混合使用

```java
# aof‐use‐rdb‐preamble yes
```

跟AOF相比，RDB快照的恢复速度快，但快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销

**在Redis4.0提出了混合使用AOF和RDB快照的方法，也就是两次RDB快照期间的所有命令操作由AOF日志文件进行记录。这样的好处是RDB快照不需要很频繁的执行，可以避免频繁fork对主线程的影响，而且AOF日志也只记录两次快照期间的操作，不用记录所有操作，也不会出现文件过大的情况，避免了重写开销。既可以享受RDB快速恢复的好处，也可以享受AOF记录简单命令的优势。**

如果开启了混合持久化，AOF在重写时，将重写这一刻之前的内存做RDB快照处理并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件，新的文件一开始不叫appendonly.aof,等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。在Redis重启的时候，可以先加载RDB的内容，然后再重放增量AOF日志就可以完全替代之前的AOF全量文件重放，因此重启效率大幅得到提升.

　　![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/1460613-20210226225333335-1001578826.png)

 

**对于AOF和RDB的选择问题**：

- 数据不能丢失时，内存快照和AOF的混合使用是一个很好的选择。

- 如果允许分钟级别的数据丢失，可以只使用RDB。

- 如果只用AOF，优先使用everysec的配置选项，因为它在可靠性和性能之间取了一个平衡。

 **Redis 数据备份策略**

1. 写crontab 定时调度脚本，每小时copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份
2. 每天都保留一份当日的数据备份到一个目录中去，可以保留最近一个月的备份
3. 每次copy备份的时候，都把太旧的备份给删了
4. 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏

## 3. Redis主从架构

### CAP原理

分区容错性，一致性，可用性。

在分区容错性的前提下，一致性和可用性只能实现其一，网络分区发生时，一个节点的数据修改不能同步到另一个节点，因此一致性无法满足，除非牺牲可用性，即关闭子服务，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。

**最终一致**

Redis 保证「**最终一致性**」，从节点会努力追赶主节点，最终从节点的状态会和主节点的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢

复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致

### 主从同步

![image-20221115154048532](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115154048532.png)

#### 增量同步

Redis 同步的是指令流，主节点会将产生修改性影响的指令记录在本地的内存 buffer 中，然后异步将 buffer 中的指令同步到从节点，从节点一边执行同步的指令流来达到和主节点一样的状态，一遍向主节点反馈自己同步到哪里了 (偏移量)。

内存的 buffer 是有限的，所以 Redis 主库不能将所有的指令都记录在内存 buffer 中。Redis 的复制内存 buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容、

如果网络状况不好，从节点在短时间内无法和主节点进行同步，那么当网络状况恢复时，Redis 的主节点中那些没有同步的指令在 buffer 中有可能已经被后续的指令覆盖掉了，从节点将无法直接通过指令流来进行同步，这个时候就需要快照同步。

#### 快照同步

**Redis 主从工作原理**

1. 如果你为master配置了一个slave,不管这个slave是否是第一次连接上Master,它都会发送一个PSYNC命令给master请求复制数据。
2. master收到PSYNC命令后，会在后台进行数据持久化通过bgsave生成最新的rdb快照文件，持久化期间，master会继续接受客户端的请求，他会把这些可能修改的数据集的请求缓存在buffer中，当持久化进行完毕以后，master会将buffer发送给slave。
3. salve加载之前先要将当前内存的数据清空，之后把收到的数据进行持久化生成rdb,然后再加载到内存中。加载完毕后通知主节点继续进行增量同步。然后，master再将之前缓存在buffer中的命令发送给slave.
4. 当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多个slave并发连接请求，他只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave

**注意：**

如果全量备份时间过长或buffer过小，都会导致同步期间的增量指令在复制 buffer 中被覆盖，这样就会导致快照同步完成后无法进行增量复制，然后会再次发起快照同步，如此极有可能会陷入快照同步的死循环。以务必配置一个合适的复制 buffer 大小参数，避免快照复制的死循环。

当从节点刚刚加入到集群时，它必须先要进行一次快照同步，同步完成后再继续进行增量同步。

**主从复制流程图：**

![image-20221115154521199](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115154521199.png)

#### 无盘复制

快照同步时，会进行很重的IO操作，对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响

当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率

无盘复制：

无磁盘化复制是master不会将RDB文件落到本地磁盘，会将RDB文件直接从内存中通过网络传输到slave的内存中。如果我们的服务器使用的是普通的机械硬盘（重点是磁盘的读写效率很低），而且内网的网络带宽又很高（内网网速快），那么完全可以使用这种无磁盘化的复制方式。

```java
# 开启redis的无磁盘化复制，默认是关闭的
repl-diskless-sync yes
# 这一点很重要，因为一旦传输开始，就不可能服务新的从服务器到达，它将排队等待下一次RDB传输，所以服
# 务器等待延迟以便让更多的从节点到达。延迟以秒为单位指定，默认为5秒。禁用它完全只是设置为0秒，传
# 输将尽快开始。
repl-diskless-sync-delay 5
```





## 4. 管道

客户端通过对管道中的指令列表改变读写顺序就可以大幅节省 IO 时间。管道中指令越多，效果越好。

详细看redis深度历险

## 5. 事务

### 基本使用

每个事务的操作都有 begin、commit 和 rollback，begin 指示事务的开始，commit 指示事务的提交，rollback 指示事务的回滚。 

Redis 事务操作分别是 multi/exec/discard。multi 指示事务的开始，exec 指示事务的执行，discard 指示事务的丢弃。

```java
127.0.0.1:6379> multi
OK
127.0.0.1:6379(TX)> incr book
QUEUED
127.0.0.1:6379(TX)> incr book
QUEUED
127.0.0.1:6379(TX)> exec
1) (integer) 1
2) (integer) 2
127.0.0.1:6379> get book
"2"
```

> 所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。
>
> QUEUED 是一个简单字符串，同 OK 是一个形式，它表示指令已经被服务器缓存到队列里了。
>
>  Redis 的单线程特性，它不用担心自己在执行队列的时候被其它指令打搅，可以保证他们能得到的「原子性」执行。

```java
127.0.0.1:6379> multi
OK
127.0.0.1:6379(TX)> incr num
QUEUED
127.0.0.1:6379(TX)> incr num
QUEUED
127.0.0.1:6379(TX)> incr num
QUEUED
127.0.0.1:6379(TX)> discard
OK
127.0.0.1:6379> get num
(nil)
discard后，队列中的所有指令都没执行。
```

### 优化

 Redis 事务在发送每个指令到事务缓存队列时都要经过一次网络读写，当一个事务内部的指令较多时，需要的网络 IO 时间也会线性增长。所以通常 Redis 的客户端在执行事务时都会结合 pipeline 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作。

```java
pipe = redis.pipeline(transaction=true)
pipe.multi()
pipe.incr("books")
pipe.incr("books")
values = pipe.execute()
```

### watch实现乐观锁

参照redis深度历险

## 6. **PubSub**

消息不会持久化，redis宕机消息就丢失了，没有合适的使用场景。

参照redis深度历险










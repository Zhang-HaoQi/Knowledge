# Redis基础

## 0. 学习资源

阿里云文档（进阶操作）：[性能排查与调优 (aliyun.com)](https://help.aliyun.com/document_detail/265988.html)

redis深度历险

## 1. Redis应用场景

1、记录帖子的点赞数、评论数和点击数 (hash)。

2、记录用户的帖子 ID 列表 (排序)，便于快速显示用户的帖子列表 (zset)。

3、记录帖子的标题、摘要、作者和封面信息，用于列表页展示 (hash)。

4、记录帖子的点赞用户 ID 列表，评论 ID 列表，用于显示和去重计数 (zset)。

5、缓存近期热帖内容 (帖子内容空间占用比较大)，减少数据库压力 (hash)。

6、记录帖子的相关文章 ID，根据内容推荐相关帖子 (list)。

7、如果帖子 ID 是整数自增的，可以使用 Redis 来分配帖子 ID(计数器)。

8、收藏集和帖子之间的关系 (zset)。

9、记录热榜帖子 ID 列表，总热榜和分类热榜 (zset)。

10、缓存用户行为历史，进行恶意行为过滤 (zset,hash)。

## 2. Redis数据结构

Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。

Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。

### String

![image-20221112093339578](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093339578.png)

![image-20221112093501306](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093501306.png)

Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的ArrayList，采用**预分配冗余空间**的方式来减少内存的频繁分配，如图中所示，**内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。**

用途：

1. 单一键值对存储
2. 批量键值对存储
3. int自增

### List

Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为

O(n)。当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。

Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。

用途：

添加数据：rpush books python java golang

1. 可作为队列使用，也可作为栈使用。

   1. 获取长度：  llen books  返回3
   2. 头部弹出数据： lpop books  返回python，队列操作
   3. 尾部弹出数据： rpop books  返回golang，栈操作

2. 慢操作：

   1. lindex books 1 ：获取books的list中索引为1的元素，返回java，复杂度O(n)

   2. lrange books 0 -1  ： 获取所有元素

   3.  ltrim books 1 -1 ：保留链表中第一个元素到倒数第一个元素，其他元素删除掉。返回 java golang

   4. ltrim books 1 0 ：清空元素，因为区间长度为负数

      ```java
      127.0.0.1:6379> rpush books python java golang
      (integer) 3
      127.0.0.1:6379> lrange books 0 -1
      1) "python"
      2) "java"
      3) "golang"
      127.0.0.1:6379> ltrim books 1 -1
      OK
      127.0.0.1:6379> lrange books 0 -1
      1) "java"
      2) "golang"
      127.0.0.1:6379> ltrim books 1 0
      OK
      127.0.0.1:6379> lrange books 0 -1
      (empty array)
      127.0.0.1:6379> 
      ```

3.  快速列表

   ![image-20221112100858789](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100858789.png)

   1. redis底层存储并不是一个简单的linkedlist，而是quicklist。
   2. 当元素较少时，将所有元素紧挨着存储，分配一块连续的内存空间，为压缩链表（ziplist）。
   3. 当元素较多时，将ziplist结合起来组成quicklist。ziplist之间使用双向链表串起来，满足快速插入和删除性能，不会出现太大的空间冗余。
      1. 如果元素与元素之间连接起来，指针占用内存空间，即浪费空间，又导致内存碎片化。

### Hash

类似Java的HashMap，数组+链表结构。

![image-20221112100956407](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100956407.png)

Redis 的字典的值只能是字符串，rehash 的方式不一样，因为Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 

为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。

![image-20221112143240585](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112143240585.png)

渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个hash 结构，然后在后续的定时任务中以及 hash 的子指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。

### Set

Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。

### ZSET（有序列表）

它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫着「跳跃列表」的数据结构。 

zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。

zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。

**跳跃列表**

zset 内部的排序功能是通过「跳跃列表」数据结构来实现的。

zset要支持随机插入和删除，数组不好表示。插入的元素要排序，要保证链表是有序的，可以通过二分查找快速找到插入点，但是二分查找只适用于数组。因此提出跳跃链表。

![image-20221112144321702](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112144321702.png)

跳跃链表：每个元素分为不同的等级，最低级是所有元素，之后依次向上挑选。

定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。

新插入的元素，采取随机策略来决定新元素可以兼职到第几层。

L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少Redis 数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。

### 数据类型通用规则

list/set/hash/zset 这四种数据结构是容器型数据结构，都满足一下规则：

1. 添加元素时，容器不存在则创建。
2. 删除元素时，容器中没有元素，立即删除元素。
3. 过期时间是以容器为单位的，而非容器中的某个元素。
   1. 如hash设置过期时间是整个hash的过期时间，而非其中一个key的过期时间。

注意：如果一个字符串设置了过期时间，如果再次修改他时，过期时间会失效。

```sql
127.0.0.1:6379> set name zhangsan ex 1000
OK
127.0.0.1:6379> ttl name
(integer) 993
127.0.0.1:6379> set name lisi
OK
127.0.0.1:6379> ttl name
(integer) -1
127.0.0.1:6379> 
127.0.0.1:6379> get name
"lisi"
```

# Redis应用

## 1. 分布式锁

### 分布式锁

使用set is not exits 命令占锁，占锁成功后执行业务，执行完成后释放锁del。

setnx lock true

问题：业务未执行完，发生异常，del没有执行，陷入死锁，锁永远得不到释放。

解决：为锁设置过期时间。

问题：业务时间过长，锁提前释放。业务再次执行时新添加锁，此时之前的业务执行完毕，将新业务的锁释放掉。

解决：

1. 分布式锁不要用于过长时间任务，如果出现了锁现象，数据小范围错乱人工干预。
2. 使用lua脚本，为每次加锁设置一个唯一的随机数，只能此随机数进行锁释放。（设置过期时间的话还有可能造成业务没执行完，锁提前释放问题-使用看门狗机制）

手写可重入锁

```java
@Component
@Log4j2
public class RedisLock {
  @Resource
  private RedisTemplate redisTemplate;
  private ThreadLocal<String> threadLock = new ThreadLocal<>();
  private ThreadLocal<Integer> threadLocalInteger = new ThreadLocal<Integer>();

  /**
   * @Description 加锁
   * @Date 2022/09/14 14:36
   * @Param [key, timeout, unit]
   * @return boolean
   */
  public boolean tryLock(String key, long timeout, TimeUnit unit) {
    Boolean isLocked = false;
    if (threadLock.get() == null) {
      String uuid = UUID.randomUUID() +"_"+System.currentTimeMillis();
      threadLock.set(uuid);
      isLocked = redisTemplate.opsForValue().setIfAbsent(key, uuid, timeout, unit);
      if(!isLocked){
        //
        for (;;) {
          isLocked = redisTemplate.opsForValue().setIfAbsent(key, uuid, timeout, unit);
          if (isLocked) {
            break;
          }
        }
      }
      //启动新线程来执行定时任务，更新锁过期时间
      new Thread(new UpdateLockTimeoutTask(uuid, redisTemplate, key)).start();
    } else {
      isLocked = true;
    }
    // 重入次数加1
    if (isLocked) {
      Integer count = threadLocalInteger.get() == null ? 0 : threadLocalInteger.get();
      threadLocalInteger.set(count++);
    }
    return isLocked;
  }
  /**
   * @Description 释放锁
   * @Date 2022/09/14 14:36
   * @Param [key]
   * @return void
   */
  public void releaseLock(String key) {
    //当前线程中绑定的uuid与Redis中的uuid相同
    String uuid= (String) redisTemplate.opsForValue().get(key);
    if(threadLock.get().equals(uuid)&&!StringUtils.isEmpty(uuid)){
      Integer count = threadLocalInteger.get();
      // 计数器减为0时才能释放锁
      if (count == null || --count <= 0) {
        redisTemplate.delete(key);
        // 获取更新锁超时时间的线程
        long threadId = (long) redisTemplate.opsForValue().get(uuid);
        Thread updateLockTimeoutThread = getThreadByThreadId(threadId);
        if (updateLockTimeoutThread != null) {
          // 中断更新锁超时时间的线程
          updateLockTimeoutThread.interrupt();
          redisTemplate.delete(uuid);
        }
      }
    }
  }

  /**
   * @Description 根据线程id获取线程对象
   * @Date 2022/09/14 14:36
   * @Param [threadId]
   * @return java.lang.Thread
   */
  public Thread getThreadByThreadId(long threadId) {
    ThreadGroup group = Thread.currentThread().getThreadGroup();
    Thread[] threads = new Thread[(int)(group.activeCount() * 1.2)];
    int current=0;
    if(group != null){
      int count = group.enumerate(threads, true);
      for (int i = 0; i < count; i++){
        if (threadId == threads[i].getId()) {
          current=i;
          break;
        }
      }
    }else {
      return null;
    }
    return threads[current];
  }
}


public class UpdateLockTimeoutTask implements Runnable{
  private String uuid;
  private String key;
  private RedisTemplate redisTemplate;

  //uuid=UUID.randomUUID() +"_"+System.currentTimeMillis();
  //key=userId+标识
  public UpdateLockTimeoutTask(String uuid, RedisTemplate redisTemplate, String key) {
    this.uuid = uuid;
    this.key = key;
    this.redisTemplate = redisTemplate;
  }

  @Override
  public void run() {
    // 将以uuid为Key，当前线程Id为Value的键值对保存到Redis中
    redisTemplate.opsForValue().set(uuid, Thread.currentThread().getId());
    while (true) {
      // 更新锁的过期时间，30秒更新一次
      redisTemplate.expire(key, 30, TimeUnit.SECONDS);
      try{
        // 每隔10秒执行一次;
        Thread.sleep(1000*10);
      }catch (InterruptedException e){
        break;
      }
    }
  }
}
```



## 2. 异步消息队列

### 异步队列实现

**list实现队列**

对比消息中间件，redis队列没有非常多的高级特性，没有ack保证，如果对消息的可靠性要求较高，不建议使用。

Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用 lpop 和 rpop 来出队列。

![image-20221112151839587](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112151839587.png)

rpush入队，lpop出队。

lpush入队，rpop出队。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> lpop fruit
"apple"
127.0.0.1:6379> lpop fruit
"banana"
127.0.0.1:6379> lpop fruit
"pear"
127.0.0.1:6379> lpop fruit
"orange"
127.0.0.1:6379> lpop fruit
(nil)
```

使用pop获取消息后，进行处理，处理完毕后继续获取。while循环的方式。

如果队列为null，则进行一段睡眠后再pop，降低redis的qps和客户端的cpu占用。

**阻塞读**

问题：一个消费者延迟就是1s，如果是多个消费者，彼此的延迟都是岔开的，实际延迟可能不到1s就有消费者又尝试获取

解决：使用阻塞读 blpop/brpop

阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "apple"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "banana"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "pear"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "orange"
127.0.0.1:6379> blpop fruit 10   //10s后，如果还没有数据，则结束。
(nil)   
(10.07s)
```

注意：如果线程一直闲置在哪里，超过阻塞的时间，redis的客户端连接就成了闲置连接，服务器一端会主动断开链接，减少闲置资源占用，此时blpop/brpop会抛出异常。因此编写客户端要注意捕获异常和重试。

### 加锁失败的处理方式

1. 直接抛出异常，通知用户之后重试
2. sleep一会重试
   1. 如果请求过多，如果一个请求产生死锁，导致之后的请求都无法运行。
3. 请求移交到延时队列，过一会再试。

### 延时队列实现

延时队列可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。

详细实现参考书籍。

## 3. 位图

### 基本使用

开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。

Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下。

位图详解:[Redis bitmap位图操作（图解） (biancheng.net)](http://c.biancheng.net/redis/bitmap.html)

语法：SETBIT key 位 值（0或1）

位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。

**通过位图打印hello**

接下来我们使用位操作将字符串设置为 hello (不是直接使用 set 指令)，首先我们需要得到 hello 的 ASCII 码，用 Python 命令行可以很方便地得到每个字符的 ASCII 码的二进制值。

![image-20221112161807776](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112161807776.png)

```java
127.0.0.1:6379> setbit user:2 1 1
(integer) 0
127.0.0.1:6379> setbit user:2 2 1
(integer) 0
127.0.0.1:6379> setbit user:2 4 1
(integer) 0
127.0.0.1:6379> setbit user:2 9 1
(integer) 0
127.0.0.1:6379> setbit user:2 10 1
(integer) 0
127.0.0.1:6379> setbit user:2 13 1
(integer) 0
127.0.0.1:6379> setbit user:2 15 1
(integer) 0
127.0.0.1:6379> get user:2
"he"
```

如果对应位的字节是不可打印字符，redis-cli 会显示该字符的 16 进制形式。

```java
127.0.0.1:6379> setbit user:3 0 1
(integer) 0
127.0.0.1:6379> setbit user:3 2 1
(integer) 0
127.0.0.1:6379> get user:3
"\xa0"
```

### 统计查找

使用bitcount计算字节中1的个数（注意，bitcount是以字节为单位的）

```java
127.0.0.1:6379> bitcount user:2  key user:2中一共有7个1。
(integer) 7
127.0.0.1:6379> bitcount user:2 0 0 key user:2中第一个字节有3个1。
(integer) 3
127.0.0.1:6379> bitcount user:2 0 1  key user:2中前两个字节有7个1。
(integer) 7
```

使用bitpos 用来查找指定范围内出现的第一个 0 或 1

```java
127.0.0.1:6379> bitpos user:2 0  # 第一个 0 位
(integer) 0
127.0.0.1:6379> bitpos user:2 1 # 第一个 1 位
(integer) 1
127.0.0.1:6379> bitpos user:2 1 1 1 # 从第二个字符算起，第一个 1 位
(integer) 9
127.0.0.1:6379> bitpos user:2 1 2 2   # 从第三个字符算起，第一个 1 位
(integer) -1
```

### 魔数指令bitfield

看书

## 4. HyperLogLog

### 统计网站数据

统计**网站每个网页**一天的PV和UV数据。

PV：页面一天访问量（用户每访问一次加一次）  

**解决：**给每个网页设计一个redis计数器，接口请求一次，incrby一次即可。

UV：页面一天访客量（一个用户每天最多纪录一次）

**解决：**

分析：要去重，同一个用户一天之内的多次访问请求只能计数一次。每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一ID 来标识

实现：

为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。

问题：

如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。

另外这些数据不需要太精确，没有必要为这样一个去重功能浪费这么大的内存空间。

### HyperLogLog 

HyperLogLog 提供不精确的去重计数方案，标准误差是 0.81%，精确度已经可以满足上面的 UV 统计需求。

语法：

pfadd  key value  添加一个计数，如果不存在返回1，否则返回0（有误差，但很小）

pfcount key  计算添加的元素数量

pfmerge key1 key2 ...  将多个pf的值进行合并（注意：合并的时候，如果pf1和pf2有重复的，也会进行去重再计算）

```java
连续添加了两次重复的用户，最后计算的数量是5，正确。
127.0.0.1:6379> pfadd hotel user1
(integer) 1
127.0.0.1:6379> pfadd hotel user2
(integer) 1
127.0.0.1:6379> pfadd hotel user3
(integer) 1
127.0.0.1:6379> pfadd hotel user4
(integer) 1
127.0.0.1:6379> pfadd hotel user5
(integer) 1
127.0.0.1:6379> pfadd hotel user1
(integer) 0
127.0.0.1:6379> pfadd hotel user2
(integer) 0
127.0.0.1:6379> pfadd hotel user3
(integer) 0
127.0.0.1:6379> pfadd hotel user4
(integer) 0
127.0.0.1:6379> pfadd hotel user5
(integer) 0
127.0.0.1:6379> pfcount hotel
(integer) 5
```

注意：

该数据结构使用的时候，会占据一定12k的存储空间，并不是和统计单个用户相关的数据。适合流量比较大，对公共数据的统计。

相比set存储方案，HyperLogLog用的空间相对少很多。

Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。

### 实现原理

查看书籍。

## 5. 布隆过滤器

推荐文章：[布隆过滤器，这一篇给你讲的明明白白-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/773205#slide-14)

相关过滤器：布谷鸟过滤器：[布谷鸟过滤器（Cuckoo Filter） - 泰阁尔 - 博客园 (cnblogs.com)](https://www.cnblogs.com/zhaodongge/p/15067657.html)

### 布隆过滤器

判断一个元素是否存在于集合中，我们会存储这些元素然后进行判重操作，但是使用链表，树，hash这些数据结构，随着元素数量的增多，存储空间会直线增张，最终达到性能瓶颈。检索时间复杂度：$O(n)$，$O(logn)$，$O(1)$。

用于解决批量数据的判重问题，在去重的同时，空间能节省90%，但是有一定的误判概率。

**hash函数结构**

![image-20221112205746248](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205746248.png)

- 如果两个散列值是不相同的（根据同一函数)，那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为**单向散列函数**。
- 散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“**散列碰撞**（collision）”。

但是用 hash表存储大数据量时，空间效率还是很低，当只有一个 hash 函数时，还很容易发生哈希碰撞。

**布隆过滤器**

BloomFilter 是由一个固定大小的二进制向量或者位图（bitmap）和一系列映射函数组成的。

在初始状态时，对于长度为 m 的位数组，它的所有位都被置为0。

![image-20221112205840897](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205840897.png)

当有变量被加入集合时，通过 K 个映射函数将这个变量映射成位图中的 K 个点，把它们置为 1（假定有两个变量都通过 3 个映射函数）。

![image-20221112205904421](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205904421.png)

查询某个变量的时候我们只要看看这些点是不是都是 1 就可以大概率知道集合中有没有它了

**特性：**

- **一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在**。
- **布隆过滤器可以添加元素，但是不能删除元素**。因为删掉元素会导致误判率增加。

**添加元素步骤：**

1. 将要添加的元素给 k 个哈希函数
2. 得到对应于位数组上的 k 个位置
3. 将这k个位置设为 1

**查询元素步骤：**

1. 将要查询的元素给k个哈希函数
2. 得到对应于位数组上的k个位置
3. 如果k个位置有一个为 0，则肯定不在集合中
4. 如果k个位置全部为 1，则可能在集合中

**优点：**

1. 对比其他数据结构，时间和空间有巨大优势。插入/查询时间复杂度都是O（K）。

2. 散列函数相互之间没有关系，方便由硬件并行实现。

3. 不存储元素本身，对保密要求有严格的场合有优势。

**缺点：**

1. 误判，随着元素的增加，误算率也随之增加。如果元素数量较少，使用散列表足矣。
2. 不能删除元素。

### 使用场景

1. 已阅读文章/视频去重推荐
2. 缓存穿透，请求来的时候先经过布隆过滤器，如果布隆过滤器有数据，再去查redis，redis没有再去查库。如果布隆过滤器没有数据，直接拒绝。
3. WEB拦截器，如果相同请求则拦截，防止重复被攻击。用户第一次请求，将请求参数放入布隆过滤器中，当第二次请求时，先判断请求参数是否被布隆过滤器命中。
4. 爬虫去重，已经爬过的网页不再去爬
5. Nosql中，当用户来查询某个 row 时，可以先通过内存中的布隆过滤器过滤掉大量不存在的row 请求，然后再去磁盘进行查询。
6. 垃圾邮件的过滤功能。

### 布隆过滤器使用

#### redis布隆过滤器

```sql
docker run -p 6381:6379 \
--name redis-bloom \
-d --restart=always \
-e TZ="Asia/Shanghai" \
 -v /opt/dockers/docker_redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \
 -v /opt/dockers/docker_redis/data:/var/lib/redis \
 -v /opt/dockers/docker_redis/log:/var/log/redis \
 redislabs/rebloom:2.2.2 \
 /usr/local/bin/redis-server /usr/local/etc/redis/redis.conf \
 --appendonly yes\
 --requirepass "123456" \
 --loadmodule "/usr/lib/redis/modules/redisbloom.so"
 
 docker exec -it redis-bloom redis-cli
 
 auth
 
```

布隆过滤器基本指令：

- bf.add 添加元素到布隆过滤器
- bf.exists 判断元素是否在布隆过滤器
- bf.madd 添加多个元素到布隆过滤器，bf.add 只能添加一个
- bf.mexists 判断多个元素是否在布隆过滤器

```sql
# 添加元素
127.0.0.1:6379> bf.add user Tom
(integer) 1
127.0.0.1:6379> bf.add user Tom1
(integer) 1
127.0.0.1:6379> bf.add user Tom2
(integer) 1
127.0.0.1:6379> bf.add user Tom3
(integer) 1
# 重复添加元素
127.0.0.1:6379> bf.add user Tom1
(integer) 0
127.0.0.1:6379> bf.add user Tom
(integer) 0
# 判断元素是否存在
127.0.0.1:6379> bf.exists user Tom
(integer) 1
# 判断多个元素是否存在
127.0.0.1:6379> bf.mexists user Tom1 Tom2
1) (integer) 1
2) (integer) 1
127.0.0.1:6379> bf.mexists user Tom11 Tom12
1) (integer) 0
2) (integer) 0
```

问题：有一定的误判

Redis 还提供了自定义参数的布隆过滤器，`bf.reserve 过滤器名 error_rate initial_size`

- error_rate：允许布隆过滤器的错误率，这个值越低过滤器的位数组的大小越大，占用空间也就越大
- initial_size：布隆过滤器可以储存的元素个数，当实际存储的元素个数超过这个值之后，过滤器的准确率会下降

bf.reserve 需要在add之前显式创建，否则会报错。

```java
127.0.0.1:6379> bf.reserve user 0.01 100
(error) ERR item exists
127.0.0.1:6379> bf.reserve topic 0.01 1000
OK
```

通过Redisson使用过布隆滤器

```java
public class RedissonBloomFilterDemo {

    public static void main(String[] args) {

        Config config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");
        RedissonClient redisson = Redisson.create(config);

        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("user");
        // 初始化布隆过滤器，预计统计元素数量为55000000，期望误差率为0.03
        bloomFilter.tryInit(55000000L, 0.03);
        bloomFilter.add("Tom");
        bloomFilter.add("Jack");
        System.out.println(bloomFilter.count());   //2
        System.out.println(bloomFilter.contains("Tom"));  //true
        System.out.println(bloomFilter.contains("Linda"));  //false
    }
}
```

#### 自定义布隆过滤器

```java
public class MyBloomFilter {

    /**
     * 一个长度为10 亿的比特位
     */
    private static final int DEFAULT_SIZE = 256 << 22;

    /**
     * 为了降低错误率，使用加法hash算法，所以定义一个8个元素的质数数组
     */
    private static final int[] seeds = {3, 5, 7, 11, 13, 31, 37, 61};

    /**
     * 相当于构建 8 个不同的hash算法
     */
    private static HashFunction[] functions = new HashFunction[seeds.length];

    /**
     * 初始化布隆过滤器的 bitmap
     */
    private static BitSet bitset = new BitSet(DEFAULT_SIZE);

    /**
     * 添加数据
     *
     * @param value 需要加入的值
     */
    public static void add(String value) {
        if (value != null) {
            for (HashFunction f : functions) {
                //计算 hash 值并修改 bitmap 中相应位置为 true
                bitset.set(f.hash(value), true);
            }
        }
    }

    /**
     * 判断相应元素是否存在
     * @param value 需要判断的元素
     * @return 结果
     */
    public static boolean contains(String value) {
        if (value == null) {
            return false;
        }
        boolean ret = true;
        for (HashFunction f : functions) {
            ret = bitset.get(f.hash(value));
            //一个 hash 函数返回 false 则跳出循环
            if (!ret) {
                break;
            }
        }
        return ret;
    }

    /**
     * 模拟用户是不是会员，或用户在不在线。。。
     */
    public static void main(String[] args) {

        for (int i = 0; i < seeds.length; i++) {
            functions[i] = new HashFunction(DEFAULT_SIZE, seeds[i]);
        }

        // 添加1亿数据
        for (int i = 0; i < 100000000; i++) {
            add(String.valueOf(i));
        }
        String id = "123456789";
        add(id);

        System.out.println(contains(id));   // true
        System.out.println("" + contains("234567890"));  //false
    }
}

class HashFunction {

    private int size;
    private int seed;

    public HashFunction(int size, int seed) {
        this.size = size;
        this.seed = seed;
    }

    public int hash(String value) {
        int result = 0;
        int len = value.length();
        for (int i = 0; i < len; i++) {
            result = seed * result + value.charAt(i);
        }
        int r = (size - 1) & result;
        return (size - 1) & result;
    }
}
```

#### Guava 中的 BloomFilter

```java
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>23.0</version>
</dependency>

public class GuavaBloomFilterDemo {

    public static void main(String[] args) {
        //后边两个参数：预计包含的数据量，和允许的误差值
        BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), 100000, 0.01);
        for (int i = 0; i < 100000; i++) {
            bloomFilter.put(i);
        }
        System.out.println(bloomFilter.mightContain(1));
        System.out.println(bloomFilter.mightContain(2));
        System.out.println(bloomFilter.mightContain(3));
        System.out.println(bloomFilter.mightContain(100001));

        //bloomFilter.writeTo();
    }
}
```

#### SpringBoot

[(287条消息) SpringBoot + Redis实现布隆过滤器拦截无效请求_Toner_唐纳的博客-CSDN博客_布隆过滤器拦截](https://blog.csdn.net/qq_37012496/article/details/106375261)

## 6. 限流

限流目的：

1. 系统处理能力有限，阻止计划外的请求对系统施压。
2. 控制用户行为，避免垃圾请求。

### Redis实现限流

限定用户的某个行为在指定的时间里只能允许发生 N 次。

使用ZSET，通过滑动窗口的形式来计算指定时间内请求的次数。

![image-20221114092907767](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114092907767.png)

通过score的range可以查看单位时间内用户操作的次数。

```java
public Response limitFlow(){
 Long currentTime = new Date().getTime();
 System.out.println(currentTime);
 if(redisTemplate.hasKey("1001")) {
 Integer count = redisTemplate.opsForZSet().rangeByScore("1001", currentTime -  intervalTime, currentTime).size();        // intervalTime是限流的时间 
 System.out.println(count);
 if (count != null && count > 5) {
 return Response.ok("每分钟最多只能访问5次");
 }
 }
 redisTemplate.opsForZSet().add("limit",UUID.randomUUID().toString(),currentTime);
 return Response.ok("访问成功");
 }

```

其他实现方式：[Redis的三种限流方法_fking86的博客-CSDN博客_redis限流](https://fking.blog.csdn.net/article/details/109967406?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-109967406-blog-107744599.pc_relevant_multi_platform_whitelistv4&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-109967406-blog-107744599.pc_relevant_multi_platform_whitelistv4&utm_relevant_index=1)

### 漏斗限流

#### Java实现

![image-20221114095843081](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114095843081.png)

```java
package redis.限流算法;

import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * 漏斗限流算法
 */
public class FunnelRateLimiter {
    private Map<String, Funnel> funnelMap = new ConcurrentHashMap<>();

    public static void main(String[] args) throws InterruptedException {
        FunnelRateLimiter limiter = new FunnelRateLimiter();
        int testAccessCount = 30;//测试次数
        int capacity = 5;//漏斗容量
        int allowQuota = 5;//漏斗流动比率
        int perSecond = 30;//流动速率
        int allowCount = 0;//允许次数
        int denyCount = 0;//拒绝次数
        for (int i = 0; i < testAccessCount; i++) {
            boolean isAllow = limiter.isActionAllowed("dadiyang", "doSomething", 5, 5, 30);
            if (isAllow) {
                allowCount++;
            } else {
                denyCount++;
            }
            System.out.println("访问权限：" + isAllow);
            Thread.sleep(1000);
        }
        System.out.println("报告：");
        System.out.println("漏斗容量：" + capacity);
        System.out.println("漏斗流动速率：" + allowQuota + "次/" + perSecond + "秒");
        System.out.println("测试次数=" + testAccessCount);
        System.out.println("允许次数=" + allowCount);
        System.out.println("拒绝次数=" + denyCount);
    }

    /**
     * 根据给定的漏斗参数检查是否允许访问
     *
     * @param username   用户名
     * @param action     操作
     * @param capacity   漏斗容量
     * @param allowQuota 每单个单位时间允许的流量
     * @param perSecond  单位时间（秒）
     * @return 是否允许访问
     */
    public boolean isActionAllowed(String username, String action, int capacity, int allowQuota, int perSecond) {
        String key = "funnel:" + action + ":" + username;
        if (!funnelMap.containsKey(key)) {
            funnelMap.put(key, new Funnel(capacity, allowQuota, perSecond));
        }
        Funnel funnel = funnelMap.get(key);
        return funnel.watering(1);
    }

    private static class Funnel {
        private int capacity;
        private float leakingRate;
        private int leftQuota;
        private long leakingTs;

        public Funnel(int capacity, int count, int perSecond) {
            this.capacity = capacity;
            // 因为计算使用毫秒为单位的
            perSecond *= 1000;
            this.leakingRate = (float) count / perSecond;
        }

        /**
         * 根据上次水流动的时间，腾出已流出的空间
         */
        private void makeSpace() {
            long now = System.currentTimeMillis();
            long time = now - leakingTs;
            int leaked = (int) (time * leakingRate);
            if (leaked < 1) {
                return;
            }
            leftQuota += leaked;
            // 如果剩余大于容量，则剩余等于容量
            if (leftQuota > capacity) {
                leftQuota = capacity;
            }
            leakingTs = now;
        }

        /**
         * 漏斗漏水
         *
         * @param quota 流量
         * @return 是否有足够的水可以流出（是否允许访问）
         */
        public boolean watering(int quota) {
            makeSpace();
            int left = leftQuota - quota;
            if (left >= 0) {
                leftQuota = left;
                return true;
            }
            return false;
        }
    }
}
 
```

Funnel 对象的 make_space 方法是漏斗算法的核心，其在每次灌水前都会被调用以触发漏水，给漏斗腾出空间来。能腾出多少空间取决于过去了多久以及流水的速率。Funnel 对象占据的空间大小不再和行为的频率成正比，它的空间占用是一个常量。

#### redis实现

将 Funnel 对象的内容按字段存储到一个hash结构中，灌水的时候将 hash 结构的字段取出来进行逻辑运算后，再将新值回填到hash 结构中就完成了一次行为频度的检测。但是有个问题，我们无法保证整个过程的原子性。从 hash 结构中取值，然后在内存里运算，再回填到 hash 结构，这三个过程无法原子化，意味着需要进行适当的加锁控制。而一旦加锁，就意味着会有加锁失败，加锁失败就需要选择重试或者放弃。

如果重试的话，就会导致性能下降。如果放弃的话，就会影响用户体验。同时，代码的复杂度也跟着升高很多。

**redis4.0提供漏斗算法 4.0以上版本**

Redis 4.0 提供了一个限流 Redis 模块，它叫 redis-cell。该模块也使用了漏斗算法，并**提供了原子的限流指令**。

> 命令格式：cl.throttle  key名字   令牌桶容量-1   令牌产生个数   令牌产生时间 本次取走的令牌数 （不写时默认1，负值表放入令牌）
>
> 返回格式：
>
>  cl.throttle user 15 30 60 1
>
> > 1) (integer) 0    # 0 表示允许，1表示拒绝
> > 2) (integer) 16   # 漏斗总容量+1
> > 3) (integer) 15   # 漏斗剩余空间
> > 4) (integer) -1   # 如果拒绝了，需要多长时间后再试(漏斗有空间了，单位秒)
> > 5) (integer) 2    # 表示多久后令牌桶中的令牌会存满(单位秒)

频率为每 60s 最多 30 次(漏水速率)，漏斗的初始容量为 15，也就是说一开始可以连续回复 15 个帖子，然后才开始受漏水速率的影响。我们看到这个指令中漏水速率变成了 2 个参数，替代了之前的单个浮点数。

在执行限流指令时，如果被拒绝了，就需要丢弃或重试。cl.throttle 指令考虑的非常周到，连重试时间都帮你算好了，直接取返回结果数组的第四个值进行 sleep 即可，如果不想阻塞线程，也可以异步定时任务来重试。

**安装：**

redis-cell是一个插件，需要下载安装。

[Releases · brandur/redis-cell (github.com)](https://github.com/brandur/redis-cell/releases)

![image-20221114121720249](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114121720249.png)

解压：tar -zxvf redis-cell-v0.3.0-x86_64-unknown-linux-gnu.tar.gz          

配置conf文件，添加以下内容（loadmodule libredis_cell.so的路径）：loadmodule /data/plus/libredis_cell.so                 

重启redis即可。

查看是否安装成功：cli进入redis后，执行module list，可看到redis-cell模块。

### 令牌桶算法

每访问一次请求的时候，可以从Redis中获取一个令牌，如果拿到令牌了，那就说明没超出限制，而如果拿不到，则结果相反。

令牌桶算法提及到输入速率和输出速率，当输出速率大于输入速率，那么就是超出流量限制了。

可以在filter或者aop中配置策略。

```java
   // 输出令牌
   public Response limitFlow2(Long id){
        Object result = redisTemplate.opsForList().leftPop("limit_list");
        if(result == null){
            return Response.ok("当前令牌桶中无令牌");
        }
        return Response.ok(articleDescription2);
    } 


    // 10S的速率往令牌桶中添加UUID，只为保证唯一性
    @Scheduled(fixedDelay = 10_000,initialDelay = 0)
    public void setIntervalTimeTask(){
        redisTemplate.opsForList().rightPush("limit_list",UUID.randomUUID().toString());
    } 
```

![image-20221114163113470](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114163113470.png)

1、判断有没有被限流惩罚，有则直接返回，无则进入下一步。

2、判断令牌桶是否存在，不存在则先创建令牌桶，然后扣减令牌返回，存在则进入下一步。

3、判断是否需要投放令牌，不需要则直接扣减令牌，需要则先投放令牌再扣减令牌。

4、判断扣减后的令牌数，如果小于0则返回限流，同时设置限流惩罚，如果大于等于0则进入下一步。

5、更新桶中的令牌数到Redis。

## 7. GeoHash

Redis 在 3.2 版本以后增加了地理位置 GEO 模块。

计算周围的人;

![image-20221114163847768](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114163847768.png)

使用关系数据库：select id from positions where x0-r < x < x0+r and y0-r < y < y0+r

需要在经纬度坐标加上双向复合索引 (x, y)，可以最大优化查询性能。

问题：数据库性能有限，在高并发场合，如果请求的人非常多，效率比较低。

**GeoHash实现：**

它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘。所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。然后对这些方格进行整数编码，越是靠近的方格编码越是接近。那如何编码呢？一个最简单的方案就是切蛋糕法。设想一个正方形的蛋糕摆在你面前，二刀下去均分分成四块小正方形，这四个小正方形可以分别标记为 00,01,10,11 四个二进制整数。然后对每一个小正方形继续用二刀法切割一下，这时每个小小正方形就可以使用 4bit 的二进制整数予以表示。然后继续切下去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。

编码之后，每个地图元素的坐标都将变成一个整数，通过这个整数可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程度就越小。对于「附近的人」这个功能而言，损失的一点精确度可以忽略不计。

详情参考文章：https://blog.csdn.net/usher_ou/article/details/122716877

## 8. Scan：筛选海量数据

### 字符串匹配

需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除 key。

**使用字符串匹配**

u1:userid，c1:courseId；

学生的选课信息：

```java
127.0.0.1:6379> set u1-c1 1
OK
127.0.0.1:6379> set u1-c2 1
OK
127.0.0.1:6379> set u1-c3 1
OK
127.0.0.1:6379> set u1-c4 1
OK
127.0.0.1:6379> set u2-c1 1
OK
127.0.0.1:6379> set u2-c3 1
OK
127.0.0.1:6379> set u3-c1 1
OK
127.0.0.1:6379> set u4-c1 1
//获取选u1的选课信息
127.0.0.1:6379> keys u1-c*
1) "u1-c1"
2) "u1-c3"
3) "u1-c4"
4) "u1-c2"
//获取选择c1课程用户信息
127.0.0.1:6379> keys u*c1
1) "u4-c1"
2) "u3-c1"
3) "u1-c1"
4) "u2-c1"
```

**问题：**

1. 没有 offset、limit 参数，一次性吐出所有满足条件的 key,如果满足的key比较多，降低传输速率。
2. keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错，因为Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续

### scan基本使用

**特点：**scan 相比keys 具备有以下特点:

1、复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;

**2、提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少;**

3、同 keys 一样，它也提供模式匹配功能;

4、服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数;

5、**返回的结果可能会有重复，需要客户端去重复，这点非常重要;**

6、遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;

7、单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;

scan 参数提供了三个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三个是遍历的 limit hint。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。

 scan 0 match key99* count 1000

**使用：**

批量添加数据：https://blog.csdn.net/weixin_41677422/article/details/108626587

```java
 Map<String,Integer> keys = new HashMap<>();
        for (int i = 1; i <=10000; i++) {
            String str1 = "user1-c"+i;
            String str2 = "user2-c"+i;
            keys.put(str1,1);
            keys.put(str2,1);
        }
        redisTemplate.opsForValue().multiSet(keys);
```

**命令：**

 scan 0 match user1-c* count 1000

```java
1) "32208"
2)   1) "user1-c8506"
     2) "user1-c8657"
     3) "user1-c3984"
     4) "user1-c7815"
     5) "user1-c6278"
     6) "user1-c6254"
     7) "user1-c8514"
     8) "user1-c264"
     9) "user1-c7740"
```

scan 32008 match user1-c* count 1000                                                                                                                                                                                                                        

```java
1) "1464"                                                                                                                                                                                                                                                                   
2) 1) "user1-c7383"                                                                                                                                                                                                                                                       
   2) "user1-c7729"                                                                                                                                                                                                                                      
   3) "user1-c3169"                                                                                                                                                                                                                                                       
   4) "user1-c6614"                                                                                                                                                                                                                                                       
   5) "user1-c8633"                                                                                                                                                                                                                                                       
   6) "user1-c7440"                                                                                                                                                                                                                                                       
   7) "user1-c1604"                                                                                                                                                                                                                                                       
   8) "user1-c4434"                                                                                                                                                                                                                                                       
   9) "user1-c6236"                                                                                                                                                                                                                                                       
   10) "user1-c2290"                                                                                                                                                                                                                                                       
   11) "user1-c1856"                                                                                                                                                                                                                                                       
   12) "user1-c888"                                                                                                                                                                                                                                                        
   13) "user1-c8608"    
```

从上面的过程可以看到虽然提供的 limit 是 1000，但是返回的结果只有 10 个左右。因为这个 limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量(约等于)。如果将 limit 设置为 10，你会发现返回结果是空的，但是游标值不为零，意味着遍历还没结束。

### 字典结构

scan是通过hash的形式查找的

![image-20221114202955771](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114202955771.png)

scan 指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽 (slot)。。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。

**scan的遍历顺序**

scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。

**普通加法和高位进位加法的区别**

高位进位法从左边加，进位往右边移动，同普通加法正好相反。但是最终它们都会遍历所有的槽位并且没有重复。

**针对其他数据结构同样适用**

scan 指令是一系列指令，除了可以遍历所有的 key 之外，还可以对指定的容器集合进行遍历。比如 zscan 遍历 zset 集合元素，hscan 遍历 hash 字典的元素、sscan 遍历 set 集合的元素

### 大key 检测

进入redis容器（非直接进入redis-cli），使用：redis-cli -h 127.0.0.1 -p 6379 -a PASSWORD --bigkeys   

| 名称      | 说明                  |
| :-------- | :-------------------- |
| -h        | 指定Redis的连接地址。 |
| -a        | 指定Redis的认证密码。 |
| --hotkeys | 用来查询热点Key。     |
| --bigkeys | 用来查询大Key。       |

推荐文章：

[Redis 4.0热点Key查询方法 (aliyun.com)](https://help.aliyun.com/document_detail/101108.html)

[发现并处理Redis的大Key和热Key (aliyun.com)](https://help.aliyun.com/document_detail/353223.html)

# Redis原理

## 1. 操作系统的IO模型

redis是单线程，nginx，node.js都是单线程。

**redis单线程还这么快的原因**

redis速度快原因在于redis操作的是内存，因为是单线程的，因此对于复杂度为O（n）的指令要谨慎执行。

**Redis** **单线程如何处理那么多的并发客户端连接？**

redis使用的是非阻塞IO，通过多路复用来处理多个客户端发送的链接。

### 同步阻塞 IO 模型

假设应用程序的进程发起 **IO 调用**，但是如果**内核的数据还没准备好**的话，那应用程序进程就一直在**阻塞等待**，一直等到内核数据准备好，直到内核拷贝到用户空间，才返回成功提示，此次 IO 操作，称之为**阻塞 IO**。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071111906.webp)](https://mynotepicture.oss-cn-hangzhou.aliyuncs.com/img/202211071111906.webp)

> - 阻塞 IO 比较经典的应用就是**阻塞 socket、Java BIO**。
> - 阻塞 IO 的缺点就是：如果内核数据一直没准备好，那用户进程将一直阻塞，**浪费性能**，可以使用**非阻塞 IO** 优化。

### 同步非阻塞 IO 模型

如果内核数据还没准备好，可以先返回错误信息给用户进程，让它不需要等待，通过轮询的方式再来请求，这就是非阻塞 IO，流程图如下：

![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071114171.webp)

非阻塞 IO 的流程如下：

- 应用进程向操作系统内核，发起 `recvfrom` 读取数据。
- 操作系统内核数据没有准备好，立即返回 `EWOULDBLOCK` 错误码。
- 应用程序轮询调用，继续向操作系统内核发起 `recvfrom` 读取数据。
- 操作系统内核数据准备好了，从内核缓冲区拷贝到用户空间。
- 完成调用，返回成功提示。

非阻塞 IO 模型，简称 **NIO**，`Non-Blocking IO`。它相对于阻塞 IO，虽然大幅提升了性能，但是它依然存在**性能问题**，即**频繁的轮询**，导致频繁的系统调用，同样会消耗大量的 CPU 资源。可以考虑 **IO 复用模型**，去解决这个问题。

### IO 多路复用模型

IO 复用模型核心思路：系统给我们提供**一类函数**（如我们耳濡目染的 **select、poll、epoll** 函数），它们可以同时监控多个文件描述符的操作，并在其中某个文件描述符可读写时由操作系统唤醒阻塞等待的线程。

> I/O 复用其实复用的不是 I/O 连接，而是复用线程，让线程能够监听多个连接（I/O 事件）。
>
> 文件描述符（fd）：它是计算机科学中的一个术语，形式上是一个非负整数。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

#### IO 多路复用之 select

应用进程通过调用 select 函数，可以同时监控多个 `fd`，当有 fd 准备就绪时，select 返回数据可读状态，应用程序再调用 recvfrom 读取数据。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071138127.webp)](https://mynotepicture.oss-cn-hangzhou.aliyuncs.com/img/202211071138127.webp)

非阻塞 IO 模型（NIO）中，需要 `N`（N>=1）次轮询系统调用，然而借助 `select` 的 IO 多路复用模型，只需要发起一次系统调用就够了，大大优化了性能。

但是呢，`select` 有几个缺点：

- 监听的 IO 最大连接数有限，在 Linux 系统上一般为 1024。
- select 函数返回后，是通过遍历 `fdset`，找到就绪的描述符 `fd`。

因为**存在连接数限制**，所以后来又提出了 **poll**。与 select 相比，**poll** 解决了**连接数限制问题**。但是呢，select 和 poll 一样，还是需要通过遍历文件描述符来获取已经就绪的 `socket`。如果同时连接的大量客户端在一时刻可能只有极少处于就绪状态，伴随着监视的描述符数量的增长，**效率也会线性下降**。

因此经典的多路复用模型 `epoll` 诞生。

#### IO 多路复用之 epoll

为了解决 `select/poll` 存在的问题，多路复用模型 `epoll` 诞生，它采用事件驱动来实现，流程图如下：

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071139505.webp)

**epoll** 先通过 `epoll_ctl()` 来注册一个 `fd`（文件描述符），一旦基于某个 `fd` 就绪时，内核会采用回调机制，迅速激活这个 `fd`，当进程调用 `epoll_wait()` 时便得到通知。这里去掉了**遍历文件描述符**的坑爹操作，而是采用**监听事件回调**的的机制。这就是 epoll 的亮点。

select、poll、epoll 的区别：

|               | **select**                                              | **poll**                                              | **epoll**                                                    |
| ------------- | ------------------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| 底层数据结构  | 数组                                                    | 链表                                                  | 红黑树和双链表                                               |
| 获取就绪的 fd | 遍历                                                    | 遍历                                                  | 事件回调                                                     |
| 事件复杂度    | O(n)                                                    | O(n)                                                  | O(1)                                                         |
| 最大连接数    | 1024                                                    | 无限制                                                | 无限制                                                       |
| fd 数据拷贝   | 每次调用 select，需要将 fd 数据从用户空间拷贝到内核空间 | 每次调用 poll，需要将 fd 数据从用户空间拷贝到内核空间 | 使用内存映射 (mmap)，不需要从用户空间频繁拷贝 fd 数据到内核空间 |

**epoll** 明显优化了 IO 的执行效率，但在进程调用 `epoll_wait()` 时，仍然可能被阻塞的。能不能这样：不用我老是去问你数据是否准备就绪，等我发出请求后，你数据准备好了通知我就行了，这就诞生了**信号驱动 IO 模型**。

### IO 模型之信号驱动模型

信号驱动 IO 不再用主动询问的方式去确认数据是否就绪，而是向内核发送一个信号（调用 `sigaction` 的时候建立一个 `SIGIO` 的信号），然后应用用户进程可以去做别的事，不用阻塞。当内核数据准备好后，再通过 `SIGIO` 信号通知应用进程。应用用户进程收到信号之后，立即调用 `recvfrom`，去读取数据。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071141603.webp)

信号驱动 IO 模型，在应用进程发出信号后，是立即返回的，不会阻塞进程。它已经有异步操作的感觉了。但是你细看上面的流程图，**发现数据复制到应用缓冲的时候**，应用进程还是阻塞的。回过头来看下，不管是 BIO，还是 NIO，还是信号驱动，在数据从内核复制到应用缓冲的时候，都是阻塞的。还有没有优化方案呢？**AIO**（真正的异步 IO）！

### IO 模型之异步 IO (AIO)

前面讲的 `BIO，NIO和信号驱动`，在数据从内核复制到应用缓冲的时候，都是**阻塞**的，因此都不是真正的异步。`AIO` 实现了 IO 全流程的非阻塞，就是应用进程发出系统调用后，是立即返回的，但是**立即返回的不是处理结果，而是表示提交成功类似的意思**。等内核数据准备好，将数据拷贝到用户进程缓冲区，发送信号通知用户进程 IO 操作执行完毕。

[![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/202211071142114.webp)](https://mynotepicture.oss-cn-hangzhou.aliyuncs.com/img/202211071142114.webp)



异步 IO 的优化思路很简单，只需要向内核发送一次请求，就可以完成数据状态询问和数据拷贝的所有操作，并且不用阻塞等待结果。日常开发中，有类似的业务场景：

> 比如发起一笔批量转账，但是转账处理比较耗时，这时候后端可以先告知前端转账提交成功，等到结果处理完，再通知前端结果即可。

总结：

- 阻塞 IO 就是那种[ recv](https://www.zhihu.com/search?q=recv&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A14413599}), read，一直等，等到有了数据才返回；
- 非阻塞 IO 就是立即返回，设置描述符为非阻塞，但是要进程自己一直检查是否可读；
- IO 复用其实也是阻塞的，不过可以用来等很多描述符，比起阻塞有了进步，可以算有点异步了，但需要阻塞着检查是否可读。**对同一个描述符的 IO 操作也是有序的。**
- 信号驱动采用[信号机制](https://www.zhihu.com/search?q=信号机制&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A14413599})等待，有了更多的进步，不用监视描述符了，而且不用阻塞着等待数据到来，被动等待信号通知，由[信号处理程序](https://www.zhihu.com/search?q=信号处理程序&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A14413599})处理。**但对同一个描述符的 IO 操作还是有序的。**
- 异步 IO，发送 IO 请求后，不用等了，也不再需要发送 IO 请求获取结果了。等到通知后，其实是系统帮你把数据读取好了的，**你等到的通知也不再是要求你去读写 IO 了，而是告诉你 IO 请求过程已经结束了**。你要做的就是可以处理数据了。且同一个描述符上可能同时存在很多请求。

#### 指令队列和响应队列

指令队列：Redis 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。

响应队列：Redis 同样也会为每个客户端套接字关联一个响应队列。Redis 服务器通过响应队列来将指令的返回结果回复给客户端。 如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符从 write_fds 里面移出来。等到队列有数据了，再将描述符放进去。避免 select 系统调用立即返回写事件，结果发现没什么数据可以写。出这种情况的线程会飙高 CPU。

## 2. 持久化

两种持久化机制：RDB和AOF。

**RDB：**快照，全量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑。

**AOF: **增量备份，记录的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。

### RDB

快照，全量备份。

记录内存中的数据在某一时刻的状态，进行全量快照，会将内存中所有的数据都记录到磁盘中。即使服务器宕机，快照文件也不会丢失，恢复时只需要将文件读到内存即可。

在进行快照的时候是全量快照，会将内存中所有的数据都记录到磁盘中，这就有可能会阻塞主线程的执行。

Redis提供了两个命令来生成RDB文件，分别是**save**和**bgsave**：

- save：在主线程中执行，会导致阻塞；

- bgsave：会创建一个子进程，该进程专门用于写入RDB文件，可以避免主线程的阻塞，也是默认的方式。

可以采用bgsave的命令来执行全量快照，提供了数据的可靠性保证，也避免了对Redis的性能影响

问题：执行快照期间数据能不能修改呢?

如果不能修改，快照过程中如果有新的写操作，数据就会不一致，这肯定是不符合预期的。Redis借用了操作系统的**写时复制**，在执行快照的期间，正常处理写操作。

主要流程：

- bgsave子进程是由主线程fork出来的，可以共享主线程的所有内存数据。

- bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入RDB文件中。

- 如果主线程对这些数据都是读操作，例如A，那么主线程和bgsave子进程互不影响。

- 如果主线程需要修改一块数据，如C，这块数据会被复制一份，生成数据的副本，然主线程在这个副本上进行修改；bgsave子进程可以把原来的数据C写入RDB文件。

![image-20221115150441025](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115150441025.png)

**多久进行一次快照？**

理论上来说快照时间间隔越短越好，可以减少数据的丢失，毕竟fork的子进程不会阻塞主线程，但是频繁的将数据写入磁盘，会给磁盘带来很多压力，也可能会存在多个快照竞争磁盘带宽（当前快照没结束，下一个就开始了）。另一方面，虽然fork出的子进程不会阻塞，但fork这个创建过程是会阻塞主线程的，当主线程需要的内存越大，阻塞时间越长。

**增量快照**

在做一次全量快照后，后续的快照只对修改的数据进行记录，需要记住哪些数据被修改了，可以避免全量快照带来的开销。

### AOF

AOF日志是写后日志，也就是Redis先执行命令，然后将数据写入内存，最后才记录日志。

AOF日志中记录的是Redis收到的每一条命令，这些命令都是以文本的形式保存的。

AOF为了避免额外的检查开销，并不会检查命令的正确性，因此需要先执行命令，再写日志。执行命令后再写日志，不会阻塞当前写操作。

**风险：**

1. 命令执行后，redis宕机了，日志没有写入。
2. AOF可以避免对当前命令的阻塞（因为是先写入再记录日志），但有可能会对下一次操作带来阻塞风险（可能存在写入磁盘较慢的情况）

**写入磁盘的机制**

![image-20221115142422728](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115142422728.png)

- Always可靠性较高，数据基本不丢失，但是对性能的影响较大。

- Everysec性能适中，即使宕机也只会丢失1秒的数据。

- No性能好，但是如果宕机丢失的数据较多。

问题：

1. AOF是通过文件的形式记录所写的命令，指令越多，文件会越来越大，最后超过文件的限制。
2. 文件较大时，写入命令效率会降低，如果发生宕机，AOF所有命令需要重新执行，数据越大恢复时间越长。

AOF提供了重写机制，可以解决文件过大问题。

#### **AOF的重写机制**

AOF重写就是根据所有的键值对创建一个新的AOF文件，可以减少大量的文件空间。

减少的原因是：AOF对于命令的添加是追加的方式，逐一记录命令，但有可能存在某个键值被反复更改，产生了一些冗余数据，这样在重写的时候就可以过滤掉这些指令，从而更新当前的最新状态。

Redis 提供了 bgrewriteaof 指令用于AOF重写。可以避免阻塞主进程导致性能下降。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中（重写的过程中，发生数据的写或修改操作，会先把数据写入缓冲区，最后追加到新的AOF中），追加完毕后就立即替代旧的 AOF 日志文件了。

#### fsync

AOF写日志时，实际将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核将日志刷新到磁盘。

问题：

如果redis突然宕机，内存中的内容还没来得及刷新磁盘，此时会出现日志丢失。

解决：

Linux 的 glibc 提供了 fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个

磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。

在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能

使得数据少丢失。Redis 同样也提供了另外两种策略，一个是永不 fsync——让操作系统来决定合适同步磁盘，很不安全，另一个是来一个指令就 fsync 一次——非常慢。

### 混合使用

```java
# aof‐use‐rdb‐preamble yes
```

跟AOF相比，RDB快照的恢复速度快，但快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销

**在Redis4.0提出了混合使用AOF和RDB快照的方法，也就是两次RDB快照期间的所有命令操作由AOF日志文件进行记录。这样的好处是RDB快照不需要很频繁的执行，可以避免频繁fork对主线程的影响，而且AOF日志也只记录两次快照期间的操作，不用记录所有操作，也不会出现文件过大的情况，避免了重写开销。既可以享受RDB快速恢复的好处，也可以享受AOF记录简单命令的优势。**

如果开启了混合持久化，AOF在重写时，将重写这一刻之前的内存做RDB快照处理并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件，新的文件一开始不叫appendonly.aof,等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。在Redis重启的时候，可以先加载RDB的内容，然后再重放增量AOF日志就可以完全替代之前的AOF全量文件重放，因此重启效率大幅得到提升.

　　![img](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/1460613-20210226225333335-1001578826.png)

 

**对于AOF和RDB的选择问题**：

- 数据不能丢失时，内存快照和AOF的混合使用是一个很好的选择。

- 如果允许分钟级别的数据丢失，可以只使用RDB。

- 如果只用AOF，优先使用everysec的配置选项，因为它在可靠性和性能之间取了一个平衡。

 **Redis 数据备份策略**

1. 写crontab 定时调度脚本，每小时copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份
2. 每天都保留一份当日的数据备份到一个目录中去，可以保留最近一个月的备份
3. 每次copy备份的时候，都把太旧的备份给删了
4. 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏

## 3. 管道

客户端通过对管道中的指令列表改变读写顺序就可以大幅节省 IO 时间。管道中指令越多，效果越好。

详细看redis深度历险

## 4. 事务

### 基本使用

每个事务的操作都有 begin、commit 和 rollback，begin 指示事务的开始，commit 指示事务的提交，rollback 指示事务的回滚。 

Redis 事务操作分别是 multi/exec/discard。multi 指示事务的开始，exec 指示事务的执行，discard 指示事务的丢弃。

```java
127.0.0.1:6379> multi
OK
127.0.0.1:6379(TX)> incr book
QUEUED
127.0.0.1:6379(TX)> incr book
QUEUED
127.0.0.1:6379(TX)> exec
1) (integer) 1
2) (integer) 2
127.0.0.1:6379> get book
"2"
```

> 所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。
>
> QUEUED 是一个简单字符串，同 OK 是一个形式，它表示指令已经被服务器缓存到队列里了。
>
>  Redis 的单线程特性，它不用担心自己在执行队列的时候被其它指令打搅，可以保证他们能得到的「原子性」执行。

```java
127.0.0.1:6379> multi
OK
127.0.0.1:6379(TX)> incr num
QUEUED
127.0.0.1:6379(TX)> incr num
QUEUED
127.0.0.1:6379(TX)> incr num
QUEUED
127.0.0.1:6379(TX)> discard
OK
127.0.0.1:6379> get num
(nil)
discard后，队列中的所有指令都没执行。
```

### 优化

 Redis 事务在发送每个指令到事务缓存队列时都要经过一次网络读写，当一个事务内部的指令较多时，需要的网络 IO 时间也会线性增长。所以通常 Redis 的客户端在执行事务时都会结合 pipeline 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作。

```java
pipe = redis.pipeline(transaction=true)
pipe.multi()
pipe.incr("books")
pipe.incr("books")
values = pipe.execute()
```

### watch实现乐观锁

参照redis深度历险

## 5. **PubSub**

### Pubsub

Redis 消息队列的不足之处，那就是它不支持消息的多播机制。PubSub用于支持消息多播。PubSub，也就是 PublisherSubscriber，发布者订阅者模型。

消息多播允许生产者生产一次消息，中间件负责将消息复制到多个消息队列，每个消息队列由相应的消费组进行消费。

![image-20221116194352159](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116194352159.png)

缺点：

1. 发送的消息，会立即被消费，如果没有消费者，则消息丢失。
2. 如果有三个消费者，其中一个挂掉了，另外两个可以接收消息消费，挂掉的恢复后，期间的消息会丢失。
3. redis宕机，pubsub的消息不会持久化。
4. 消息不会持久化，redis宕机消息就丢失了，没有合适的使用场景。

### Stream

教程：[Redis Stream | 菜鸟教程 (runoob.com)](https://www.runoob.com/redis/redis-stream.html)

Redis5支持，模仿kafka，是一个支持多播的可持久化的消息队列

![image-20221116201527310](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116201527310.png)

有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容。消息是持久化的，Redis 重启后，内容还在。

每个Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。

每个 Stream 都可以挂多个消费组，每个消费组会有个游标 last_delivered_id 在 Stream 数组之上往前移动，表示当前消费组已经消费到哪条消息了。每个消费组都有一个 Stream 内唯一的名称，消费组不会自动创建，它需要单独的指令 xgroup create 进行创建，需要指定从 Stream 的某个消息 ID 开始消费，这个 ID 用来初始last_delivered_id 变量。

每个消费组 (Consumer Group) 的状态都是独立的，相互不受影响。也就是说同一份Stream 内部的消息会被每个消费组都消费到。

同一个消费组 (Consumer Group) 可以挂接多个消费者 (Consumer)，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动。每个消费者有一个组内唯一名称。

消费者 (Consumer) 内部会有个状态变量 pending_ids，它记录了当前已经被客户端读取的消息，但是还没有 ack。如果客户端没有 ack，这个变量里面的消息 ID 会越来越多，一旦某个消息被 ack，它就开始减少。这个 pending_ids 变量在 Redis 官方被称之为 PEL，也就是 Pending Entries List，这是一个很核心的数据结构，它用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理。

**消息id**

消息 ID 的形式是 timestampInMillis-sequence，例如 1527846880572-5，表示当前的消息在毫米时间戳 1527846880572 时产生，并且是该毫秒内产生的第 5 条消息。消息 ID 可以由服务器自动生成，也可以由客户端自己指定，但是形式必须是整数-整数，而且必须是后面加入的消息的 ID 要大于前面的消息 ID。

**消息内容**

消息内容就是键值对，类似 hash 结构的键值对

**增删改查**

xadd mystream1 * name hb age 20

mystream1为Stream的名称；*代表由Redis自行生成消息ID；name、age为该消息的field；hb、20则为对应的field的值。每个消息都由以下两部分组成。
每个消息有唯一的消息ID，消息ID严格递增。
消息内容由多个field-value对组成。

```java
 1、xadd 追加消息
 2、xdel 删除消息，这里的删除仅仅是设置了标志位，不影响消息总长度
 3、xrange 获取消息列表，会自动过滤已经删除的消息
 4、xlen 消息长度
 5、del 删除 Stream
```

相关操作：

```java
127.0.0.1:6379> xadd codehole * name laoqian age 30
"1668602768061-0"
127.0.0.1:6379> xadd codehole * name laoqian age 29
"1668602774627-0"
127.0.0.1:6379> xadd codehole * name laoqian age 28
"1668602780397-0"
127.0.0.1:6379> xlen codehole
(integer) 3
127.0.0.1:6379> xrange codehole - +
1) 1) "1668602768061-0"
   2) 1) "name"
      2) "laoqian"
      3) "age"
      4) "30"
2) 1) "1668602774627-0"
   2) 1) "name"
      2) "laoqian"
      3) "age"
      4) "29"
3) 1) "1668602780397-0"
   2) 1) "name"
      2) "laoqian"
      3) "age"
      4) "28"
127.0.0.1:6379> xdel codehole 1668602780397-0
(integer) 1
127.0.0.1:6379> xrange codehole - +
1) 1) "1668602768061-0"
   2) 1) "name"
      2) "laoqian"
      3) "age"
      4) "30"
2) 1) "1668602774627-0"
   2) 1) "name"
      2) "laoqian"
      3) "age"
      4) "29"
127.0.0.1:6379> del codehole
(integer) 1
127.0.0.1:6379> xrange codehole - +
(empty array)
```

#### 独立消费

可以在不定义消费组的情况下进行 Stream 消息的独立消费，当 Stream 没有新消息时，甚至可以阻塞等待。

Redis 设计了一个单独的消费指令 xread，可以将 Stream 当成普通的消息队列 (list) 来使用。使用 xread 时，我们可以完全忽略消费组 (Consumer Group) 的存在，就好比 Stream 就是一个普通的列表 (list)。

**从头部读取两条数据**

XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...]

- **count** ：数量
- **milliseconds** ：可选，阻塞毫秒数，没有设置就是非阻塞模式
- **key** ：队列名
- **id** ：消息 ID

```java
127.0.0.1:6379> xread count 2 streams codehole 0-0
1) 1) "codehole"
   2) 1) 1) "1668603249817-0"
         2) 1) "name"
            2) "laoqian"
            3) "age"
            4) "30"
      2) 1) "1668603252755-0"
         2) 1) "name"
            2) "laoqian"
            3) "age"
            4) "29\\"
```

**从尾部读消息**

xread count 1 streams codehole $ 

**$** ： 表示从尾部开始消费，只接受新消息，当前 Stream 消息会全部忽略。

从尾部阻塞等待新消息到来，下面的指令会堵住，直到新消息到来

xread block 0 count 1 streams codehole $

此时程序阻塞，新开窗口添加消息，即可获得最新添加的消息。

```java
127.0.0.1:6379> xread block 0 count 1 streams codehole $
1) 1) "codehole"
   2) 1) 1) "1668604153069-0"
         2) 1) "name"
            2) "laoqian"
            3) "age"
            4) "25"
(27.05s)
```

block 0 表示永远阻塞，直到消息到来，block 1000 表示阻塞 1s，如果 1s 内没有任何消息到来，就返回 nil。

#### 消费组消费

Stream 提供了 xreadgroup 指令可以进行消费组的组内消费，需要提供消费组名称、消费者名称和起始消息 ID。

它同 xread 一样，也可以阻塞等待新消息。读到新消息后，对应的消息 ID 就会进入消费者的 PEL(正在处理的消息) 结构里，客户端处理完毕后使用 xack 指令通知服务器，本条消息已经处理完毕，该消息 ID 就会从 PEL 中移除。

![image-20221116211956925](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116211956925.png)

Stream 通过 xgroup create 指令创建消费组 (Consumer Group)，需要传递起始消息 ID 参数用来初始化 last_delivered_id 变量。

读：xreadgroup GROUP cg1 c1 count 1 streams codehole >

阻塞读： xreadgroup GROUP cg1 c1 block 0 count 1 streams codehole >



```java
# > 号表示从当前消费组的 last_delivered_id 后面开始读
# 每当消费者读取一条消息，last_delivered_id 变量就会前进
127.0.0.1:6379> xreadgroup GROUP cg1 c1 count 1 streams codehole >
1) 1) "codehole"
 2) 1) 1) 1527851486781-0
 2) 1) "name"
 2) "laoqian"
 3) "age"
 4) "30"
127.0.0.1:6379> xreadgroup GROUP cg1 c1 count 1 streams codehole >
1) 1) "codehole"
 2) 1) 1) 1527851493405-0
 2) 1) "name"
 2) "yurui"
 3) "age"
 4) "29"
127.0.0.1:6379> xreadgroup GROUP cg1 c1 count 2 streams codehole >
1) 1) "codehole"
 2) 1) 1) 1527851498956-0
 2) 1) "name"
 2) "xiaoqian"
 3) "age"
 4) "1"
 2) 1) 1527852774092-0
 2) 1) "name"
 2) "youming"
 3) "age"
 4) "60"
# 再继续读取，就没有新消息了
127.0.0.1:6379> xreadgroup GROUP cg1 c1 count 1 streams codehole >
(nil)
# 那就阻塞等待吧
127.0.0.1:6379> xreadgroup GROUP cg1 c1 block 0 count 1 streams codehole >
# 开启另一个窗口，往里塞消息
127.0.0.1:6379> xadd codehole * name lanying age 61
1527854062442-0
# 回到前一个窗口，发现阻塞解除，收到新消息了
127.0.0.1:6379> xreadgroup GROUP cg1 c1 block 0 count 1 streams codehole >
1) 1) "codehole"
 2) 1) 1) 1527854062442-0
 2) 1) "name"
 2) "lanying"
 3) "age"
 4) "61"
(36.54s)
# 观察消费组信息
127.0.0.1:6379> xinfo groups codehole
1) 1) name
 2) "cg1"
 3) consumers
 4) (integer) 1 # 一个消费者
 5) pending
 6) (integer) 5 # 共 5 条正在处理的信息还有没有 ack
2) 1) name
 2) "cg2"
 3) consumers
 4) (integer) 0 # 消费组 cg2 没有任何变化，因为前面我们一直在操纵 cg1
 5) pending
 6) (integer) 0
# 如果同一个消费组有多个消费者，我们可以通过 xinfo consumers 指令观察每个消费者的状态
127.0.0.1:6379> xinfo consumers codehole cg1 # 目前还有 1 个消费者
1) 1) name
 2) "c1"
 3) pending
 4) (integer) 5 # 共 5 条待处理消息
 5) idle
 6) (integer) 418715 # 空闲了多长时间 ms 没有读取消息了
# 接下来我们 ack 一条消息
127.0.0.1:6379> xack codehole cg1 1527851486781-0
(integer) 1
127.0.0.1:6379> xinfo consumers codehole cg1
1) 1) name
 2) "c1"
 3) pending
 4) (integer) 4 # 变成了 5 条
 5) idle
 6) (integer) 668504
# 下面 ack 所有消息
127.0.0.1:6379> xack codehole cg1 1527851493405-0 1527851498956-0 1527852774092-0 
1527854062442-0
(integer) 4
127.0.0.1:6379> xinfo consumers codehole cg1
1) 1) name
 2) "c1"
 3) pending
 4) (integer) 0 # pel 空了
 5) idle
 6) (integer) 745505
```

#### 消息过多

消息积累太多，Stream 的链表岂不是很长，内容会不会爆掉?xdel指令又不会删除消息，它只是给消息做了个标志位。

定长 Stream 功能：在 xadd 的指令提供一个定长长度 maxlen，就可以将老的消息干掉，确保最多不超过指定长度。

xadd codehole maxlen 3 * name xiaorui age 1 设置最大长度为3

如果有未删除的消息，比如现在队列中有10条消息，但是我执行了上述命令，那么会删除前七条。

#### 没有ACK

如果消费者收到了消息处理完了但是没有回复 ack，就会导致 PEL 列表不断增长，如果有很多消费组的话，那么这个 PEL 占用的内存就会放大。

#### PEL如何避免消息丢失

在客户端消费者读取 Stream 消息时，Redis 服务器将消息回复给客户端的过程中，客户端突然断开了连接，消息就丢失了。但是 PEL 里已经保存了发出去的消息 ID。待客户端重新连上之后，可以再次收到 PEL 中的消息 ID 列表。不过此时 xreadgroup 的起始消息ID 不能为参数>，而必须是任意有效的消息 ID，一般将参数设为 0-0，表示读取所有的PEL 消息以及自 last_delivered_id 之后的新消息。

#### 高可用

Stream 的高可用是建立主从复制基础上的，它和其它数据结构的复制机制没有区别，也就是说在 Sentinel 和 Cluster 集群环境下 Stream 是可以支持高可用的。不过鉴于 Redis 的指令复制是异步的，在 failover 发生时，Redis 可能会丢失极小部分数据，这点 Redis 的其它数据结构也是一样的。

#### 分区

Redis 的服务器没有原生支持分区能力，如果想要使用分区，那就需要分配多个Stream，然后在客户端使用一定的策略来生产消息到不同的 Stream。如果需要分 parition 的话，得在客户端做，提供不同的 Stream 名称，对消息进行 hash 取模来选择往哪个 Stream 里塞。

kafka是支持分区的



## 6. Redis集群

### CAP原理

分区容错性，一致性，可用性。

在分区容错性的前提下，一致性和可用性只能实现其一，网络分区发生时，一个节点的数据修改不能同步到另一个节点，因此一致性无法满足，除非牺牲可用性，即关闭子服务，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。

**最终一致**

Redis 保证「**最终一致性**」，从节点会努力追赶主节点，最终从节点的状态会和主节点的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢

复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致

### 主从复制

![image-20221115154048532](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115154048532.png)

#### 增量同步

Redis 同步的是指令流，主节点会将产生修改性影响的指令记录在本地的内存 buffer 中，然后异步将 buffer 中的指令同步到从节点，从节点一边执行同步的指令流来达到和主节点一样的状态，一遍向主节点反馈自己同步到哪里了 (偏移量)。

内存的 buffer 是有限的，所以 Redis 主库不能将所有的指令都记录在内存 buffer 中。Redis 的复制内存 buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容、

如果网络状况不好，从节点在短时间内无法和主节点进行同步，那么当网络状况恢复时，Redis 的主节点中那些没有同步的指令在 buffer 中有可能已经被后续的指令覆盖掉了，从节点将无法直接通过指令流来进行同步，这个时候就需要快照同步。

#### 快照同步

**Redis 主从工作原理**

1. 如果你为master配置了一个slave,不管这个slave是否是第一次连接上Master,它都会发送一个PSYNC命令给master请求复制数据。
2. master收到PSYNC命令后，会在后台进行数据持久化通过bgsave生成最新的rdb快照文件，持久化期间，master会继续接受客户端的请求，他会把这些可能修改的数据集的请求缓存在buffer中，当持久化进行完毕以后，master会将buffer发送给slave。
3. salve加载之前先要将当前内存的数据清空，之后把收到的数据进行持久化生成rdb,然后再加载到内存中。加载完毕后通知主节点继续进行增量同步。然后，master再将之前缓存在buffer中的命令发送给slave.
4. 当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多个slave并发连接请求，他只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave

**注意：**

如果全量备份时间过长或buffer过小，都会导致同步期间的增量指令在复制 buffer 中被覆盖，这样就会导致快照同步完成后无法进行增量复制，然后会再次发起快照同步，如此极有可能会陷入快照同步的死循环。以务必配置一个合适的复制 buffer 大小参数，避免快照复制的死循环。

当从节点刚刚加入到集群时，它必须先要进行一次快照同步，同步完成后再继续进行增量同步。

**主从复制流程图：**

![image-20221115154521199](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221115154521199.png)

#### 无盘复制

快照同步时，会进行很重的IO操作，对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响

当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率

无盘复制：

无磁盘化复制是master不会将RDB文件落到本地磁盘，会将RDB文件直接从内存中通过网络传输到slave的内存中。如果我们的服务器使用的是普通的机械硬盘（重点是磁盘的读写效率很低），而且内网的网络带宽又很高（内网网速快），那么完全可以使用这种无磁盘化的复制方式。

```java
# 开启redis的无磁盘化复制，默认是关闭的
repl-diskless-sync yes
# 这一点很重要，因为一旦传输开始，就不可能服务新的从服务器到达，它将排队等待下一次RDB传输，所以服
# 务器等待延迟以便让更多的从节点到达。延迟以秒为单位指定，默认为5秒。禁用它完全只是设置为0秒，传
# 输将尽快开始。
repl-diskless-sync-delay 5
```

#### wait指令

Redis 的复制是异步进行的，wait 指令可以让异步复制变身同步复制，确保系统的强一致性 (不严格)。wait 指令是 Redis3.0 版本以后才出现的。

```java
> set key value
OK
> wait 1 0
(integer) 1
```

wait 提供两个参数，第一个参数是从库的数量 N，第二个参数是时间 t，以毫秒为单位。它表示等待 wait 指令之前的所有写操作同步到 N 个从库 (也就是确保 N 个从库的同

步没有滞后)，最多等待时间 t。如果时间 t=0，表示无限等待直到 N 个从库同步完成达成一致。

假设此时出现了网络分区，wait 指令第二个参数时间 t=0，主从同步无法继续进行，wait 指令会永远阻塞，Redis 服务器将丧失可用性。

### 哨兵

![image-20221116151337058](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116151337058.png)

在主从复制的情况下，如果出现master节点宕机，只能手动重新启动运行。

哨兵提供了高可用的方案来抵抗单节点故障，当故障发生时可以自动进行从主切换，程序可以不用重启。

Redis Sentinel 集群负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端。

#### 消息丢失

Redis 主要采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了。如果主从延迟特别大，那么丢失的数据就可能会特别多。Sentinel 无法保证消息完全不丢失，但是也尽可能保证消息少丢失。它有两个选项可以限制主从延迟过大。

min-slaves-to-write 1：表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写服务，丧失可用性。

min-slaves-max-lag 10：表示如果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，要么网络断开了，要么一直没有给反馈。

### codis

#### 基础介绍

![image-20221116162233496](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116162233496.png)



当客户端向 Codis 发送指令时，Codis 负责将指令转发到后面的 Redis 实例来执行，并将返回结果再转回给客户端。Codis使用和redis一样的通信协议对外服务。

Codis 上挂接的所有 Redis 实例构成一个 Redis 集群，当集群空间不足时，可以通过动态增加 Redis 实例来实现扩容需求。

Codis 是无状态的，它只是一个转发代理中间件，这意味着我们可以启动多个Codis 实例，供客户端使用，每个 Codis 节点都是对等的。因为单个 Codis 代理能支撑的

QPS 比较有限，通过启动多个 Codis 代理可以显著增加整体的 QPS 需求，还能起到容灾功能，挂掉一个 Codis 代理没关系，还有很多 Codis 代理可以继续服务。

![image-20221116162439711](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116162439711.png)

#### 分片原理

Codis 要负责将特定的 key 转发到特定的 Redis 实例，Codis 将所有的 key 默认划分为 1024 个槽位(slot)，它首先对客户端传过来的 key 进行 crc32 运算计算哈希值，再将 hash 后的整数值对 1024 这个整数进行取模得到一个余数，这个余数就是对应 key 的槽位。

每个槽位都会唯一映射到后面的多个 Redis 实例之一，Codis 会在内存维护槽位和Redis 实例的映射关系。有了key 对应的槽位，那么应该转发到哪个 Redis 实例就很明确。

槽位数量默认是 1024，它是可以配置的，如果集群节点比较多，建议将这个数值配置大一些，比如 2048、4096。

#### **不同的** **Codis** 实例之间槽位关系如何同步?

如果 Codis 的槽位映射关系只存储在内存里，那么不同的 Codis 实例之间的槽位关系就无法得到同步。所以 Codis 还需要一个分布式配置存储数据库专门用来持久化槽位关系。Codis 开始使用 ZooKeeper，后来连 etcd 也一块支持了。

![image-20221116164044757](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116164044757.png)

Codis 将槽位关系存储在 zk 中，并且提供了一个 Dashboard 可以用来观察和修改槽位关系，当槽位关系变化时，Codis Proxy 会监听到变化并重新同步槽位关系，从而实现多个Codis Proxy 之间共享相同的槽位关系配置。

#### 扩容

当codis只有一个redis服务时，1024个槽都指向同一个redis1，数据量过大时，需要进行扩容，此时这1024个槽就需要分配到两个redis中，此时原来存储到redis1上的部分数据就需要迁移到redis2，因为此时两个redis共享同一个codis。

**问题：codis如何找到redis2对应的所有key？**

Codis 对 Redis 进行了改造，增加了 SLOTSSCAN 指令，可以遍历指定 slot 下所有的key。Codis 通过 SLOTSSCAN 扫描出待迁移槽位的所有的 key，然后挨个迁移每个 key 到新的 Redis 节点。

更多内容查看redis深度历险

## 7. redis-cluster

redis-cluster是去中心化的，如图所示，**该集群有三个 Redis 节点组成，每个节点负责整个集群的一部分数据，每个节点负责的数据多少可能不一样。**

这三个节点相互连接组成一个对等的集群，它们之间通过一种特殊的二进制协议相互交互集群信息。

![image-20221116170813558](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116170813558.png)

当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息。这样当客户端要查找某个 key 时，可以直接定位到目标节点。

Codis 需要通过 Proxy 来定位目标节点，RedisCluster 是直接定位。客户端为了可以直接定位某个具体的 key 所在的节点，它就需要缓存槽位相关信息，这样才可以准确快速地定位到相应的节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。

RedisCluster 的每个节点会将集群的配置信息持久化到配置文件中，所以必须确保配置文件是可写的，而且尽量不要依靠人工修改配置文件。

**槽位定位算法**

Cluster 默认会对 key 值使用 crc32 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。

Cluster 还允许用户强制某个 key 挂在特定槽位上，通过在 key 字符串里面嵌入 tag 标记，这就可以强制 key 所挂在的槽位等于 tag 所在的槽位。

**跳转**

当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。

```java
GET x
-MOVED 3999 127.0.0.1:6381
```

MOVED 指令的第一个参数 3999 是 key 对应的槽位编号，后面是目标节点地址。MOVED 指令前面有一个减号，表示该指令是一个错误消息。

客户端收到 MOVED 指令后，要立即纠正本地的槽位映射表。后续所有 key 将使用新的槽位映射表。

**迁移**

Redis Cluster 提供了工具 redis-trib 可以让运维人员手动调整槽位的分配情况，通过组合各种原生的 Redis Cluster 指令来实现。

![image-20221116172425535](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221116172425535.png)

Redis 迁移的单位是槽，Redis 一个槽一个槽进行迁移，当一个槽正在迁移时，这个槽就处于中间过渡状态。这个槽在原节点的状态为 migrating，在目标节点的状态为 importing，表示数据正在从源流向目标。

更多查看书籍

## 8. redis信息查看指令

参考书籍，INFO指令

## 9. 过期策略

### 过期策略

Redis 所有的数据结构都可以设置过期时间，时间一到，就会自动删除。

问题：redis是单线程的，删除的时间也会占用线程的处理时间，如果删除时间过长，有可能影响redis的效率。

删除策略：

1. 定时扫描：为每个有过期时间的key存放到一个单独的字典，定时遍历删除过期key。
2. 访问key的时候，对key的过期时间进行检查，过期就立即删除。

**定时扫描策略：**

Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。

 1、从过期字典中随机 20 个 key；

 2、删除这 20 个 key 中已经过期的 key；

 3、如果过期的 key 比率超过 1/4，那就重复步骤 1；

同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。

如果短时间内，redis大量key同时过期，那么Redis 会持续扫描过期字典 (循环多次)，直到过期字典中过期的 key 变得稀疏，才会停止 (循环次数明显下降)。这就会导致线上读写请求出现明显的卡顿现象。

另外，删除时内存管理器需要频繁回收内存页，这也会产生一定的 CPU 消耗。

有大批量的 key 过期，要给过期时间设置一个随机范围，而不能全部在同一时间过期。项目中：未设置过期时间的key设置一个默认的过期时间范围在2-3小时内随机。

### 从库过期策略

从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的key。

因为指令同步是异步进行的，所以主库过期的 key 的 del 指令没有及时同步到从库的话，会出现主从数据的不一致，主库没有的数据在从库里还存在。

### 回收算法

当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)，交换会让 Redis 的性能急剧下降。

在生产环境中我们是不允许 Redis 出现交换行为的，为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。

当实际内存超出 maxmemory 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。

**noeviction** ：拒绝写，可以删。线上业务不能继续运行，默认的淘汰策略。

**volatile-lru**：尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。

**volatile-ttl：** 根据key 的剩余寿命 ttl 的值进行淘汰，ttl 越小越优先被淘汰。

**volatile-random**：淘汰的 key 是过期 key 集合中随机的 key。

**allkeys-lru：**淘汰所有key，这意味着没有设置过期时间的 key 也会被淘汰。 

**allkeys-random:** 跟上面一样，淘汰随机的 key。

总结：volatile策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的key 进行淘汰。

如果你只拿 Redis 做缓存，那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法汰。

**LRU算法**

实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照一定的顺序进行排列。当空间满的时候，会踢掉链表尾部的元素。当字典的某个元素被访问时，它在链表中的位置会被移动到表头。所以链表的元素排列顺序就是元素最近被访问的时间顺序。

位于链表尾部的元素就是不被重用的元素，所以会被踢掉。位于表头的元素就是最近刚刚被人用过的元素，所以暂时不会被踢。

**Redis的LRU算法**

Redis 使用的是一种近似 LRU 算法，因为使用LRU算法，需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造。

redis实现lru:

在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。Redis 为实现近似 LRU 算法，它给每个 key 增加了一个额外的小字段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳。

key 过期方式分为集中处理和懒惰处理，LRU 淘汰不一样，它的处理方式只有懒惰处理。

Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次LRU淘汰算法。这个算法也很简单，就是随机采样出 5(可以配置) 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于maxmemory 为止。

如何采样就是看 maxmemory-policy 的配置，如果是 allkeys 就是从所有的 key 字典中随机，如果是 volatile 就从带过期时间的 key 字典中随机。每次采样多少个 key 看的是maxmemory_samples 的配置，默认为 5。

Redis3.0 在算法中增加了淘汰池，进一步提升了近似 LRU 算法的效果。淘汰池是一个数组，它的大小是 maxmemory_samples，在每一次淘汰循环中，新随机出

来的 key 列表会和淘汰池中的 key 列表进行融合，淘汰掉最旧的一个 key 之后，保留剩余较旧的 key 列表放入淘汰池中留待下一个循环。

## 10. 懒惰删除

redis是单线程的，但内部并不是只有一个线程，还有几个异步线程来处理一些耗时操作。

### 对象删除

删除指令 del 会直接释放对象的内存，大部分情况下，这个指令非常快，没有明显延迟。不过如果删除的 key 是一个非常大的对象，比如一个包含了千万元素的 hash，那么删除操作就会导致单线程卡顿。

4.0 版本引入了 unlink 指令，它能对删除操作进行懒处理，丢给后台线程来异步回收内存。

命令： unlink key

unlink之后，在主线程中就访问不到该变量了，因此不会出现脏读问题。

并不是所有的unlink都会异步处理，如果key的内容比较小，key的内存会立即回收，和del指令一样。

### flush

flushdb 和 flushall 指令，用来清空数据库，这也是极其缓慢的操作。

Redis 4.0 同样给这两个指令也带来了异步化，在指令后面增加 async 交给后台线程处理。

### 异步队列

后台线程执行删除任务时，会将任务放入异步任务队列，后台线程会从这个异步队列中取任务。任务队列被主线程和异步线程同时操作，所以必须是一个线程安全的队列。

![image-20221117114652697](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117114652697.png)

#### AOF SYNC

Redis 需要每秒一次(可配置)同步 AOF 日志到磁盘，确保消息尽量不丢失，需要调用sync 函数，这个操作会比较耗时，会导致主线程的效率下降，所以 Redis 也将这个操作移到异步线程来完成。执行 AOF Sync 操作的线程是一个独立的异步线程，和前面的懒惰删除线程不是一个线程，同样它也有一个属于自己的任务队列，队列里只用来存放 AOF Sync 任务。

#### 更多的异步删除点

Redis 回收内存除了 del 指令和 flush 之外，还会存在于在 key 的过期、LRU 淘汰、rename 指令以及从库全量同步时接受完 rdb 文件后会立即进行的 flush 操作。

Redis4.0 为这些删除点也带来了异步删除机制，打开这些点需要额外的配置选项。

 1、slave-lazy-flush 从库接受完 rdb 文件后的 flush 操作

 2、lazyfree-lazy-eviction 内存达到 maxmemory 时进行淘汰

 3、lazyfree-lazy-expire key 过期删除

 4、lazyfree-lazy-server-del rename 指令删除 destKey

## 11. 安全通信

参照redis深度历险书籍。

# Redis内部结构

## 1. 字符串

### SDS结构

redis没有使用C语言的字符串(以空字符结尾的字符数组)，而是自己构建的简单动态字符串（SDS），是redis的默认字符串。

rredis中，c字符串只用于一些无需对字符串修改的字面量，如日志打印。

当redis需要可被修改的字符串时，使用的是SDS。

```java
SET msg "hello world"
键值对的键是一个字符串对象，对象的底层实现是一个保存着字符串“msg”的SDS
键值对的值也是一个字符串对象，对象的底层实现是一个保存着字符串“hello world”的SDS
```

保存数据库中的字符串值之外，SDS还被用作缓冲区（buffer）：AOF模块中的AOF缓冲区，以及客户端状态中的输入缓冲区，都是由SDS实现的

SDS结构：

```c
struct sds {
    int len;// buf 中已占用字节数
    int free;// buf 中剩余可用字节数
    char buf[];// 数据空间
};
```

![image-20221117155613059](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117155613059.png)

·free属性的值为0，表示这个SDS没有分配任何未使用空间。

·len属性的值为5，表示这个SDS保存了一个五字节长的字符串。

·buf属性是一个char类型的数组，数组的前五个字节分别保存了'R'、'e'、'd'、'i'、's'五个字符，而最后一个字节则保存了空字符'\0'。

SDS遵循C字符串以空字符结尾的惯例，保存空字符的1字节空间不计算在SDS的len属性里面，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都是由SDS函数自动完成的，所以这个空字符对于SDS的使用者来说是完全透明的。遵循空字符结尾这一惯例的好处是，SDS可以直接重用一部分C字符串函数库里面的函数。

### SDS和C字符串区别

#### 1. 字符串长度记录

C语言使用长度为N+1的字符数组来表示长度为N的字符串，并且字符数组的最后一个元素总是空字符'\0'。

C语言使用的这种简单的字符串表示方式，并不能满足Redis对字符串在安全性、效率以及功能方面的要求。

C字符串并不记录自身的长度信息，所以为了获取一个C字符串的长度，程序必须遍历整个字符串，对遇到的每个字符进行计数，直到遇到代表字符串结尾的空字符为止，这个操作的复杂度为O（N）。

![image-20221117160505475](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117160505475.png)

SDS在len属性中记录了SDS本身的长度，所以获取一个SDS长度的复杂度仅为O（1）。

**通过使用SDS而不是C字符串，Redis将获取字符串长度所需的复杂度从O（N）降低到了O（1），这确保了获取字符串长度的工作不会成为Redis的性能瓶颈。**

#### 2. 杜绝缓冲区溢出

C字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出（buffer overflow）。

char *strcat(char *dest, const char *src);为拼接字符串 可以将src拼接到dest末尾。

因为C字符串不记录自身的长度，所以strcat假定用户在执行这个函数时，已经为dest分配了足够多的内存，可以容纳src字符串中的所有内容，而一旦这个假定不成立时，就会产生缓冲区溢出。

假设程序里有两个在内存中紧邻着的C字符串s1和s2，其中s1保存了字符串"Redis"，而s2则保存了字符串"MongoDB"

![image-20221117162222722](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117162222722.png)

**使用c字符串拼接**

执行：strcat(s1, " Cluster");

将s1的内容修改为"Redis Cluster"，忘了在执行strcat之前为s1分配足够的空间，那么在strcat函数执行之后，s1的数据将溢出到s2所在的空间中，导致s2保存的内容被意外地修改。

![image-20221117162906989](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117162906989.png)

SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能性：当SDS API需要对SDS进行修改时，

API会先检查SDS的空间是否满足修改所需的要求，如果不满足的话，API会自动将SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用SDS既不需要手动修改SDS的空间大小，也不会出现前面所说的缓冲区溢出问题。

```c
int main ()
{
    //c创建字符串：char site[7] = {'R', 'U', 'N', 'O', 'O', 'B', '\0'};
    
   char src[50], dest[50];
 
   strcpy(src,  "This is source");      //将This is source放入src
   strcpy(dest, "This is destination"); //将This is destination放入dest
 
   strcat(dest, src);//将src拼接到dest后面
  
   printf("最终的目标字符串： |%s|", dest); // |This is destinationThis is source|
   
   return(0);
}
```

**使用SDS拼接**

将s1的内容修改为"Redis Cluster"，执行：strcat(s1, " Cluster");

sdscat将在执行拼接操作之前检查s的长度是否足够，在发现s目前的空间不足以拼接"Cluster"之后，sdscat就会先扩展s的空间，然后才执行拼接"Cluster"的操作

![image-20221117162536702](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117162536702.png)

拼接完成后，len为13，并且还多分配了13个字节的未使用空间。

#### 3. 减少修改字符串时带来的内存重分配次数

C字符串并不记录自身的长度，所以对于一个包含了N个字符的C字符串来说，这个C字符串的底层实现总是一个N+1个字符长的数组（额外的一个字符空间用于保存空字符）。因为C字符串的长度和底层数组的长度之间存在着这种关联性，所以每次增长或者缩短一个C字符串，程序都总要对保存这个C字符串的数组进行一次内存重分配操作：

·如果程序执行的是增长字符串的操作，比如拼接操作（append），那么在执行这个操作之前，程序需要先通过内存重分配来扩展底层数组的空间大小——如果忘了这一步就会产生缓冲区溢出。

·如果程序执行的是缩短字符串的操作，比如截断操作（trim），那么在执行这个操作之后，程序需要通过内存重分配来释放字符串不再使用的那部分空间——如果忘了这一步就会产生内存泄漏。

举例：

s：redis

将s的值改为 redis cluster；执行strcat(s, " Cluster")，此时需要对s内存空间重新分配，扩容s

再将redis cluster 改为 redis cluster Tutorial;执行 strcat(s, " Tutorial")，此时需要对s内存空间重新分配，扩容s

如果对字符串频繁修改，就需要进行频繁的扩容或缩容，这个操作比较耗时。

**一般程序中，字符串很少发生变化，可以容忍内存空间的扩展，但redis对速度要求严苛、数据被频繁修改的场合，如果每次修改数据都进行扩容或缩容，会大大降低性能**

**sds实现**

SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联：在SDS中，buf数组的长度不一定就是字符数量加一，数组里面可以包含未使用的字节，而这些字节的数量就由SDS的free属性记录。

SDS实现了空间预分配和惰性空间释放两种优化策略：

1. 空间预分配

   空间预分配用于优化SDS的字符串增长操作：当SDS的API对一个SDS进行修改，并且需要对SDS进行空间扩展的时候，**程序不仅会为SDS分配修改所必须要的空间，还会为SDS分配额外的未使用空间。**

   如果对SDS进行修改之后，SDS的长度（也即是len属性的值）将小于1MB，那么程序分配和len属性同样大小的未使用空间，这时SDS len属性的值将和free属性的值相同。举个例子，如果进行修改之后，SDS的len将变成13字节，那么程序也会分配13字节的未使用空间，SDS的buf数组的实际长度将变成13+13+1=27字节（额外的一字节用于保存空字符）。

   ·如果对SDS进行修改之后，SDS的长度将大于等于1MB，那么程序会分配1MB的未使用空间。举个例子，如果进行修改之后，SDS的len将变成30MB，那么程序会分配1MB的未使用空间，SDS的buf数组的实际长度将为30MB+1MB+1byte。

   **通过空间预分配策略，Redis可以减少连续执行字符串增长操作所需的内存重分配次数。**

   在扩展SDS空间之前，SDS API会先检查未使用空间是否足够，如果足够的话，API就会直接使用未使用空间，而无须执行内存重分配。

   ![image-20221117170058188](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117170058188.png)

2. 惰性空间释放

   惰性空间释放用于优化SDS的字符串缩短操作：当SDS的API需要缩短SDS保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用。

   sdstrim函数接受一个SDS和一个C字符串作为参数，移除SDS中所有在C字符串中出现过的字符。

   ![image-20221117171931668](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117171931668.png)

   sdstrim(s, "XY"); // 移除SDS 字符串中的所有'X' 和'Y'  

   ![image-20221117172232379](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117172232379.png)

   sdstrim之后的SDS并没有释放多出来的8字节空间，而是将这8字节空间作为未使用空间保留在了SDS里面，如果将来要对SDS进行增长操作的话，这些未使用空间就可能会派上用场。

   sdscat(s, " Redis");那么完成这次sdscat操作将不需要执行内存重分配：因为SDS里面预留的8字节空间已经足以拼接6个字节长的"Redis"

   ![image-20221117172324555](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117172324555.png)

   **通过惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能有的增长操作提供了优化。SDS也提供了相关API，在有需要的时候真正释放SDS空间**

#### 4. 二进制安全

C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串**只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据**。

如果有一种使用空字符来分割多个单词的特殊数据格式，那么这种格式就不能使用C字符串来保存，因为C字符串所用的函数只会识别出其中的"Redis"，而忽略之后的"Cluster"。

![image-20221117194804815](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117194804815.png)

为了确保Redis可以适用于各种不同的使用场景，SDS的API都是二进制安全的（binary-safe），所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，它被读取时就是什么样。

Redis使用buf数组来保存二进制数据，而非保存字符。

使用SDS来保存之前提到的特殊数据格式就没有任何问题，因为SDS使用len属性的值而不是空字符来判断字符串是否结束。

![image-20221117195751997](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117195751997.png)

使用二进制安全的SDS，而不是C字符串，使得Redis不仅可以保存文本数据，还可以保存任意格式的二进制数据。

#### 5. 兼容部分C字符串函数

SDS的API是二进制安全的，但是遵循C字符串以空字符结尾的惯例：这些API总会将SDS保存的数据的末尾设置为空字符，并且总会在为buf数组分配空间时多分配一个字节来容纳这个空字符，这是为了让那些保存文本数据的SDS可以重用一**部分定义的函数**。

#### 总结：二者区别，同时sds字符串优点

1. SDS字符串获取长度复杂度为O（1），c字符串为O（n）(sds记录了字符串长度，c没有记录，需要遍历)
2. c字符串拼接需要程序员事先分配好内存，如果内存不够会发生内存覆盖。sds会动态分配内存
3. c字符串分配的内存是固定的，如果字符串经常修改，会导致数据频繁的扩大和缩小，严重影响效率。sds发生数据改变时，如果改变后已有内存不满足使用，则进行扩容，扩容后，如果数据大小小于1M，则多申请出一倍已占内存大小，如果大于1M，则多申请1M的内存空间。
4. c字符串保存的是字符数据，遇到空格则认为读取结束，只能存储文本。sds保存的是字节数据，存储二进制流。
5. c字符串可以使用<string.h>库中所有的函数，sds只能使用部分函数。

## 2. 链表

C语言没有内置的链表结构，redis进行了自己的链表实现。

当一个列表键包含了数量比较多的元素，又或者列表中包含的元素都是比较长的字符串时，Redis就会使用链表作为列表键的底层实现。

使用场景：链表键，发布与订阅、慢查询、监视器等功能也用到了链表，Redis服务器本身还使用链表来保存多个客户端的状态信息，以及使用链表来构建客户端输出缓冲区

### 链表的结构

```c
typedef struct listNode {
    // 前置节点
    struct listNode * prev;
    // 后置节点
    struct listNode * next;
    // 节点的值
    void * value;
}listNode
```

多个listNode可以通过prev和next指针组成双端链表

![image-20221117202500348](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221117202500348.png)

```c
typedef struct list {
    // 表头节点
    listNode * head;
    // 表尾节点
    listNode * tail;
    // 链表所包含的节点数量
    unsigned long len;
    // 节点值复制函数
    void *(*dup)(void *ptr);
    // 节点值释放函数
    void (*free)(void *ptr);
    // 节点值对比函数
    int (*match)(void *ptr,void *key);
} list;
```

list结构为链表提供了表头指针head、表尾指针tail，以及链表长度计数器len，而dup、free和match成员则是用于实现多态链表所需的类型特定函数：

·dup函数用于复制链表节点所保存的值；

·free函数用于释放链表节点所保存的值；

·match函数则用于对比链表节点所保存的值和另一个输入值是否相等。

Redis的链表实现的特性：

·双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O（1）。

·无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。

·带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O（1）。

·带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O（1）。

·多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。

## 3. 字典

Redis的数据库就是使用字典来作为底层实现的，对数据库的增、删、查、改操作也是构建在对字典的操作之上的。

SET msg "hello world"

在数据库中创建一个键为"msg"，值为"hello world"的键值对时，这个键值对就是保存在代表数据库的字典里面的。

字典还是哈希键的底层实现之一，**当一个哈希键包含的键值对比较多，或者键值对中的元素都是比较长的字符串时**，Redis就会使用字典作为哈希键的底层实现。

### 字典的实现

Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。

![image-20221118092255063](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118092255063.png)

**hash表**

```c
typedef struct dictht {
    // 哈希表数组
    dictEntry **table;
    // 哈希表大小
    unsigned long size;
    //哈希表大小掩码，用于计算索引值
    //总是等于size-1
    unsigned long sizemask;
    // 该哈希表已有节点的数量
    unsigned long used;
} dictht;
```

table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存着一个键值对。

size属性记录了哈希表的大小，也即是table数组的大小

used属性则记录了哈希表目前已有节点（键值对）的数量。

sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。

一个大小为4的空哈希表（没有包含任何键值对）。

![image-20221118092533453](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118092533453.png)

**hash表节点**

哈希表节点使用dictEntry结构表示，每个**dictEntry结构都保存着一个键值对**

```c
typedef struct dictEntry {
    // 键
    void *key;
    // 值
    union{
        void *val;
        uint64_tu64;
        int64_ts64;
    } v;
    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;
} dictEntry;
```

key属性保存着键值对中的键，而v属性则保存着键值对中的值，其中键值对的值可以是一个指针，或者是一个uint64_t整数，又或者是一个int64_t整数。

next属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来解决键冲突（collision）的问题。

![image-20221118092834473](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118092834473.png)

**字典**

```c
typedef struct dict {
    // 类型特定函数
    dictType *type;
    // 私有数据
    void *privdata;
    // 哈希表
    dictht ht[2];
    // rehash索引
    //当rehash不在进行时，值为-1
    in trehashidx; /* rehashing not in progress if rehashidx == -1 */
} dict;
```

type属性和privdata属性是针对不同类型的键值对，为创建多态字典而设置的：

type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于**操作特定类型键值对的函数**，Redis会为用途不同的字典设置不同的类型特定函数。

privdata属性则保存了需要传给那些类型特定函数的可选参数。

```c
typedef struct dictType {
    // 计算哈希值的函数
    unsigned int (*hashFunction)(const void *key);
    // 复制键的函数
    void *(*keyDup)(void *privdata, const void *key);
    // 复制值的函数
    void *(*valDup)(void *privdata, const void *obj);
    // 对比键的函数
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);
    // 销毁键的函数
    void (*keyDestructor)(void *privdata, void *key);
    // 销毁值的函数
    void (*valDestructor)(void *privdata, void *obj);
} dictType;
```

ht属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。

除了ht[1]之外，另一个和rehash有关的属性就是rehashidx，它记录了rehash目前的进度，如果目前没有在进行rehash，那么它的值为-1。

一个普通状态下（没有进行rehash）的字典。

![image-20221118093937163](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118093937163.png)

### hash算法

当要将一个新的键值对添加到字典里面时，程序需要先根据键值对的键计算出哈希值和索引值，然后再根据索引值，将包含新键值对的哈希表节点放到哈希表数组的指定索引上面。

Redis计算哈希值和索引值的方法

```c
#使用字典设置的哈希函数，计算键key的哈希值
hash = dict->type->hashFunction(key);
#使用哈希表的sizemask属性和哈希值，计算出索引值
#根据情况不同，ht[x]可以是ht[0]或者ht[1]
index = hash & dict->ht[x].sizemask;  # 两个位都为1时，结果才为1
```

将一个键值对k0和v0添加到字典，假如sizemask为3，size为4

1. hash = dict->type->hashFunction(k0);假设计算得出的哈希值为8
2. index = hash&dict->ht[0].sizemask = 8 & 3 = 0;
3. 计算出键k0的索引值0，这表示包含键值对k0和v0的节点应该被放置到哈希表数组的索引0位置

当字典被用作数据库的底层实现，或者哈希键的底层实现时，Redis使用MurmurHash2算法来计算键的哈希值。

算法的优点在于，即使输入的键是有规律的，算法仍能给出一个很好的随机分布性，并且算法的计算速度也非常快。

Redis使用的是MurmurHash2,[(382条消息) 哈希MurmurHash算法详解_yjgithub的博客-CSDN博客_murmurhash](https://blog.csdn.net/yjgithub/article/details/120447399)

### 键冲突

当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时，我们称这些键发生了冲突

Redis的哈希表使用链地址法（separate chaining）来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，这就解决了键冲突的问题。

因为dictEntry节点组成的链表没有指向链表表尾的指针，所以为了速度考虑，程序总是将新节点添加到链表的表头位置（复杂度为O（1）），排在其他已有节点的前面。

![image-20221118095627042](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118095627042.png)

### rehash

随着操作的不断执行，哈希表保存的键值对会逐渐地增多或者减少，为了让哈希表的负载因子（load factor）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。扩展和收缩哈希表的工作可以通过执行rehash（重新散列）操作来完成。

执行步骤：

1. 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及**ht[0]当前包含的键值对数量（也即是ht[0].used属性的值）**
   1. 如果执行的是扩展操作，那么ht[1]的大小为**第一个大于等于ht[0].used*2**的（2的n次方幂）；
   2. 如果执行的是收缩操作，那么ht[1]的大小为**第一个大于等于ht[0].used**的2的n次方幂）；
2. 将保存在ht[0]中的所有键值对rehash到ht[1]上面：**rehash指的是重新计算键的哈希值和索引值，**然后将键值对放置到ht[1]哈希表的指定位置上。
3. 当ht[0]包含的所有键值对都迁移到了ht[1]之后（ht[0]变为空表），**释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表**，为下一次rehash做准备。

**哈希表的扩展与收缩条件**

当以下条件中的任意一个被满足时，程序会自动开始对哈希表执行扩展操作：

1. 服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于1。

   Redis Bgsave 命令用于在后台异步保存当前数据库的数据到磁盘。

   Redis Bgrewriteaof 命令用于异步执行一个 AOF（AppendOnly File） 文件重写操作。重写会创建一个当前 AOF 文件的体积优化版本。

2. 服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于5。

```c
# 负载因子 = 哈希表已保存节点数量/ 哈希表大小
load_factor = ht[0].used / ht[0].size
```

根据BGSAVE命令或BGREWRITEAOF命令是否正在执行，服务器执行扩展操作所需的负载因子并不相同，这是因为在执行BGSAVE命令或BGREWRITEAOF命令的过程中，Redis需要创建当前服务器进程的子进程，而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免在子进程存在期间进行哈希表扩展操作，这可以避免不必要的内存写入操作，最大限度地节约内存。

写时复制：子线程向磁盘写数据时，会读取主存中的数据，如果主存中的数据没有改变不影响，如果改变了，则拷贝一个副本，将副本写入磁盘。如果在BGSAVE过程中，发生了rehash，那么数据的内存空间发生变化，需要拷贝大量数据的副本，浪费内存空间。

另一方面，当哈希表的负载因子小于0.1时，程序自动开始对哈希表执行收缩操作。

### 渐进式rehash

扩展或收缩哈希表需要将ht[0]里面的所有键值对rehash到ht[1]里面，但是，这个rehash动作并不是一次性、集中式地完成的，而是分多次、渐进式地完成的。

如果ht[0]里只保存着四个键值对，那么服务器可以在瞬间就将这些键值对全部rehash到ht[1]；但是，如果哈希表里保存的键值对数量不是四个，而是四百万、四千万甚至四亿个键值对，那么要一次性将这些键值对全部rehash到ht[1]的话，庞大的计算量可能会导致服务器在一段时间内停止服务。

为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。

渐进式rehash步骤：

1. 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。
2. 在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。
3. 在rehash进行期间，**每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一。**
4. 随着字典操作的不断执行，**最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1**，表示rehash操作已完成。

渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。

**渐进式rehash操作**

因为在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行。例如，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。

另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。

查找：先找ht[o]，找到了将ht[0]的搬迁到ht[1]，并删除ht[0]

删除：ht[o]有直接删除，没有则在ht[1]删除

增加：直接新增到ht[1]

更新：将ht[o]搬到ht[1]，再进行更新。

### 总结

·字典被广泛用于实现Redis的各种功能，其中包括数据库和哈希键。

·Redis中的字典使用哈希表作为底层实现，每个字典带有两个哈希表，一个平时使用，另一个仅在进行rehash时使用。

·当字典被用作数据库的底层实现，或者哈希键的底层实现时，Redis使用MurmurHash2算法来计算键的哈希值。

·哈希表使用链地址法来解决键冲突，被分配到同一个索引上的多个键值对会连接成一个单向链表。

·在对哈希表进行扩展或者收缩操作时，程序需要将现有哈希表包含的所有键值对rehash到新哈希表里面，并且这个rehash过程并不是一次性地完成的，而是渐进式地完成的。

## 4. 压缩链表

压缩链表是Redis 为了**节约内存空间**使用，由一系列特殊编码的连续内存块组成的**顺序型**（sequential）数据结构。

zset 和 hash 容器（set和hash）对象在元素个数较少，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串的时候，采用压缩列表 (ziplist) 进行存储。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。

```java
127.0.0.1:6379> zadd programmings 1.0 go 2.0 python 3.0 java
(integer) 3
127.0.0.1:6379> OBJECT ENCODING programmings
"ziplist"
```

```c
struct ziplist<T> {
 int32 zlbytes; // 整个压缩列表占用字节数
 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点
 int16 zllength; // 元素个数
 T[] entries; // 元素内容列表，挨个挨个紧凑存储
 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF
}
```

![image-20221118130204884](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118130204884.png)

压缩列表为了支持双向遍历，所以才会有 ztail_offset 这个字段，用来快速定位到最后一个元素，然后倒着遍历。

entry 块随着容纳的元素类型不同，也会有不一样的结构。

```c
struct entry {
 int<var> prevlen; // 前一个 entry 的字节长度
 int<var> encoding; // 元素类型编码
 optional byte[] content; // 元素内容
}
```

**它的 prevlen 字段表示前一个 entry 的字节长度**，当压缩列表倒着遍历时，需要通过这个字段来快速定位到下一个元素的位置。

prevlen 是一个变长的整数，**当字符串长度小于254(0xFE) 时，使用一个字节表示**；如果达到或超出 254(0xFE) 那就使用 5 个字节来表示。第一个字节是 0xFE(254)，剩余四个字节表示字符串长度。

encoding 字段存储了元素内容的编码类型信息，ziplist 通过这个字段来决定后面的content 内容的形式。

### 添加元素

因为 ziplist 都是紧凑存储，没有冗余空间 (对比一下 Redis 的字符串结构)。意味着插入一个新的元素就需要调用 realloc 扩展内存。取决于内存分配器算法和当前的 ziplist 内存大小，**realloc 可能会重新分配新的内存空间**，**并将之前的内容一次性拷贝到新的地址，也可能在原有的地址上进行扩展，这时就不需要进行旧内容的内存拷贝。**

如果 ziplist 占据内存太大，重新分配内存和拷贝内存就会有很大的消耗。所以 ziplist 不适合存储大型字符串，存储的元素也不宜过多。

### 级联更新

每个 entry 都会有一个 prevlen 字段存储前一个 entry 的长度。如果内容小于254 字节，prevlen 用 1 字节存储，否则就是 5 字节。这意味着如果某个 entry 经过了修改

操作从 253 字节变成了 254 字节，那么它的下一个 entry 的 prevlen 字段就要更新，从 1 个字节扩展到 5 个字节；如果这个 entry 的长度本来也是 253 字节，那么后面 entry 的prevlen 字段还得继续更新。

如果 ziplist 里面每个 entry 恰好都存储了 253 字节的内容，那么第一个 entry 内容的修改就会导致后续所有 entry 的级联更新，这就是一个比较耗费计算资源的操作。

## 小整数集合

当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。

Redis Sadd 命令将一个或多个成员元素加入到集合中，已经存在于集合的成员元素将被忽略。

```java
127.0.0.1:6379> SADD codeholes 1 2 3
(integer) 3
127.0.0.1:6379> OBJECT ENCODING codeholes
"intset"
```

### 实现方式

![image-20221118132636945](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118132636945.png)

```c
struct intset<T> {
 int32 encoding; // 决定整数位宽是 16 位、32 位还是 64 位
 int32 length; // 元素个数
 int<T> contents; // 整数数组，可以是 16 位、32 位和 64 位
}
```

·整数集合是集合键的底层实现之一。

·整数集合的底层实现为数组，这个数组以有序、无重复的方式保存集合元素，在有需要时，程序会根据新添加元素的类型，改变这个数组的类型。

·升级操作为整数集合带来了操作上的灵活性，并且尽可能地节约了内存。

·整数集合只支持升级操作，不支持降级操作。

更多内容查看书籍：redis设计与实现。

## 快速列表

Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表linkedlist，也就是元素少时用 ziplist，元素多时用 linkedlist。

```java
// 链表的节点
struct listNode<T> {
 listNode* prev;
 listNode* next;
 T value;
}
// 链表
struct list {
 listNode *head;
 listNode *tail;
 long length;
}
```

链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。

```c
127.0.0.1:6379> rpush name 1 2 3 4
(integer) 5
127.0.0.1:6379> OBJECT ENCODING name
"quicklist"
```

### 实现

![image-20221118133538643](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118133538643.png)

```c
struct ziplist<T> {
 int32 zlbytes; // 整个压缩列表占用字节数
 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点
 int16 zllength; // 元素个数
 T[] entries; // 元素内容列表，挨个挨个紧凑存储
 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF
}
struct ziplist_compressed {
 int32 size;
 byte[] compressed_data;
}
struct quicklistNode {
 quicklistNode* prev;
 quicklistNode* next;
 ziplist* zl; // 指向压缩列表
 int32 size; // ziplist 的字节总数
 int16 count; // ziplist 中的元素数量
 int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储
 ...
}
struct quicklist {
 quicklistNode* head;
 quicklistNode* tail;
 long count; // 元素总数
 int nodes; // ziplist 节点的个数
 int compressDepth; // LZF 算法压缩深度
 ...
}
```

为了进一步节约空间，Redis 还会对ziplist 进行压缩存储，使用 LZF 算法压缩，可以选择压缩深度。

### 每个ziplist存多少元素

quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个ziplist。ziplist 的长度由配置参数 list-max-ziplist-size 决定。

> \# -5: max size: 64 Kb <-- not recommended for normal workloads
>
> \# -4: max size: 32 Kb <-- not recommended
>
> \# -3: max size: 16 Kb <-- probably not recommended
>
> \# -2: max size: 8 Kb <-- good
>
> \# -1: max size: 4 Kb <-- good

### 压缩深度

![image-20221118134300913](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118134300913.png)

quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数 listcompress-depth 决定。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压

缩，此时深度就是 1。如果深度为 2，就表示 quicklist 的首尾第一个 ziplist 以及首尾第二个 ziplist 都不压缩。

### 性能对比

[Redis Quicklist - From a More Civilized Age (matt.sh)](https://matt.sh/redis-quicklist)

## 紧凑链表

### 结构实现

Redis 5.0 又引入了一个新的数据结构 listpack，它是对 ziplist 结构的改进，在存储空间上会更加节省，而且结构上也比 ziplist 要精简。

```c
struct listpack<T> {
 int32 total_bytes; // 占用的总字节数
 int16 size; // 元素个数
 T[] entries; // 紧凑排列的元素列表
 int8 end; // 同 zlend 一样，恒为 0xFF
}
```

![image-20221118134617413](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118134617413.png)

 

listpack 跟 ziplist 的结构几乎一摸一样，只是少了一个 zltail_offset 字段。ziplist 通过这个字段来定位出最后一个元素的位置，用于逆序遍历。

```c
struct lpentry {
 int<var> encoding;
 optional byte[] content;
 int<var> length;
}
```

元素的结构和 ziplist 的元素结构也很类似，都是包含三个字段。不同的是长度字段放在了元素的尾部，而且存储的不是上一个元素的长度，是当前元素的长度。正是因为长度放在了尾部，所以可以省去了 zltail_offset 字段来标记最后一个元素的位置，这个位置可以通过total_bytes 字段和最后一个元素的长度字段计算出来。

长度字段使用 varint 进行编码，不同于 skiplist 元素长度的编码为 1 个字节或者 5 个字节，listpack 元素长度的编码可以是 1、2、3、4、5 个字节。

Redis 为了让 listpack 元素支持很多类型，它对 encoding 字段也进行了较为复杂的设计

### 级联更新

listpack 的设计彻底消灭了 ziplist 存在的级联更新行为，元素与元素之间完全独立，不会因为一个元素的长度变长就导致后续的元素内容会受到影响。

### 取代ziplist

listpack 的设计的目的是用来取代 ziplist，不过当下还没有做好替换 ziplist 的准备，因为有很多兼容性的问题需要考虑，ziplist 在 Redis 数据结构中使用太广泛了，替换起来复杂度会非常之高。它目前只使用在了新增加的 Stream 数据结构中。

## 4.跳表

[Redis内部数据结构详解(6)——skiplist - 铁蕾的个人博客 (zhangtielei.com)](http://zhangtielei.com/posts/blog-redis-skiplist.html)

[数据结构与算法——跳表 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/68516038)

Redis 的 zset 是一个复合结构，一方面它需要一个 hash 结构来存储 value 和 score 的对应关系，另一方面需要提供按照 score 来排序的功能，还需要能够指定 score 的范围来获取 value 列表的功能，这就需要另外一个结构「跳跃列表」。

zset 的内部实现是一个 hash 字典加一个跳跃列表 (skiplist)。

![image-20221118104404064](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118104404064.png)

![image-20221118104507501](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118104507501.png)

Redis 的跳跃表共有 64 层，意味着最

多可以容纳 2^64 次方个元素。

### 结构

```c
节点
struct zslnode {
 string value;
 double score;
 zslnode*[] forwards; // 多层连接指针
 zslnode* backward; // 回溯指针
}
链表
struct zsl {
 zslnode* header; // 跳跃列表头指针
 int maxLevel; // 跳跃列表当前的最高层
 map<string, zslnode*> ht; // hash 结构的所有键值对
}
```

每一个 kv 块对应着一个zslnode 结构，kv header 也是这个结构，只不过 value 字段是 null 值——无效的。

score 是Double.MIN_VALUE，用来垫底的。

kv 之间使用指针串起来形成了双向链表结构，它们是有序 排列的，从小到大。不同的 kv 层高可能不一样，层数越高的 kv 越少。同一层的 kv 会使用指针串起来。每一个层元素的遍历都是从 kv header 出发。

### 查找过程

如果跳表只有一层，需要挨个遍历，复杂度为O（n）

跳跃列表有了多层结构之后，这个定位的算法复杂度将会降到O(lg(n))。

![image-20221118110235865](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118110235865.png)

我们要定位到那个紫色的 kv，需要从 header 的最高层开始遍历找到第一个节点 (最后一个比「我」小的元素)，然后从这个节点开始降一层再遍历找到第二个节点 (最

后一个比「我」小的元素)，然后一直降到最底层进行遍历就找到了期望的节点 (最底层的最后一个比我「小」的元素)

这样，就可以快速找到要查找的元素。

### 添加元素

插入的时候，需要定位到位置，然后插入元素，但是新插入的节点，有多少层，需要使用算法分配。跳跃列表使用的是随机算法。

对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数。直观上期望的目标是 50% 的 Level1，25% 的 Level2，12.5% 的 Level3，一直到最顶层 2^-63，因为这里每一层的晋升概率是 50%。每个跳跃表节点的层高都是1至32之间的随机数。

跳跃列表会记录一下当前的最高层数 maxLevel，遍历时从这个 maxLevel 开始遍历性能就会提高很多。

首先我们在搜索合适插入点的过程中将「搜索路径」摸出来了，然后就可以开始创建新节点了，创建的时候需要给这个节点随机分配一个层数，再将搜索路径上的节点和这个新节点通过前向后向指针串起来。如果分配的新节点的高度高于当前跳跃列表的最大高度，就需要更新一下跳跃列表的最大高度。

![zset](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/zset.png)

### 删除元素

删除过程和插入过程类似，都需先把这个「搜索路径」找出来。然后对于每个层的相关节点都重排一下前向后向指针就可以了。同时还要注意更新一下最高层数 maxLevel。

### 更新元素

我们调用 zadd 方法时，如果对应的 value 不存在，那就是插入过程。如果这个value 已经存在了，只是调整一下 score 的值，那就需要走一个更新的流程。

更新策略：

1. 假设这个新的score 值不会带来排序位置上的改变，那么就不需要调整位置，直接修改元素的 score 值就可以了。但是如果排序位置改变了，那就要调整位置。
2. score发生改变，位置也改变，删除key，再新增。

### score值都一样

 在一个极端的情况下，zset 中所有的 score 值都是一样的，zset 的查找性能会退化为O(n)，zset 的排序元素不只看 score 值，如果score 值相同还需要再比较 value 值 (字符串比较)

### 计算排名

Redis Zrank 返回有序集中指定成员的排名。其中有序集成员按分数值递增(从小到大)顺序排列。

```sql
//添加元素
ZADD runkey 1 redis 2 mysql 3 java 4 go
//获取排名
ZRANK runkey redis
//获取所有排名
ZRANGE runoobkey 0 -1 WITHSCORES
```

Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 span 属性，span 是「跨度」的意思，表示从前一个节点沿着当前层的 forward 指针跳到当前这个节点中间会跳过多少个节点。Redis 在插入删除操作时会更新 span 值的大小。

当我们要计算一个元素的排名时，只需要将「搜索路径」上的经过的所有节点的跨度 span 值进行叠加就可以算出元素的最终 rank 值

```c
typedef struct zskiplistNode {
    // 层
    struct zskiplistLevel {
        // 前进指针
        struct zskiplistNode *forward;
        // 跨度
        unsigned int span;
    } level[];
    // 后退指针
    struct zskiplistNode *backward;
    // 分值
    double score;
    // 成员对象
    robj *obj;
} zskiplistNode;
```

level是一个数组，记录了当前节点拥有的所有层级节点。

![image-20221118114717889](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221118114717889.png)

更详细的查看书籍：redis设计与实现。



# 其他

[(344条消息) redis内存清理实践_sms technonogy的博客-CSDN博客](https://blog.csdn.net/maxi1234/article/details/113882346)

​	

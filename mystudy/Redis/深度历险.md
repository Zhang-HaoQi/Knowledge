# Redis基础

## 0. 学习资源

阿里云文档（进阶操作）：[性能排查与调优 (aliyun.com)](https://help.aliyun.com/document_detail/265988.html)

redis深度历险

## 1. Redis应用场景

1、记录帖子的点赞数、评论数和点击数 (hash)。

2、记录用户的帖子 ID 列表 (排序)，便于快速显示用户的帖子列表 (zset)。

3、记录帖子的标题、摘要、作者和封面信息，用于列表页展示 (hash)。

4、记录帖子的点赞用户 ID 列表，评论 ID 列表，用于显示和去重计数 (zset)。

5、缓存近期热帖内容 (帖子内容空间占用比较大)，减少数据库压力 (hash)。

6、记录帖子的相关文章 ID，根据内容推荐相关帖子 (list)。

7、如果帖子 ID 是整数自增的，可以使用 Redis 来分配帖子 ID(计数器)。

8、收藏集和帖子之间的关系 (zset)。

9、记录热榜帖子 ID 列表，总热榜和分类热榜 (zset)。

10、缓存用户行为历史，进行恶意行为过滤 (zset,hash)。

## 2. Redis数据结构

Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。

Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。

### String

![image-20221112093339578](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093339578.png)

![image-20221112093501306](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112093501306.png)

Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的ArrayList，采用**预分配冗余空间**的方式来减少内存的频繁分配，如图中所示，**内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。**

用途：

1. 单一键值对存储
2. 批量键值对存储
3. int自增

### List

Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为

O(n)。当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。

Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。

用途：

添加数据：rpush books python java golang

1. 可作为队列使用，也可作为栈使用。

   1. 获取长度：  llen books  返回3
   2. 头部弹出数据： lpop books  返回python，队列操作
   3. 尾部弹出数据： rpop books  返回golang，栈操作

2. 慢操作：

   1. lindex books 1 ：获取books的list中索引为1的元素，返回java，复杂度O(n)

   2. lrange books 0 -1  ： 获取所有元素

   3.  ltrim books 1 -1 ：保留链表中第一个元素到倒数第一个元素，其他元素删除掉。返回 java golang

   4. ltrim books 1 0 ：清空元素，因为区间长度为负数

      ```java
      127.0.0.1:6379> rpush books python java golang
      (integer) 3
      127.0.0.1:6379> lrange books 0 -1
      1) "python"
      2) "java"
      3) "golang"
      127.0.0.1:6379> ltrim books 1 -1
      OK
      127.0.0.1:6379> lrange books 0 -1
      1) "java"
      2) "golang"
      127.0.0.1:6379> ltrim books 1 0
      OK
      127.0.0.1:6379> lrange books 0 -1
      (empty array)
      127.0.0.1:6379> 
      ```

3.  快速列表

   ![image-20221112100858789](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100858789.png)

   1. redis底层存储并不是一个简单的linkedlist，而是quicklist。
   2. 当元素较少时，将所有元素紧挨着存储，分配一块连续的内存空间，为压缩链表（ziplist）。
   3. 当元素较多时，将ziplist结合起来组成quicklist。ziplist之间使用双向链表串起来，满足快速插入和删除性能，不会出现太大的空间冗余。
      1. 如果元素与元素之间连接起来，指针占用内存空间，即浪费空间，又导致内存碎片化。

### Hash

类似Java的HashMap，数组+链表结构。

![image-20221112100956407](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112100956407.png)

Redis 的字典的值只能是字符串，rehash 的方式不一样，因为Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 

为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。

![image-20221112143240585](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112143240585.png)

渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个hash 结构，然后在后续的定时任务中以及 hash 的子指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。

### Set

Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。

### ZSET（有序列表）

它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫着「跳跃列表」的数据结构。 

zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。

zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。

**跳跃列表**

zset 内部的排序功能是通过「跳跃列表」数据结构来实现的。

zset要支持随机插入和删除，数组不好表示。插入的元素要排序，要保证链表是有序的，可以通过二分查找快速找到插入点，但是二分查找只适用于数组。因此提出跳跃链表。

![image-20221112144321702](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112144321702.png)

跳跃链表：每个元素分为不同的等级，最低级是所有元素，之后依次向上挑选。

定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。

新插入的元素，采取随机策略来决定新元素可以兼职到第几层。

L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少Redis 数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。

### 数据类型通用规则

list/set/hash/zset 这四种数据结构是容器型数据结构，都满足一下规则：

1. 添加元素时，容器不存在则创建。
2. 删除元素时，容器中没有元素，立即删除元素。
3. 过期时间是以容器为单位的，而非容器中的某个元素。
   1. 如hash设置过期时间是整个hash的过期时间，而非其中一个key的过期时间。

注意：如果一个字符串设置了过期时间，如果再次修改他时，过期时间会失效。

```sql
127.0.0.1:6379> set name zhangsan ex 1000
OK
127.0.0.1:6379> ttl name
(integer) 993
127.0.0.1:6379> set name lisi
OK
127.0.0.1:6379> ttl name
(integer) -1
127.0.0.1:6379> 
127.0.0.1:6379> get name
"lisi"
```

# Redis应用

## 1. 分布式锁

### 分布式锁

使用set is not exits 命令占锁，占锁成功后执行业务，执行完成后释放锁del。

setnx lock true

问题：业务未执行完，发生异常，del没有执行，陷入死锁，锁永远得不到释放。

解决：为锁设置过期时间。

问题：业务时间过长，锁提前释放。业务再次执行时新添加锁，此时之前的业务执行完毕，将新业务的锁释放掉。

解决：

1. 分布式锁不要用于过长时间任务，如果出现了锁现象，数据小范围错乱人工干预。
2. 使用lua脚本，为每次加锁设置一个唯一的随机数，只能此随机数进行锁释放。（设置过期时间的话还有可能造成业务没执行完，锁提前释放问题-使用看门狗机制）

## 2. 异步消息队列

### 异步队列实现

**list实现队列**

对比消息中间件，redis队列没有非常多的高级特性，没有ack保证，如果对消息的可靠性要求较高，不建议使用。

Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用 lpop 和 rpop 来出队列。

![image-20221112151839587](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112151839587.png)

rpush入队，lpop出队。

lpush入队，rpop出队。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> lpop fruit
"apple"
127.0.0.1:6379> lpop fruit
"banana"
127.0.0.1:6379> lpop fruit
"pear"
127.0.0.1:6379> lpop fruit
"orange"
127.0.0.1:6379> lpop fruit
(nil)
```

使用pop获取消息后，进行处理，处理完毕后继续获取。while循环的方式。

如果队列为null，则进行一段睡眠后再pop，降低redis的qps和客户端的cpu占用。

**阻塞读**

问题：一个消费者延迟就是1s，如果是多个消费者，彼此的延迟都是岔开的，实际延迟可能不到1s就有消费者又尝试获取

解决：使用阻塞读 blpop/brpop

阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。

```java
127.0.0.1:6379> rpush fruit apple banana pear orange
(integer) 4
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "apple"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "banana"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "pear"
127.0.0.1:6379> blpop fruit 10
1) "fruit"
2) "orange"
127.0.0.1:6379> blpop fruit 10   //10s后，如果还没有数据，则结束。
(nil)   
(10.07s)
```

注意：如果线程一直闲置在哪里，超过阻塞的时间，redis的客户端连接就成了闲置连接，服务器一端会主动断开链接，减少闲置资源占用，此时blpop/brpop会抛出异常。因此编写客户端要注意捕获异常和重试。

### 加锁失败的处理方式

1. 直接抛出异常，通知用户之后重试
2. sleep一会重试
   1. 如果请求过多，如果一个请求产生死锁，导致之后的请求都无法运行。
3. 请求移交到延时队列，过一会再试。

### 延时队列实现

延时队列可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。

详细实现参考书籍。

## 3. 位图

### 基本使用

开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。

Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下。

位图详解:[Redis bitmap位图操作（图解） (biancheng.net)](http://c.biancheng.net/redis/bitmap.html)

语法：SETBIT key 位 值（0或1）

位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。

**通过位图打印hello**

接下来我们使用位操作将字符串设置为 hello (不是直接使用 set 指令)，首先我们需要得到 hello 的 ASCII 码，用 Python 命令行可以很方便地得到每个字符的 ASCII 码的二进制值。

![image-20221112161807776](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112161807776.png)

```java
127.0.0.1:6379> setbit user:2 1 1
(integer) 0
127.0.0.1:6379> setbit user:2 2 1
(integer) 0
127.0.0.1:6379> setbit user:2 4 1
(integer) 0
127.0.0.1:6379> setbit user:2 9 1
(integer) 0
127.0.0.1:6379> setbit user:2 10 1
(integer) 0
127.0.0.1:6379> setbit user:2 13 1
(integer) 0
127.0.0.1:6379> setbit user:2 15 1
(integer) 0
127.0.0.1:6379> get user:2
"he"
```

如果对应位的字节是不可打印字符，redis-cli 会显示该字符的 16 进制形式。

```java
127.0.0.1:6379> setbit user:3 0 1
(integer) 0
127.0.0.1:6379> setbit user:3 2 1
(integer) 0
127.0.0.1:6379> get user:3
"\xa0"
```

### 统计查找

使用bitcount计算字节中1的个数（注意，bitcount是以字节为单位的）

```java
127.0.0.1:6379> bitcount user:2  key user:2中一共有7个1。
(integer) 7
127.0.0.1:6379> bitcount user:2 0 0 key user:2中第一个字节有3个1。
(integer) 3
127.0.0.1:6379> bitcount user:2 0 1  key user:2中前两个字节有7个1。
(integer) 7
```

使用bitpos 用来查找指定范围内出现的第一个 0 或 1

```java
127.0.0.1:6379> bitpos user:2 0  # 第一个 0 位
(integer) 0
127.0.0.1:6379> bitpos user:2 1 # 第一个 1 位
(integer) 1
127.0.0.1:6379> bitpos user:2 1 1 1 # 从第二个字符算起，第一个 1 位
(integer) 9
127.0.0.1:6379> bitpos user:2 1 2 2   # 从第三个字符算起，第一个 1 位
(integer) -1
```

### 魔数指令bitfield

看书

## 4. HyperLogLog

### 统计网站数据

统计**网站每个网页**一天的PV和UV数据。

PV：页面一天访问量（用户每访问一次加一次）  

**解决：**给每个网页设计一个redis计数器，接口请求一次，incrby一次即可。

UV：页面一天访客量（一个用户每天最多纪录一次）

**解决：**

分析：要去重，同一个用户一天之内的多次访问请求只能计数一次。每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一ID 来标识

实现：

为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。

问题：

如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。

另外这些数据不需要太精确，没有必要为这样一个去重功能浪费这么大的内存空间。

### HyperLogLog 

HyperLogLog 提供不精确的去重计数方案，标准误差是 0.81%，精确度已经可以满足上面的 UV 统计需求。

语法：

pfadd  key value  添加一个计数，如果不存在返回1，否则返回0（有误差，但很小）

pfcount key  计算添加的元素数量

pfmerge key1 key2 ...  将多个pf的值进行合并（注意：合并的时候，如果pf1和pf2有重复的，也会进行去重再计算）

```java
连续添加了两次重复的用户，最后计算的数量是5，正确。
127.0.0.1:6379> pfadd hotel user1
(integer) 1
127.0.0.1:6379> pfadd hotel user2
(integer) 1
127.0.0.1:6379> pfadd hotel user3
(integer) 1
127.0.0.1:6379> pfadd hotel user4
(integer) 1
127.0.0.1:6379> pfadd hotel user5
(integer) 1
127.0.0.1:6379> pfadd hotel user1
(integer) 0
127.0.0.1:6379> pfadd hotel user2
(integer) 0
127.0.0.1:6379> pfadd hotel user3
(integer) 0
127.0.0.1:6379> pfadd hotel user4
(integer) 0
127.0.0.1:6379> pfadd hotel user5
(integer) 0
127.0.0.1:6379> pfcount hotel
(integer) 5
```

注意：

该数据结构使用的时候，会占据一定12k的存储空间，并不是和统计单个用户相关的数据。适合流量比较大，对公共数据的统计。

相比set存储方案，HyperLogLog用的空间相对少很多。

Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。

### 实现原理

查看书籍。

## 5. 布隆过滤器

推荐文章：[布隆过滤器，这一篇给你讲的明明白白-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/773205#slide-14)

相关过滤器：布谷鸟过滤器：[布谷鸟过滤器（Cuckoo Filter） - 泰阁尔 - 博客园 (cnblogs.com)](https://www.cnblogs.com/zhaodongge/p/15067657.html)

### 布隆过滤器

判断一个元素是否存在于集合中，我们会存储这些元素然后进行判重操作，但是使用链表，树，hash这些数据结构，随着元素数量的增多，存储空间会直线增张，最终达到性能瓶颈。检索时间复杂度：$O(n)$，$O(logn)$，$O(1)$。

用于解决批量数据的判重问题，在去重的同时，空间能节省90%，但是有一定的误判概率。

**hash函数结构**

![image-20221112205746248](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205746248.png)

- 如果两个散列值是不相同的（根据同一函数)，那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为**单向散列函数**。
- 散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“**散列碰撞**（collision）”。

但是用 hash表存储大数据量时，空间效率还是很低，当只有一个 hash 函数时，还很容易发生哈希碰撞。

**布隆过滤器**

BloomFilter 是由一个固定大小的二进制向量或者位图（bitmap）和一系列映射函数组成的。

在初始状态时，对于长度为 m 的位数组，它的所有位都被置为0。

![image-20221112205840897](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205840897.png)

当有变量被加入集合时，通过 K 个映射函数将这个变量映射成位图中的 K 个点，把它们置为 1（假定有两个变量都通过 3 个映射函数）。

![image-20221112205904421](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221112205904421.png)

查询某个变量的时候我们只要看看这些点是不是都是 1 就可以大概率知道集合中有没有它了

**特性：**

- **一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在**。
- **布隆过滤器可以添加元素，但是不能删除元素**。因为删掉元素会导致误判率增加。

**添加元素步骤：**

1. 将要添加的元素给 k 个哈希函数
2. 得到对应于位数组上的 k 个位置
3. 将这k个位置设为 1

**查询元素步骤：**

1. 将要查询的元素给k个哈希函数
2. 得到对应于位数组上的k个位置
3. 如果k个位置有一个为 0，则肯定不在集合中
4. 如果k个位置全部为 1，则可能在集合中

**优点：**

1. 对比其他数据结构，时间和空间有巨大优势。插入/查询时间复杂度都是O（K）。

2. 散列函数相互之间没有关系，方便由硬件并行实现。

3. 不存储元素本身，对保密要求有严格的场合有优势。

**缺点：**

1. 误判，随着元素的增加，误算率也随之增加。如果元素数量较少，使用散列表足矣。
2. 不能删除元素。

### 使用场景

1. 已阅读文章/视频去重推荐
2. 缓存穿透，请求来的时候先经过布隆过滤器，如果布隆过滤器有数据，再去查redis，redis没有再去查库。如果布隆过滤器没有数据，直接拒绝。
3. WEB拦截器，如果相同请求则拦截，防止重复被攻击。用户第一次请求，将请求参数放入布隆过滤器中，当第二次请求时，先判断请求参数是否被布隆过滤器命中。
4. 爬虫去重，已经爬过的网页不再去爬
5. Nosql中，当用户来查询某个 row 时，可以先通过内存中的布隆过滤器过滤掉大量不存在的row 请求，然后再去磁盘进行查询。
6. 垃圾邮件的过滤功能。

### 布隆过滤器使用

#### redis布隆过滤器

```sql
docker run -p 6381:6379 \
--name redis-bloom \
-d --restart=always \
-e TZ="Asia/Shanghai" \
 -v /opt/dockers/docker_redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \
 -v /opt/dockers/docker_redis/data:/var/lib/redis \
 -v /opt/dockers/docker_redis/log:/var/log/redis \
 redislabs/rebloom:2.2.2 \
 /usr/local/bin/redis-server /usr/local/etc/redis/redis.conf \
 --appendonly yes\
 --requirepass "123456" \
 --loadmodule "/usr/lib/redis/modules/redisbloom.so"
 
 docker exec -it redis-bloom redis-cli
 
 auth
 
```

布隆过滤器基本指令：

- bf.add 添加元素到布隆过滤器
- bf.exists 判断元素是否在布隆过滤器
- bf.madd 添加多个元素到布隆过滤器，bf.add 只能添加一个
- bf.mexists 判断多个元素是否在布隆过滤器

```sql
# 添加元素
127.0.0.1:6379> bf.add user Tom
(integer) 1
127.0.0.1:6379> bf.add user Tom1
(integer) 1
127.0.0.1:6379> bf.add user Tom2
(integer) 1
127.0.0.1:6379> bf.add user Tom3
(integer) 1
# 重复添加元素
127.0.0.1:6379> bf.add user Tom1
(integer) 0
127.0.0.1:6379> bf.add user Tom
(integer) 0
# 判断元素是否存在
127.0.0.1:6379> bf.exists user Tom
(integer) 1
# 判断多个元素是否存在
127.0.0.1:6379> bf.mexists user Tom1 Tom2
1) (integer) 1
2) (integer) 1
127.0.0.1:6379> bf.mexists user Tom11 Tom12
1) (integer) 0
2) (integer) 0
```

问题：有一定的误判

Redis 还提供了自定义参数的布隆过滤器，`bf.reserve 过滤器名 error_rate initial_size`

- error_rate：允许布隆过滤器的错误率，这个值越低过滤器的位数组的大小越大，占用空间也就越大
- initial_size：布隆过滤器可以储存的元素个数，当实际存储的元素个数超过这个值之后，过滤器的准确率会下降

bf.reserve 需要在add之前显式创建，否则会报错。

```java
127.0.0.1:6379> bf.reserve user 0.01 100
(error) ERR item exists
127.0.0.1:6379> bf.reserve topic 0.01 1000
OK
```

通过Redisson使用过布隆滤器

```java
public class RedissonBloomFilterDemo {

    public static void main(String[] args) {

        Config config = new Config();
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");
        RedissonClient redisson = Redisson.create(config);

        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("user");
        // 初始化布隆过滤器，预计统计元素数量为55000000，期望误差率为0.03
        bloomFilter.tryInit(55000000L, 0.03);
        bloomFilter.add("Tom");
        bloomFilter.add("Jack");
        System.out.println(bloomFilter.count());   //2
        System.out.println(bloomFilter.contains("Tom"));  //true
        System.out.println(bloomFilter.contains("Linda"));  //false
    }
}
```

#### 自定义布隆过滤器

```java
public class MyBloomFilter {

    /**
     * 一个长度为10 亿的比特位
     */
    private static final int DEFAULT_SIZE = 256 << 22;

    /**
     * 为了降低错误率，使用加法hash算法，所以定义一个8个元素的质数数组
     */
    private static final int[] seeds = {3, 5, 7, 11, 13, 31, 37, 61};

    /**
     * 相当于构建 8 个不同的hash算法
     */
    private static HashFunction[] functions = new HashFunction[seeds.length];

    /**
     * 初始化布隆过滤器的 bitmap
     */
    private static BitSet bitset = new BitSet(DEFAULT_SIZE);

    /**
     * 添加数据
     *
     * @param value 需要加入的值
     */
    public static void add(String value) {
        if (value != null) {
            for (HashFunction f : functions) {
                //计算 hash 值并修改 bitmap 中相应位置为 true
                bitset.set(f.hash(value), true);
            }
        }
    }

    /**
     * 判断相应元素是否存在
     * @param value 需要判断的元素
     * @return 结果
     */
    public static boolean contains(String value) {
        if (value == null) {
            return false;
        }
        boolean ret = true;
        for (HashFunction f : functions) {
            ret = bitset.get(f.hash(value));
            //一个 hash 函数返回 false 则跳出循环
            if (!ret) {
                break;
            }
        }
        return ret;
    }

    /**
     * 模拟用户是不是会员，或用户在不在线。。。
     */
    public static void main(String[] args) {

        for (int i = 0; i < seeds.length; i++) {
            functions[i] = new HashFunction(DEFAULT_SIZE, seeds[i]);
        }

        // 添加1亿数据
        for (int i = 0; i < 100000000; i++) {
            add(String.valueOf(i));
        }
        String id = "123456789";
        add(id);

        System.out.println(contains(id));   // true
        System.out.println("" + contains("234567890"));  //false
    }
}

class HashFunction {

    private int size;
    private int seed;

    public HashFunction(int size, int seed) {
        this.size = size;
        this.seed = seed;
    }

    public int hash(String value) {
        int result = 0;
        int len = value.length();
        for (int i = 0; i < len; i++) {
            result = seed * result + value.charAt(i);
        }
        int r = (size - 1) & result;
        return (size - 1) & result;
    }
}
```

#### Guava 中的 BloomFilter

```java
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>23.0</version>
</dependency>

public class GuavaBloomFilterDemo {

    public static void main(String[] args) {
        //后边两个参数：预计包含的数据量，和允许的误差值
        BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel(), 100000, 0.01);
        for (int i = 0; i < 100000; i++) {
            bloomFilter.put(i);
        }
        System.out.println(bloomFilter.mightContain(1));
        System.out.println(bloomFilter.mightContain(2));
        System.out.println(bloomFilter.mightContain(3));
        System.out.println(bloomFilter.mightContain(100001));

        //bloomFilter.writeTo();
    }
}
```

#### SpringBoot

[(287条消息) SpringBoot + Redis实现布隆过滤器拦截无效请求_Toner_唐纳的博客-CSDN博客_布隆过滤器拦截](https://blog.csdn.net/qq_37012496/article/details/106375261)

## 6. 限流

限流目的：

1. 系统处理能力有限，阻止计划外的请求对系统施压。
2. 控制用户行为，避免垃圾请求。

### Redis实现限流

限定用户的某个行为在指定的时间里只能允许发生 N 次。

使用ZSET，通过滑动窗口的形式来计算指定时间内请求的次数。

![image-20221114092907767](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114092907767.png)

通过score的range可以查看单位时间内用户操作的次数。

```java
public Response limitFlow(){
 Long currentTime = new Date().getTime();
 System.out.println(currentTime);
 if(redisTemplate.hasKey("1001")) {
 Integer count = redisTemplate.opsForZSet().rangeByScore("1001", currentTime -  intervalTime, currentTime).size();        // intervalTime是限流的时间 
 System.out.println(count);
 if (count != null && count > 5) {
 return Response.ok("每分钟最多只能访问5次");
 }
 }
 redisTemplate.opsForZSet().add("limit",UUID.randomUUID().toString(),currentTime);
 return Response.ok("访问成功");
 }

```

其他实现方式：[Redis的三种限流方法_fking86的博客-CSDN博客_redis限流](https://fking.blog.csdn.net/article/details/109967406?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-109967406-blog-107744599.pc_relevant_multi_platform_whitelistv4&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-109967406-blog-107744599.pc_relevant_multi_platform_whitelistv4&utm_relevant_index=1)

### 漏斗限流

#### Java实现

![image-20221114095843081](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114095843081.png)

```java
package redis.限流算法;

import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * 漏斗限流算法
 */
public class FunnelRateLimiter {
    private Map<String, Funnel> funnelMap = new ConcurrentHashMap<>();

    public static void main(String[] args) throws InterruptedException {
        FunnelRateLimiter limiter = new FunnelRateLimiter();
        int testAccessCount = 30;//测试次数
        int capacity = 5;//漏斗容量
        int allowQuota = 5;//漏斗流动比率
        int perSecond = 30;//流动速率
        int allowCount = 0;//允许次数
        int denyCount = 0;//拒绝次数
        for (int i = 0; i < testAccessCount; i++) {
            boolean isAllow = limiter.isActionAllowed("dadiyang", "doSomething", 5, 5, 30);
            if (isAllow) {
                allowCount++;
            } else {
                denyCount++;
            }
            System.out.println("访问权限：" + isAllow);
            Thread.sleep(1000);
        }
        System.out.println("报告：");
        System.out.println("漏斗容量：" + capacity);
        System.out.println("漏斗流动速率：" + allowQuota + "次/" + perSecond + "秒");
        System.out.println("测试次数=" + testAccessCount);
        System.out.println("允许次数=" + allowCount);
        System.out.println("拒绝次数=" + denyCount);
    }

    /**
     * 根据给定的漏斗参数检查是否允许访问
     *
     * @param username   用户名
     * @param action     操作
     * @param capacity   漏斗容量
     * @param allowQuota 每单个单位时间允许的流量
     * @param perSecond  单位时间（秒）
     * @return 是否允许访问
     */
    public boolean isActionAllowed(String username, String action, int capacity, int allowQuota, int perSecond) {
        String key = "funnel:" + action + ":" + username;
        if (!funnelMap.containsKey(key)) {
            funnelMap.put(key, new Funnel(capacity, allowQuota, perSecond));
        }
        Funnel funnel = funnelMap.get(key);
        return funnel.watering(1);
    }

    private static class Funnel {
        private int capacity;
        private float leakingRate;
        private int leftQuota;
        private long leakingTs;

        public Funnel(int capacity, int count, int perSecond) {
            this.capacity = capacity;
            // 因为计算使用毫秒为单位的
            perSecond *= 1000;
            this.leakingRate = (float) count / perSecond;
        }

        /**
         * 根据上次水流动的时间，腾出已流出的空间
         */
        private void makeSpace() {
            long now = System.currentTimeMillis();
            long time = now - leakingTs;
            int leaked = (int) (time * leakingRate);
            if (leaked < 1) {
                return;
            }
            leftQuota += leaked;
            // 如果剩余大于容量，则剩余等于容量
            if (leftQuota > capacity) {
                leftQuota = capacity;
            }
            leakingTs = now;
        }

        /**
         * 漏斗漏水
         *
         * @param quota 流量
         * @return 是否有足够的水可以流出（是否允许访问）
         */
        public boolean watering(int quota) {
            makeSpace();
            int left = leftQuota - quota;
            if (left >= 0) {
                leftQuota = left;
                return true;
            }
            return false;
        }
    }
}
 
```

Funnel 对象的 make_space 方法是漏斗算法的核心，其在每次灌水前都会被调用以触发漏水，给漏斗腾出空间来。能腾出多少空间取决于过去了多久以及流水的速率。Funnel 对象占据的空间大小不再和行为的频率成正比，它的空间占用是一个常量。

#### redis实现

将 Funnel 对象的内容按字段存储到一个hash结构中，灌水的时候将 hash 结构的字段取出来进行逻辑运算后，再将新值回填到hash 结构中就完成了一次行为频度的检测。但是有个问题，我们无法保证整个过程的原子性。从 hash 结构中取值，然后在内存里运算，再回填到 hash 结构，这三个过程无法原子化，意味着需要进行适当的加锁控制。而一旦加锁，就意味着会有加锁失败，加锁失败就需要选择重试或者放弃。

如果重试的话，就会导致性能下降。如果放弃的话，就会影响用户体验。同时，代码的复杂度也跟着升高很多。

**redis4.0提供漏斗算法 4.0以上版本**

Redis 4.0 提供了一个限流 Redis 模块，它叫 redis-cell。该模块也使用了漏斗算法，并**提供了原子的限流指令**。

> 命令格式：cl.throttle  key名字   令牌桶容量-1   令牌产生个数   令牌产生时间 本次取走的令牌数 （不写时默认1，负值表放入令牌）
>
> 返回格式：
>
>  cl.throttle user 15 30 60 1
>
> > 1) (integer) 0    # 0 表示允许，1表示拒绝
> > 2) (integer) 16   # 漏斗总容量+1
> > 3) (integer) 15   # 漏斗剩余空间
> > 4) (integer) -1   # 如果拒绝了，需要多长时间后再试(漏斗有空间了，单位秒)
> > 5) (integer) 2    # 表示多久后令牌桶中的令牌会存满(单位秒)

频率为每 60s 最多 30 次(漏水速率)，漏斗的初始容量为 15，也就是说一开始可以连续回复 15 个帖子，然后才开始受漏水速率的影响。我们看到这个指令中漏水速率变成了 2 个参数，替代了之前的单个浮点数。

在执行限流指令时，如果被拒绝了，就需要丢弃或重试。cl.throttle 指令考虑的非常周到，连重试时间都帮你算好了，直接取返回结果数组的第四个值进行 sleep 即可，如果不想阻塞线程，也可以异步定时任务来重试。

**安装：**

redis-cell是一个插件，需要下载安装。

[Releases · brandur/redis-cell (github.com)](https://github.com/brandur/redis-cell/releases)

![image-20221114121720249](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114121720249.png)

解压：tar -zxvf redis-cell-v0.3.0-x86_64-unknown-linux-gnu.tar.gz          

配置conf文件，添加以下内容（loadmodule libredis_cell.so的路径）：loadmodule /data/plus/libredis_cell.so                 

重启redis即可。

查看是否安装成功：cli进入redis后，执行module list，可看到redis-cell模块。

### 令牌桶算法

每访问一次请求的时候，可以从Redis中获取一个令牌，如果拿到令牌了，那就说明没超出限制，而如果拿不到，则结果相反。

令牌桶算法提及到输入速率和输出速率，当输出速率大于输入速率，那么就是超出流量限制了。

可以在filter或者aop中配置策略。

```java
   // 输出令牌
   public Response limitFlow2(Long id){
        Object result = redisTemplate.opsForList().leftPop("limit_list");
        if(result == null){
            return Response.ok("当前令牌桶中无令牌");
        }
        return Response.ok(articleDescription2);
    } 


    // 10S的速率往令牌桶中添加UUID，只为保证唯一性
    @Scheduled(fixedDelay = 10_000,initialDelay = 0)
    public void setIntervalTimeTask(){
        redisTemplate.opsForList().rightPush("limit_list",UUID.randomUUID().toString());
    } 
```

![image-20221114163113470](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114163113470.png)

1、判断有没有被限流惩罚，有则直接返回，无则进入下一步。

2、判断令牌桶是否存在，不存在则先创建令牌桶，然后扣减令牌返回，存在则进入下一步。

3、判断是否需要投放令牌，不需要则直接扣减令牌，需要则先投放令牌再扣减令牌。

4、判断扣减后的令牌数，如果小于0则返回限流，同时设置限流惩罚，如果大于等于0则进入下一步。

5、更新桶中的令牌数到Redis。

## 7. GeoHash

Redis 在 3.2 版本以后增加了地理位置 GEO 模块。

计算周围的人;

![image-20221114163847768](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114163847768.png)

使用关系数据库：select id from positions where x0-r < x < x0+r and y0-r < y < y0+r

需要在经纬度坐标加上双向复合索引 (x, y)，可以最大优化查询性能。

问题：数据库性能有限，在高并发场合，如果请求的人非常多，效率比较低。

**GeoHash实现：**

它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘。所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。然后对这些方格进行整数编码，越是靠近的方格编码越是接近。那如何编码呢？一个最简单的方案就是切蛋糕法。设想一个正方形的蛋糕摆在你面前，二刀下去均分分成四块小正方形，这四个小正方形可以分别标记为 00,01,10,11 四个二进制整数。然后对每一个小正方形继续用二刀法切割一下，这时每个小小正方形就可以使用 4bit 的二进制整数予以表示。然后继续切下去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。

编码之后，每个地图元素的坐标都将变成一个整数，通过这个整数可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程度就越小。对于「附近的人」这个功能而言，损失的一点精确度可以忽略不计。

详情参考文章：https://blog.csdn.net/usher_ou/article/details/122716877

## 8. Scan：筛选海量数据

### 字符串匹配

需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除 key。

**使用字符串匹配**

u1:userid，c1:courseId；

学生的选课信息：

```java
127.0.0.1:6379> set u1-c1 1
OK
127.0.0.1:6379> set u1-c2 1
OK
127.0.0.1:6379> set u1-c3 1
OK
127.0.0.1:6379> set u1-c4 1
OK
127.0.0.1:6379> set u2-c1 1
OK
127.0.0.1:6379> set u2-c3 1
OK
127.0.0.1:6379> set u3-c1 1
OK
127.0.0.1:6379> set u4-c1 1
//获取选u1的选课信息
127.0.0.1:6379> keys u1-c*
1) "u1-c1"
2) "u1-c3"
3) "u1-c4"
4) "u1-c2"
//获取选择c1课程用户信息
127.0.0.1:6379> keys u*c1
1) "u4-c1"
2) "u3-c1"
3) "u1-c1"
4) "u2-c1"
```

**问题：**

1. 没有 offset、limit 参数，一次性吐出所有满足条件的 key,如果满足的key比较多，降低传输速率。
2. keys 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错，因为Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续

### scan基本使用

**特点：**scan 相比keys 具备有以下特点:

1、复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;

**2、提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少;**

3、同 keys 一样，它也提供模式匹配功能;

4、服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数;

5、**返回的结果可能会有重复，需要客户端去重复，这点非常重要;**

6、遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;

7、单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;

scan 参数提供了三个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三个是遍历的 limit hint。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。

 scan 0 match key99* count 1000

**使用：**

批量添加数据：https://blog.csdn.net/weixin_41677422/article/details/108626587

```java
 Map<String,Integer> keys = new HashMap<>();
        for (int i = 1; i <=10000; i++) {
            String str1 = "user1-c"+i;
            String str2 = "user2-c"+i;
            keys.put(str1,1);
            keys.put(str2,1);
        }
        redisTemplate.opsForValue().multiSet(keys);
```

**命令：**

 scan 0 match user1-c* count 1000

```java
1) "32208"
2)   1) "user1-c8506"
     2) "user1-c8657"
     3) "user1-c3984"
     4) "user1-c7815"
     5) "user1-c6278"
     6) "user1-c6254"
     7) "user1-c8514"
     8) "user1-c264"
     9) "user1-c7740"
```

scan 32008 match user1-c* count 1000                                                                                                                                                                                                                        

```java
1) "1464"                                                                                                                                                                                                                                                                   
2) 1) "user1-c7383"                                                                                                                                                                                                                                                       
   2) "user1-c7729"                                                                                                                                                                                                                                      
   3) "user1-c3169"                                                                                                                                                                                                                                                       
   4) "user1-c6614"                                                                                                                                                                                                                                                       
   5) "user1-c8633"                                                                                                                                                                                                                                                       
   6) "user1-c7440"                                                                                                                                                                                                                                                       
   7) "user1-c1604"                                                                                                                                                                                                                                                       
   8) "user1-c4434"                                                                                                                                                                                                                                                       
   9) "user1-c6236"                                                                                                                                                                                                                                                       
   10) "user1-c2290"                                                                                                                                                                                                                                                       
   11) "user1-c1856"                                                                                                                                                                                                                                                       
   12) "user1-c888"                                                                                                                                                                                                                                                        
   13) "user1-c8608"    
```

从上面的过程可以看到虽然提供的 limit 是 1000，但是返回的结果只有 10 个左右。因为这个 limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量(约等于)。如果将 limit 设置为 10，你会发现返回结果是空的，但是游标值不为零，意味着遍历还没结束。

### 字典结构

scan是通过hash的形式查找的

![image-20221114202955771](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221114202955771.png)

scan 指令返回的游标就是第一维数组的位置索引，我们将这个位置索引称为槽 (slot)。。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。

**scan的遍历顺序**

scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。

**普通加法和高位进位加法的区别**

高位进位法从左边加，进位往右边移动，同普通加法正好相反。但是最终它们都会遍历所有的槽位并且没有重复。

**针对其他数据结构同样适用**

scan 指令是一系列指令，除了可以遍历所有的 key 之外，还可以对指定的容器集合进行遍历。比如 zscan 遍历 zset 集合元素，hscan 遍历 hash 字典的元素、sscan 遍历 set 集合的元素

### 大key 检测

进入redis容器（非直接进入redis-cli），使用：redis-cli -h 127.0.0.1 -p 6379 -a PASSWORD --bigkeys   

| 名称      | 说明                  |
| :-------- | :-------------------- |
| -h        | 指定Redis的连接地址。 |
| -a        | 指定Redis的认证密码。 |
| --hotkeys | 用来查询热点Key。     |
| --bigkeys | 用来查询大Key。       |

推荐文章：

[Redis 4.0热点Key查询方法 (aliyun.com)](https://help.aliyun.com/document_detail/101108.html)

[发现并处理Redis的大Key和热Key (aliyun.com)](https://help.aliyun.com/document_detail/353223.html)

# Redis原理

## 1. 线程IO模型

redis是单线程，nginx，node.js都是单线程。

**redis单线程**

redis速度快原因在于redis操作的是内存，因为是单线程的，因此对于复杂度为O（n）的指令要谨慎执行。

**Redis** **单线程如何处理那么多的并发客户端连接？**

redis使用的是非阻塞IO，通过多路复用来处理多个客户端发送的链接。




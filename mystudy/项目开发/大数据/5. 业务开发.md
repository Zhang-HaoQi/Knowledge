# 0. 项目介绍

参考项目：

https://gitee.com/zhijiangtianshu/Dubhe/

http://docs.tianshu.org.cn/docs/

## 项目介绍

大数据实训平台是为石家庄学院开发的综合实训平台，集日常资讯，课程管理，项目管理，在线编程，数据众包，服务器管理，综合学术圈等为一体的大型微服务项目，项目使用springcloud，k8s，elk，mysql，redis，rabbitmq等技术栈，开发人员20人，开发周期4个月。

## 架构选择

1. 选择微服务架构的原因：
   1. 如果选择单机，功能繁杂，耦合度高，并且功能越多，启动越慢不利于后期的开发与维护。
   2. 如果使用单机，所有模块应用共占一台服务器，对服务器的要求较高。并且这些功能模块的使用场景、并发量、消耗的资源类型都各有不同，使得我们对各个业务模块的系统容量很难给出较为准确的评估。如果产生内存泄露的bug，可能导致整个服务器瘫痪。

2. 使用springcloud的原因：
   1. springcloud是一套目前完整的[微服务](https://so.csdn.net/so/search?q=微服务&spm=1001.2101.3001.7020)框架集合，是分布式微服务架构的一站式解决方案。将市面上比较流行的服务框架组合了起来，通过SpringBoot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。我们能在 Spring Boot 的基础上轻松地实现微服务系统的构建。

## 模块设计

### 课程模块

#### 抢课操作

https://blog.csdn.net/Chris_Eli/article/details/125706455

需求分析：每年学期开始时，学生要进行选修课的抢课，课程有人数限制。某些热门课程很抢手，要能容纳瞬时两万左右的并发。

难点分析：

1. 开设课程时，将近两万人同时选课，一个人最多能选四门课程。
2. 热门课程选的人较多，但人数有限，要保证系统数据的一致性。

参考商品秒杀业务，进行设计。

1. 选课开始前一天，使用定时任务将所有课程基本信息存入redis。
   1. 抢课开始的时候，有可能出现缓存失效，大量请求打入数据库，造成数据库崩溃（查询数据库操作添加redisson可重入锁）
      1. 默认30s，业务超时可自动续期（每隔10s进行一次续期），不用担心业务过长，锁自动被删掉。
      2. 如果解锁业务出现异常，redission不会出现死锁，会在30s后自动过期。

   2. 将待选课程的人数限制信息，也存入数据库中。

2. 选课期间，全程不进行数据库的操作，数据的存储依赖redis。
   1. 用户最多选择3门课程，选的课程信息会记录到redis中，如果从redis中

**流程图**

redis存储

![image-20221004092816449](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221004092816449.png)

总体流程图

![image-20221004111527681](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20221004111527681.png)

用户前端在我的课程列表查询已选课程，此时课程可能未进数据库，也有可能已进，也有可能昨天

1. 加redis锁，颗粒小，学生id+课程id，过期时间为：抢课周期
2. 获取信号量

问题：

1. 请求进来直接加锁，如果用户刷课程id，会造成redis存在大量的无效key？需要先判断有无该课程。
2. 课程如果使用1,2，3这样的id，容易被猜测，用户可能使用使用脚本，同时抢多门课程。？课程预热时，返回给前端的数据是课程的随机编号，前端拿着随机编号去redis查询真正的课程信息，通过课程信息中课程的真实id去减库存。
3. redis加锁成功后，如果入队列前的业务还没有执行完，服务器宕机，此时可能造成死锁。（如果使用redission的话有看门狗机制，但是30s的续期过短）?暂时没有太好的解决方案。

取消抢课：

方式一：取消抢课后，消息重新入队列

方式二：取消抢课后





### 审批模块

系统中多个模块都需要审核功能，课程发布，朋友圈动态发布，服务资源申请，项目审批等。

因各模块业务比较独立，因此做服务拆分时，根据各个业务模块进行划分。

模块：

1. 算法编程模块
2. 圈子模块
3. 文献模块
4. 课程模块
5. 项目模块
6. 数据标注模块
7. 系统模块

其中圈子，文献，课程，项目四个模块都需要审批功能，以圈子为例，用户发布动态，或用户在动态下方进行评论时，都需要进行审批。

针对于审批功能制作，提供了两种设计思路。

**思路一：**各个模块负责各自模块内容的审批，各自编写自己模块的审批任务。

![image-20220928171838394](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220928171838394.png)

好处：

1. 设计比较简单，各个模块相对独立。

问题：

1. 审批模块的web页面在一个页面，一个开发人员开发，需要与多位后端开发人员对接接口，交流成本高。
2. 如果审批业务后续功能新增，添加审批链路，项目整体修改较大。

**思路二：**做审批功能的隔离

**审批**：

审批模块独立开发，所有的审批请求都通通进入审批模块。

以文献发表为例，发表文献时，向审批模块发送一条消息，（id,文献id，资源类型，发送时间），审批模块收到后，存入审批表。

管理审批时，前端直接调用审批模块的审批接口完成审批即可。

审批接口执行时，需要将状态同步到各自模块，此时会遇到一个事务问题，需要使用seta解决。如果不使用事务，可以通过发送消息解决。

**查询：**

查询时，也可以调用审批模块的接口，审批模块再远程调用各个模块获取信息，返回给前端。

![image-20220928172739947](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220928172739947.png)

好处：

1. 审批模块完全独立，可以很好的兼容审批模块的需求变化。

问题：

1. 系统复杂性变高，性能降低。
2. 整个链路增长，引入了消息队列，需要考虑消息丢失等一系列问题，同时远程调用需要使用分布式事务，系统性能降低。

### 在线编程模块

#### 保存操作

用户编辑代码，编辑后可以保存。

问题：用户编辑后保存的代码，如何存储的问题。

解决方案：

1. 方式一：用户保存的内容，直接写入服务器文件/文件夹中，运行的时候挂载到容器内部。
   1. 问题：
      1. 在线编程模块用户创建的是一个项目，有多级别的项目目录，直接以IO形式存储，查询麻烦，且性能较低。
      2. 用户需要对代码文件进行频繁的增删改，频繁的进行IO读写，操作复杂度较高。
2. 方式二：用户保存的代码内容，保存到数据库中，运行的时候，写入到服务器上，再挂载到容器内部。
   1. 流程：
      1. 用户保存的代码文件，都以记录的形式保存到数据库中，只存文件的记录（文件的路径和内容），不存目录的记录。
      2. 运行时，直接读取到所有文件，构建项目体，写到服务器上。
   2. 好处：
      1. 文件的增删改查特别方便，前端设置了定时保存，只保存修改内容，避免每次保存都进行大批量文件的修改。
      2. 降低业务的复杂度，较与直接磁盘IO，可以更好的专注业务，不需要考虑进行IO操作可能编码问题和链接关闭等问题。
   3. 问题：
      1. 随着项目的运行，数据库中数据量过大的问题，当数据量过大时，可能造成查询效率变低。（进行索引优化）
      2. 批量插入操作，如何保证插入的数据不会与表中的重复
         1. 前端：保存时，只保存修改的文件（增加/更新）
         2. 后端：查库，判断传入文件的文件名称，如果一样则进行更新操作，如果不存在则进行添加操作。（文件名称唯一）

#### 提交操作

使用K8s做沙箱机制的原因：

1. 环境的隔离，更安全
2. 资源限制，内存，cpu，磁盘，运行时间等k8s提供了全套的解决方案
3. 资源可读与不可读的限制

用户提交代码运行。

![](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220802202012686.png)

k8s资源配置

![image-20220804094300892](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220804094300892.png)



## 技术选型

### 消息队列

参考文章：[RabbitMQ vs. Kafka: Head-To-Head | Better Programming](https://betterprogramming.pub/rabbitmq-vs-kafka-1779b5b70c41)

rabbitMQ是一个*消息代理*，而kafka是一个*分布式流媒体平台*。

Kafka最适合用于处理数据流，而 RabbitMQ 对流中消息的顺序保证最小。

RabbitMQ内置了对重试逻辑和死信交换的支持，而Kafka则将这些实现留给了用户。

#### 消息排序

**RabbitMQ** 

RabbitMQ 对发送到队列或交换的消息的顺序提供很少的保证。

**在一个通道中发布的消息，通过一个交换和一个队列以及一个传出通道，将以与发送相同的顺序接收。**

解释：只要我们有一个消息使用者，它就会按顺序接收消息。但是，一旦有多个使用者从同一队列中读取消息，我们就不能保证消息的处理顺序。如果我们有多个消费者，或者我们开启并发消费，如果某一条消息消费失败，那么此时该消息可能会重新入队，消费顺序被打破。

可以将mq的消费者并发限制为1，但是随着系统的增长，这样会严重影响系统的效率。

**kafka**

Kafka 为消息处理提供了可靠的订购保证。Kafka 保证发送到同一主题分区的所有消息都按顺序处理。

#### 消息路由

**RabbitMQ**

RabbitMQ 可以根据订阅者定义的路由规则将消息路由到消息交换的订阅者。[主题交换](https://www.rabbitmq.com/tutorials/amqp-concepts.html#exchange-topic)可以根据名为 的专用标头路由消息。`routing_key`或者，[标头交换](https://www.rabbitmq.com/tutorials/amqp-concepts.html#exchange-headers)可以基于任意消息标头路由消息。这两种交换都有效地允许使用者指定他们有兴趣接收的消息类型，从而为解决方案架构师提供了极大的灵活性。

**kafka**

Kafka不允许消费者在轮询之前过滤主题中的消息。订阅的使用者无一例外地接收分区中的所有消息。

作为开发人员，您可以使用 [Kafka 流作业](https://kafka.apache.org/documentation/streams/)，该作业从主题中读取消息，筛选它们，并将它们推送到使用者可以订阅的另一个主题。

#### 消息计时

**RabbitMQ**

1. 可以为消息或队列设置TTL，到时间消息则自动删除或入死信队列。
2. 可以通过插件设置延迟队列，生产者可以延迟 RabbitMQ 将此消息路由到使用者队列的时间。

**kafka**

Kafka 没有为消息提供 TTL 机制，我们可以在应用程序级别实现一个。

#### 邮件保留

**RabbitMQ**

消息消费成功后，RabbitMQ会从存储中逐出消息。

**Kafaka**

Kafka 通过设计将所有消息保留到每个主题配置的超时。

关于消息保留，Kafka并不关心其消费者的消费状态，因为它充当消息日志。

使用者可以随心所欲地使用每条消息，并且他们可以通过操作其分区偏移量来“及时”来回旅行。Kafka 会定期查看主题中消息的年龄，并逐出那些足够旧的消息。

卡夫卡的性能不依赖于存储大小。因此，从理论上讲，可以几乎无限期地存储消息而不会影响性能（只要您的节点足够大以存储这些分区）。

#### 故障处理

处理消息时，可能有两种类型的错误：

1. 暂时性故障 — 由于临时问题（如网络连接、CPU 负载或服务崩溃）而发生的故障。我们通常可以通过一遍又一遍地重试来缓解这种故障。
2. 持续性故障 — 由于无法通过额外重试解决的永久性问题而发生的故障。这些故障的常见原因是软件错误或无效的消息架构（即，有害消息）。

作为架构师和开发人员，我们应该问自己：“在消息处理失败时，我们应该重试多少次？两次重试之间应等待多长时间？我们如何区分暂时性故障和持续性故障？

如果当所有重试都失败，或者遇到持续失败时，我们该怎么办？

**RabbitMQ**

RabbitMQ 提供传递重试和死信交换 （DLX） 等工具来处理消息处理失败。

DLX 的主要思想是 RabbitMQ 可以根据适当的配置自动将失败的消息路由到 DLX，并在此交换时对消息应用进一步的处理规则，包括延迟重试、重试计数和传递到“人为干预”队列。

在 RabbitMQ 中，当使用者忙于处理和重试特定消息时（甚至在将其返回到队列之前），其他使用者可以并发处理其后的消息。

当特定使用者重试特定消息时，消息处理作为一个整体不会卡住。因此，消息使用者可以根据需要同步重试消息，而不会影响整个系统。

重试机制参考文章：[兔子MQ重试 — 完整故事 |作者：埃雷兹·拉比赫·|纳尼特工程 (nanit.com)](https://engineering.nanit.com/rabbitmq-retries-the-full-story-ca4cc6c5b493)

**kafaka**

不提供任何此类开箱即用的机制。使用 Kafka，我们有责任在应用程序级别提供和实现消息重试机制。

当使用者忙于同步重试特定消息时，无法处理来自同一分区的其他消息。

我们不能拒绝和重试特定消息并提交其后的消息，因为使用者无法更改消息顺序。请记住，分区只是一个仅追加日志。

应用程序级解决方案可以将失败的消息提交到“重试主题”，并从那里处理重试。但是，在这种类型的解决方案中，我们会丢失消息排序。

优步工程的这种实现的一个例子可以在 [Uber.com 找到](https://eng.uber.com/reliable-reprocessing/)。如果消息处理延迟不是问题，那么具有充分错误监视功能的 vanilla Kafka 解决方案可能就足够了

#### 规模

Kafka通常被认为比RabbitMQ具有更好的性能。卡夫卡使用顺序磁盘 I/O 来提高性能。

大型 Kafka 部署通常每秒可以处理数十万条消息，甚至每秒处理数百万条消息。

大多数系统都不会达到任何这些限制！除非您正在构建下一个数百万用户的粉碎性软件系统，否则您不需要太关心规模，因为这两个平台都可以为您提供良好的服务。

#### 消费者复杂性

**RabbitMQ**

rabbitMQ管理消息到使用者的分法，以及队列中删除消息，消费者无须考虑。

当系统负载增加时，队列的消费者组可以有效地从一个消费者扩展到多个消费者，而无需对系统进行任何更改。

**kafka**

看的不是特别明白

![image-20220923162616082](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220923162616082.png)

#### 如何抉择

**rabbitmq**

1. 高级且灵活的路由规则。
2. 消息计时控制（控制消息过期或消息延迟）。
3. 高级故障处理功能，在使用者更有可能无法处理消息（暂时或永久）的情况下。
4. 更简单的使用者实现。

**kafka**

1. 严格的消息排序。
2. 消息保留时间较长，包括重播过去消息的可能性。
3. 当传统解决方案不足时达到高规模的能力。

**非功能约束**

1. 这些平台的现有开发人员知识。
2. 托管云解决方案的可用性（如果适用）。
3. 每个解决方案的运营成本。
4. 目标堆栈的 SDK 的可用性。



# 1. 主要任务

本次任务是在线编程模块，主要实现代码的在线编程并运行，适配编程语言有python，scala，R语言三种。

一个算法任务有多个文件组成，用户可增删改查，下载这些文件。

用户提交的文件，经后端编译运行后，返回给用户。

a. 项目进度跟踪，项目架构选择以及技术栈选型与调研，负责在线编程模块开发。

b. 负责K8s集群搭建和ELK日志可视化分析系统搭建。

c. 使用K8s的Job控制器来负责编程任务创建和运行，通过限制任务运行时间、内存、cpu、磁盘空间、资源可读写来保证算法任务可靠运行以及服务器安全。

d. 使用RabbitMq做削峰处理，防止短时间内编程任务量剧增压垮服务器。

e. 使用工厂模式来创建不同语言的编程任务，便于后期代码维护以及需求变更。

# 2 . 难点

1. 文件上传的存储，文件下载打包
2. minio的配置
3. 消息队列的配置
4. k8s的配置
5. 用户提交代码时，代码的编译运行需要放在k8s的pod中执行，通过消息队列，排队创建pod

# 3. 业务场景

开发算法编程模块，涉及接口：

1. 新增算法任务
2. 编辑算法任务
   1. 获取算法详情（获取所有文件）
   2. 保存文件
   3. 编辑文件
   4. 删除文件
   5. 重命名文件
   6. 下载文件
3. 提交运行
4. 删除算法任务
5. 获取算法任务列表

# 4. 业务实现

## 1. 总体思路

**任务状态：**0. 未提交 1. 排队中 2. 执行中 3. 已完成 4. 失败 5.  已终止

**总流程：**

![image-20220802202012686](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220802202012686.png)

任务创建后，提交任务，创建任务消息实体，交给消息队列排队，消费时，先确定服务器中job的数量，如果job的数量小于服务器的最大承受限制，则消费该消息，并异步创建job实体，如果消息有误或超过数量限制，则拒绝该消息消费，让消息重新入队，此时会产生一个问题，被拒绝的消息还会排在队列的队头位置，造成该消息在短时间内一直被重复的消费拒绝，因此，在此可以设置一段休眠时间。创建pod的时候，需要配置pod的关键信息，详细在具体之后的业务编写中会写到。

**表关系：**

![image-20220802211532083](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220802211532083.png)

## 2. 创建任务

### 功能分析

**实现效果：**

![image-20220802204945529](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220802204945529.png)

**主要功能：**

1. 一个任务有多个文件和文件夹，可以增删改查这些文件（文件都是文本文件）
2. 必须有一个主文件
3. 有文件总大小限制，不可超过1G

**实现思路：**

1. 使用数据库保存文件名路径和文件内容，如上面图中的file.py，在数据库存储时，存储的文件名路径是：code/file.py
2. 不保存文件夹的名称，回显时，通过文件名路径推出文件名称
3. 如果只创建了文件夹，文件夹中没有任何文件，是不保存文件夹的信息的，也没有必要保存。

### 核心代码

#### 文件大小

1. 文件大小获取：file.setFileSize(file.getContent().getBytes(StandardCharsets.UTF_8).length);

   ```java
     public void fileSize() throws IOException {
           //方式一：通过文件获取
           String filePath = "file/code/python/Hello.python";
           File file = new File("file/code/python/Hello.python").getCanonicalFile();
           if (!file.getParentFile().exists()){
               file.getParentFile().mkdirs();
           }
           try (Writer writer = new FileWriter(filePath)){
               writer.write("1111111111111111111111111111111111111111111111111111");
           }catch (Exception e){
               e.printStackTrace();
               System.out.println(e);
           }
           FileInputStream fis = new FileInputStream(file);
           FileChannel fc = fis.getChannel();
           long size = fc.size();
           System.out.println("fileSize"+size);
           byte[] buffer = new byte[1024];
           int hasRead;
           StringBuffer stringBuffer = new StringBuffer();
           while ((hasRead = fis.read(buffer))>0){
               String s = new String(buffer, 0, hasRead);
               stringBuffer.append(s);
           }
           //方式二：通过字符串的字节长度获取
           int length = stringBuffer.toString().getBytes(StandardCharsets.UTF_8).length;
           System.out.println("length:"+length);
       }
   ```

2. 两种方式计算出的大小相差不大，问题是使用fc.size返回的类型是long，而第二种方式返回的是int，受限于长度，使用第二种方式，返回的类型是int，int的话存储的最大容量是2G，也就是说，使用int类型时，你的文件最大容量不能超过2G，不过正常情况下，一个文件也不会这么长。

#### 创建默认文件

每次创建新任务时，都会创建run.py和run.sh两个默认文件

this.getClass().getResourceAsStream(runFilePath);文件是在resource目录下。

![image-20220803104857053](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220803104857053.png)

```java
    private String runFileName = "run.python";
    private String shFileName = "run.sh";
    private String runFilePath = "/file/code/python/run.py";
    private String shFilePath = "/file/code/python/run.sh";    

    @Override
    public List<TaskFiles> createDefaultFiles(Long recordId) throws IOException {
        InputStream runStream = this.getClass().getResourceAsStream(runFilePath);
        InputStream shStream = this.getClass().getResourceAsStream(shFilePath);
        String runCon = readStream(runStream);
        String shCon = readStream(shStream);
        TaskFiles runFile = new TaskFiles();
        runFile.setTaskRecordId(recordId)
                .setFileName(runFileName)
                .setFileSize(runCon.getBytes(StandardCharsets.UTF_8).length)
                .setMain(true)
                .setContent(runCon);
        TaskFiles shFile = new TaskFiles();
        shFile.setTaskRecordId(recordId)
                .setFileName(shFileName)
                .setFileSize(shCon.getBytes(StandardCharsets.UTF_8).length)
                .setMain(false)
                .setContent(shCon);
        List<TaskFiles> taskFiles = new ArrayList<>();
        taskFiles.add(runFile);
        taskFiles.add(shFile);
        return taskFiles;
    }

# 使用字节流读取文本，会出现乱码。这是因为一个汉字是2-4字节，而空格之类的是半个字节，缓冲区是1024字节，有可能是读到了半个汉字
    default String readStream(InputStream fileStream) throws IOException {
        int readLen;
        byte[] bytes = new byte[1024];
        StringBuffer conBuf = new StringBuffer();
        while ((readLen = fileStream.read(bytes)) > 0) {
            String text = new String(bytes, 0, readLen);
            conBuf.append(text);
        }
        return conBuf.toString();
    }
# 解决方式：将字节流转换成字符流进行读取即可
        default String readStream(InputStream fileStream) throws IOException {
        InputStreamReader reader  = new InputStreamReader(fileStream);
        int readLen;
        char[] chars = new char[1024];
        StringBuffer conBuf = new StringBuffer();
        while ((readLen = reader.read(chars)) > 0) {
            String text = new String(chars, 0, readLen);
            conBuf.append(text);
        }
        return conBuf.toString();
    }
```

#### 获取任务文件详情

**返回格式：**

```java
public class TaskFilesDetailDTO {

    @ApiModelProperty(value = "id")
    private Long id;

    @ApiModelProperty(value = "文件名")
    private String name;

    @ApiModelProperty(value = "文件内容")
    private String content;
    
    @ApiModelProperty(value = "文件类型")
    private String fileType;
    

    @ApiModelProperty(value = "文件大小")
    private Integer fileSize;

    @ApiModelProperty(value = "是否是文件夹")
    private Boolean isLeaf;

    @ApiModelProperty(value = "是否是主文件(默认不是)")
    private Boolean main;

    @ApiModelProperty(value = "子文件")
    private List<TaskFilesDetailDTO> children;

}
```

1. 将所有文件记录记载进内存，筛选出所有的文件路径，以树状的形式返回给前端。
2. 入参`List<TaskFiles> taskFiles`即为数据库中查出来的记录
3. 使用` Map<String, TaskFilesDetailDTO> taskNode = new HashMap<>();`来筛选出所有文件夹和文件。key为子路径，如果路径为train/file/code.fie，那么map中会有三个key，分别是：train       train/file         train/file/code.file ,这样就可以删选唯一的路径和文件。
4. 根路径为""，因此最后返回前端时，只需要返回根的子文件即可。

```java
private List<TaskFilesDetailDTO> getCodeDirectory(List<TaskFiles> taskFiles, boolean needContent) {
        if (taskFiles == null || taskFiles.size() == 0) {
            return new ArrayList<>();
        }
        //存储文件路径及对应的文件
        Map<String, TaskFilesDetailDTO> taskNode = new HashMap<>();
        //默认以""为根
        TaskFilesDetailDTO root = new TaskFilesDetailDTO()
                .setName("")
                .setChildren(new ArrayList<>());
        taskNode.put(root.getName(), root);
        //生成文件和文件夹
        for (TaskFiles file : taskFiles) {
            String[] split = file.getFileName().split("/");
            //当前文件的前缀，不管是哪一级文件，一定有一个前缀。
            String prefix = root.getName();
            for (String path : split) {
                //判断map中是否已存在该文件或文件夹，存在跳过，不存在就插入.注意：此处的  prefix=prefix+path+"/" 还用于下一个文件的前缀。
                TaskFilesDetailDTO curNode = taskNode.get(prefix + path + "/");
                if (curNode != null) {
                    prefix = prefix + path + "/";
                    continue;
                }
                TaskFilesDetailDTO subNode = new TaskFilesDetailDTO();
                subNode.setId(file.getId());
                subNode.setChildren(new ArrayList<>());
                if (path.contains(".")) {
                    //文件
                    subNode.setName(path);
                    if (needContent) {
                        subNode.setContent(file.getContent());
                    }
                    subNode.setFileType(path.substring(path.indexOf(".")));
                    subNode.setFileSize(file.getFileSize());
                    subNode.setMain(file.getMain());
                    subNode.setIsLeaf(true);

                } else {
                    //文件夹
                    subNode.setName(path);
//                    subNode.setContent("");
                    subNode.setFileType("");
                    subNode.setFileSize(0);
                    subNode.setMain(false);
                    subNode.setIsLeaf(false);
                }
                //获取前缀对象, 默认前缀为""，因此前缀不可能为null
                TaskFilesDetailDTO perNode = taskNode.get(prefix);
                perNode.getChildren().add(subNode);
                //将进的文件/文件夹路径放入map
                prefix = prefix + path + "/";
                taskNode.put(prefix, subNode);
            }
        }
        return root.getChildren();
    }
```

## 3. 提交任务

1. 生成文件到minio服务器
2. 发送消息到队列
3. 创建k8s对象

### 1. 提交文件

1. 之前文件的内容都是在数据库中存储，提交任务时，需要将这些文件记录变为真实的文件输出到服务器上。
2. 文件创建时，直接通过nfs创建到minio上，方便之后文件下载，创建完成之后，创建自定义的k8s参数对象，并发送到消息队列，排队创建k8s实体。
3. 创建pod的时候，需要挂载代码文件，数据集文件，日志文件，脚本文件等，最后运行pod
4. 生成文件的时候，因为不同语言的代码的配置有些不同，因此采用工厂设置模式。
5. 用户每次提交时，都会生成一个uuid作为一个用户的唯一路径在minio中，用于任务

注意：直接将前端传来的参数存入数据库时，如果出现前端传入的数据中有些符号被转入，如>转换成了&gt，前端对传入的数据做了htmlEscape处理，后端想要还原的话需要进行下htmlUnescape的操作，这时候可以使用一个spring-web中自带的一个工具类HtmlUtils。

```java
  <dependency>
      <groupId>org.springframework</groupId>
      <artifactId>spring-web</artifactId>
   </dependency>
  
   //input是后端接收到的被处理的字符串
HtmlUtils.htmlUnescape(String input);
```

**整体逻辑**

```java
@Override
    public void submitTask(TaskFileSaveVO taskFileSaveVO) throws IOException {
        //校验
        Task task = judgeTask(taskFileSaveVO.getTaskId());
        judgeDataScope(task.getUserId());
        //一个任务，一个人只能有一条正在执行的任务记录
        int i = recordService.selectUnExecTaskRecord(taskFileSaveVO.getTaskId());
        if (i > 0) {
            throw new ServiceException("当前已有正在运行的记录,运行完成后即可再次提交");
        }
        TaskRecord record = judgeUncommitTaskRecord(taskFileSaveVO.getTaskId());
        if (StringUtils.isNotBlank(taskFileSaveVO.getRemarks())) {
            record.setRemarks(taskFileSaveVO.getRemarks());
        }
        if (StringUtils.isNotBlank(taskFileSaveVO.getExecCommand())) {
            record.setExecCommand(taskFileSaveVO.getExecCommand());
        }
        recordService.updateById(record);
        List<TaskFiles> taskFiles = taskFilesMapper.selectList(Wrappers.<TaskFiles>lambdaQuery().eq(TaskFiles::getTaskRecordId, record.getId()));
        //文件在服务器存储路径
        String dirPath = "";
        String fileUid = UUID.randomUUID().toString().replace("-", "").toLowerCase();
        switch (CodeLanguageEnum.getCodeLanguage(task.getCodeLanguage())) {
            case PYTHON:
                CodeFactory pythonCodeFactory = new PythonCodeFactory();
                Code python = pythonCodeFactory.product();
                dirPath = python.submitFiles(taskFiles, nfsBasePath, fileUid);
                break;
            case SCALA:
                CodeFactory scalaCodeFactory = new ScalaCodeFactory();
                Code scala = scalaCodeFactory.product();
                dirPath = scala.submitFiles(taskFiles, nfsBasePath, fileUid);
                break;
            case R:
                CodeFactory rCodeFactory = new RCodeFactory();
                Code r = rCodeFactory.product();
                dirPath = r.submitFiles(taskFiles, nfsBasePath, fileUid);
                break;
            default:
                throw new ServerException("创建默认文件失败");
        }
        //文件在服务器存储的绝对路径
        record.setJobUid(fileUid);
        record.setDirPath(dirPath);
        String s = dirPath + "/log/" + fileUid + ".log";
        String substring = s.substring(1, s.length());
        record.setResLogPath(substring);
        record.setSubmitTime(LocalDateTime.now());
        record.setTaskStatus(TaskStatusEnum.NEW_COMMIT.getStatus());
        record.setDownloadPath(dirPath);
        if (!recordService.updateById(record)) {
            throw new ServerException("提交失败，请重试");
        }
        //消息入队列
        sendMessageToQueue(record);
    }
```

**生成文件的代码**

其中dirPath即为minio中该任务所有文件存储的基本路径

注意：dirPath如果以/开头，在windows中是不生成文件目录的，在linux中是以根目录为起始目录创建文件的（这里是以/开头）

如果是以非/开头，在windows中是在项目的根目录下创建文件的。

![image-20220803105154001](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220803105154001.png)

```java
  default String createFile(List<TaskFiles> taskFiles, String nfsPath, String basePath, String fileUid) {
        String dirPath = nfsPath + basePath + fileUid;
        //创建数据集文件夹
        String dataPath = dirPath + "/data";  //数据集文件
        String logPath = dirPath + "/log/" + fileUid + ".log"; //日志文件
        String codePath = dirPath + "/code";  //代码文件
        makeDir(dataPath);
        makeDir(codePath);
        makeFile(logPath, "");
        //创建代码文件
        for (TaskFiles taskFile : taskFiles) {
            String fileName = taskFile.getFileName();
            if (fileName != null && fileName != "") {
                String filePath = codePath + "/" + fileName;
                makeFile(filePath, taskFile.getContent());
            }
        }
        return dirPath;
    }

    default void makeDir(String filePath) {
        File file = null;
        try {
            file = new File(filePath).getCanonicalFile();
            if (!file.getCanonicalFile().exists()) {
                file.mkdirs();
            }
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }

    default void makeFile(String filePath, String content) {
        try {
            File file = new File(filePath).getCanonicalFile();
            if (!file.getParentFile().exists()) {
                file.getParentFile().mkdirs();
            }
            try (Writer writer = new FileWriter(filePath)) {
                writer.write(content);
            }
        } catch (IOException e) {
            throw new ServiceException("提交失败,请重新尝试");
        }
    }
```

### 2. 消息队列设置

目的：削峰，避免短时间内大量任务提交，搞垮服务器

总体流程图：

![image-20220803143924157](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220803143924157.png)

细节：

![image-20220803153145154](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220803153145154.png)

消费者设定为一次消费一条记录，采取手动的发布确认机制，如果接受过来的消息无误，则同意消费，如果接受过来的数据有问题，则拒绝消费，消费直接进入死信队列，在死信队列中修改运行状态。（注意，死信队列中也需要手动确认）如果是服务器资源不够，则拒绝消费，并让消费重返队列，此时一个问题是消息会回到队头，消费者又一直在监听当前队列，如果短时间内该信息没有被确认掉，该消息会被一直的重复调用，因此在此可以设置一段休眠时间。

#### 1. 安装及基本应用

**rabbitmq服务搭建以及基本配置：**https://gitee.com/zhang-haoqi/knowledge/blob/develop/mystudy/%E5%A4%A7%E6%95%B0%E6%8D%AE/k8s/10.%20rabbitmq%E5%AE%89%E8%A3%85.md

#### 2. 基本配置

1. 引入依赖

   ```xml
           <!--消息队列-->
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-amqp</artifactId>
           </dependency>
   ```

2. 创建基本配置

   ```java
   spring: 
     rabbitmq:
       host: 192.168.41.34
       port: 31382
       username: coder
       password: train@coder
       virtual-host: compile-code
       publisher-confirm-type: correlated   # 表示消息成功到达Broker后触发ConfirmCalllBack回调
       publisher-returns: true    # true表示开启失败回调，开启后当消息无法路由到指定队列时会触发ReturnCallback回调。
       template:
         mandatory: true
       listener:
         simple:
           concurrency: 1 # 并发数
           max-concurrency: 1  # 最大并发数
           prefetch: 1 # 预处理个数，即消费者所能保持最大未确认消费的数量
           acknowledge-mode: manual   # 手动后ack
           default-requeue-rejected: false   # 被拒绝的消息是否重新入队。   如果手动ack，设置的requeue的信息大于在此设置的优先级
   ```

3. 队列，交换机，路由key等信息

   ```java
   @Configuration
   public class CompileCodeConfig {
       //springboot 会为我们自动初始化这个CachingConnectionFactory，默认情况下，消费者监听的为此工厂的配置，也可以自定义。
       //队列信息
       public static final String COMPILE_CODE_EXCHANGE = "compile.code.direct";
       public static final String COMPILE_CODE_QUEUE = "compile.code.queue";
       public static final String COMPILE_CODE_ROUTEKEY = "compile.code.routekey";
       //死信队列信息
       public static final String COMPILE_CODE_DEAD_EXCHANGE = "compile.code.dead.direct";
       public static final String COMPILE_CODE_DEAD_QUEUE = "compile.code.dead.queue";
       public static final String COMPILE_CODE_DEAD_KEY = "compile.code.dead.key";
   
       @Autowired
       private CachingConnectionFactory connectionFactory;
   
       //普通交换机
       @Bean
       public DirectExchange CompileCodeExchange() {
           //1.交换机名称
           //2.交换机的类型
           //3.是否需要持久化
           //4.是否需要自动删除
           //5.其他参数
           return ExchangeBuilder.directExchange(CompileCodeConfig.COMPILE_CODE_EXCHANGE).durable(true).build();
       }
   
       //普通队列,普通队列绑定死信交换机
       @Bean
       public Queue CompileCodeQueue() {
           Map<String, Object> args = new HashMap<>(2);
           //声明当前队列绑定的死信交换机
           args.put("x-dead-letter-exchange", CompileCodeConfig.COMPILE_CODE_DEAD_EXCHANGE);
           //声明当前队列的死信路由 key
           args.put("x-dead-letter-routing-key", CompileCodeConfig.COMPILE_CODE_DEAD_KEY);
           //druable 持久化  后面输入队列的名称
           return QueueBuilder
                   .durable(CompileCodeConfig.COMPILE_CODE_QUEUE)
                   .withArguments(args).build();
       }
   
       //普通队列绑定普通交换机
       @Bean
       public Binding bindingCompileCodeQueueToExchange() {
           return BindingBuilder
                   .bind(CompileCodeQueue())
                   .to(CompileCodeExchange())
                   .with(CompileCodeConfig.COMPILE_CODE_ROUTEKEY);
       }
   
   
       //死信交换机
       @Bean("compileCodeDeadDirect")
       public DirectExchange compileCodeDeadDirect() {
           System.out.println("创建交换机");
           return (DirectExchange) ExchangeBuilder
                   .directExchange(CompileCodeConfig.COMPILE_CODE_DEAD_EXCHANGE)
                   .durable(true)
                   .build();
       }
   
   
       //死信队列
       @Bean("compileCodeDeadQueue")
       public Queue compileCodeDeadQueue() {
           return new Queue(CompileCodeConfig.COMPILE_CODE_DEAD_QUEUE);
       }
   
   
       //死信队列与死信交换机进行绑定
       @Bean
       public Binding bindingExamProcessQueueToExchange(@Qualifier("compileCodeDeadQueue") Queue queue, @Qualifier("compileCodeDeadDirect") DirectExchange customExchange) {
           return BindingBuilder
                   .bind(queue)
                   .to(customExchange)
                   .with(CompileCodeConfig.COMPILE_CODE_DEAD_KEY);
       }
   }
   ```

#### 3. ConfirmCalllBack和ReturnCallback回调

```java
@Component
@Slf4j
public class CompileCodeCallBack implements RabbitTemplate.ConfirmCallback, RabbitTemplate.ReturnsCallback {
    @Autowired
    private RabbitTemplate rabbitTemplate;


    //将创建的消息接收的回调对象添加到rabbitTemplate中。
    @PostConstruct
    public void init() {
        rabbitTemplate.setConfirmCallback(this);
        //设置当消息灭有路由到指定队列时的处理方案。   //true：重回生产者   //false：丢失（默认） 返回的消息可以从ReturnCallback回调中获取
        //rabbitTemplate.setMandatory(true);
        rabbitTemplate.setReturnsCallback(this);
    }

    /**
     * 交换机确定是否收到消息的回调方法
     * 1.发消息  交换机成功接受到了  回调
     * 1.1CorrelationData保存回调消息的ID及相关信息
     * 1.2交换机收到消息   ack：true
     * 1.3cause 失败的原因  cause：null
     * 2.发消息  交换机没有成功接收   回调
     * 2.1CorrelationData保存回调消息的ID及相关信息
     * 2.2交换机收到消息   ack：false
     * 2.3 cause：失败的原因
     */

    //消息未到达交换机
    @Override
    public void confirm(CorrelationData correlationData, boolean ack, String cause) {
        System.out.println(correlationData);
        String id = correlationData == null ? "" : correlationData.getId();
        if (ack) {
            log.info("交换机已经收到 id 为:{}的消息", id);
        } else {
            log.info("交换机还未收到 id 为:{}消息,由于原因:{}", id, cause);
        }
    }



    //消息到达交换机，但是没有对应的队列。
    @Override
    public void returnedMessage(ReturnedMessage returned) {
        Message message = returned.getMessage();
        String replyText = returned.getReplyText();
        String routingKey = returned.getRoutingKey();
        String exchange = returned.getExchange();
        log.error(" 消 息 {}, 被 交 换 机 {} 退 回 ， 退 回 原 因 :{}, 路 由 key:{}", new
                String(message.getBody()), exchange, replyText, routingKey);
    }
}
```

#### 4. 生产者配置

```java
@Component
@Slf4j
@AllArgsConstructor
public class CompileCodeSender {

    private final RabbitTemplate rabbitTemplate;


    public void sendMessage(CreateCodeJobDto jobDto) {
        log.info("发送消息到队列"+jobDto);
        rabbitTemplate.convertAndSend(CompileCodeConfig.COMPILE_CODE_EXCHANGE, CompileCodeConfig.COMPILE_CODE_ROUTEKEY, JSON.toJSONString(jobDto), new MessagePostProcessor() {
            @Override
            public Message postProcessMessage(Message message) throws AmqpException {
                MessageProperties messageProperties = message.getMessageProperties();
                //设置持久化
                messageProperties.setDeliveryMode(MessageProperties.DEFAULT_DELIVERY_MODE);
                //优先级
                messageProperties.setPriority(2);
                //过期时间,默认设置为一天
                final int expireTime = 3600000;
                messageProperties.setExpiration(String.valueOf(expireTime));
                return message;
            }
        }, new CorrelationData(UUID.randomUUID().toString()));
    }


}
```

#### 5. 消费者配置

```java
@Component
@Slf4j
@AllArgsConstructor
public class CompileCodeCustomer {


    private final TaskRecordMapper recordMapper;
    private final CompileCodeSubmit codeSubmit;
    private final K8sService k8sService;
    private final K8sRunCodeConfig runCodeConfig;



    @RabbitListener(queues = CompileCodeConfig.COMPILE_CODE_QUEUE)
    public void handleCode(Message message, Channel channel) {
        TaskRecord taskRecord = null;
        try {
            int jobMaxNum = runCodeConfig.getJobMaxNum();
            String mes = new String(message.getBody(), "UTF-8");
            log.info("收到消息:{}", mes);
            CreateCodeJobDto createCodeJobDto = JSONObject.parseObject(mes, CreateCodeJobDto.class);
            taskRecord = recordMapper.selectOne(Wrappers.<TaskRecord>lambdaQuery().eq(TaskRecord::getJobUid, createCodeJobDto.getJobUid()).last("LIMIT 1"));
            log.info("消息记录：{}", taskRecord.getId());
            //判断任务是否手动终止，如果手动终止，则直接同意
            if (!taskRecord.getTaskStatus().equals(TaskStatusEnum.NEW_COMMIT.getStatus())) {
                log.info("该任务已经完成或终止:任务记录{}", taskRecord.getId());
                channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
                return;
            }
            //获取pod的数量 或者内存占用情况
            V1PodList jobList = k8sService.listNamespacesPod(runCodeConfig.getNamespace(), runCodeConfig.getJobLabel());
            if (jobList == null || jobList.getItems().size() <= jobMaxNum) {
                log.info("同意消费,任务记录：{}", taskRecord.getId());
                //消费成功
                channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
                //异步执行提交代码
                codeSubmit.submitCode(createCodeJobDto);
            } else {
                log.info("任务已满，拒绝消费,任务记录：{}", taskRecord.getId());
                //拒绝消费，重新入队（此处的入队表示进入队头），此时消费者会持续接收该消息，直到允许消费。
                //睡眠五秒，不然的话消费者会一直消费该消息，并一直拒绝。
                Thread.sleep(5000L);
                channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);
            }
        } catch (Exception e) {
            try {
                log.info("消费失败,失败原因：{},失败记录id：{}", e.getMessage(), taskRecord.getId());
                //如果代码逻辑产生了异常，拒绝消息，入死信队列
                channel.basicReject(message.getMessageProperties().getDeliveryTag(), false);
            } catch (Exception ex) {
                log.info("信道异常");
                throw new RuntimeException(ex);
            }
        }
    }

    //死信队列，存储过期或者消费失败的消息   考虑之后做短信通知
    @RabbitListener(queues = CompileCodeConfig.COMPILE_CODE_DEAD_QUEUE)
    public void handleDeadMessage(Message message, Channel channel) {
        try {
            String mes = new String(message.getBody(), "UTF-8");
            log.info("死信队列:收到消息:{}", mes);
            CreateCodeJobDto createCodeJobDto = JSONObject.parseObject(mes, CreateCodeJobDto.class);
            TaskRecord taskRecord = recordMapper.selectOne(Wrappers.<TaskRecord>lambdaQuery().eq(TaskRecord::getJobUid, createCodeJobDto.getJobUid()).last("LIMIT 1"));
            taskRecord.setTaskStatus(TaskStatusEnum.TASK_FAIL.getStatus());
            recordMapper.updateById(taskRecord);
            log.info("死信队列：消费失败,任务记录:{}", taskRecord);
            try {
                channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
            } catch (IOException e) {
                log.info("死信队列：消费失败，信道已关闭");
                throw new RuntimeException(e);
            }
        } catch (UnsupportedEncodingException e) {
            try {
                channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
            } catch (IOException ex) {
                log.info("死信队列：消费失败，信道已关闭");
                throw new RuntimeException(ex);
            }
        }
    }

}
```

建议把消费者中的所有代码都使用trycatch捕获，这样就不会出现代码异常后，导致消息被阻塞，消息一直消费不掉。就算日志也建议捕获。

需要注意的是日志中如果有对象属性的获取，也一定要进行判null操作，否则很可能出现消费失败时，在捕获的地方打印日志，而在日志中调用了对象的属性，对象为null，导致对象进一步报错。

![image-20220812204107085](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220812204107085.png)

#### 6. 异步创建job

```java
@Component
@Slf4j
@AllArgsConstructor
public class CompileCodeSubmit {
    private final K8sService k8sService;

    @Async
    public void submitCode(CreateCodeJobDto createCodeJobDto) {
        log.info("开始消费任务:{}", createCodeJobDto);
        //创建pod，执行任务
        k8sService.createCodeJob(createCodeJobDto);
        log.info("消费完成");
    }
}
```

#### 7. 事务问题

![image-20220812174740599](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220812174740599.png)

程序运行中，出现了这样的问题，在程序中先更新了job_uid，之后消息入队列，消费者在消费时，通过该job_uid查询该条记录时，查询不到，手动到数据库中查询时，发现查询到了。

代码入下(大致代码)：

```java
    @ApiOperation("提交任务")
    @PostMapping("/task/code-file/submit")
    @Transactional(rollbackFor = Exception.class)
    public AjaxResult<Object> submitTask(@Validated({TaskFileGroup.submit.class}) @NotNull(message = "TaskFileSaveVO不能未null") @RequestBody TaskFileSaveVO saveFile) throws IOException {
        taskFilesService.submitTask(saveFile);
        return AjaxResult.success();
    }





	//提交任务
    @Override
    public void submitTask(TaskFileSaveVO taskFileSaveVO) throws IOException {
    
        TaskRecord record = judgeUncommitTaskRecord(taskFileSaveVO.getTaskId());
 
        record.setJobUid(fileUid);
     
        //更新record
        if (!recordService.updateById(record)) {
            throw new ServerException("提交失败，请重试");
        }

        //消息入队列
        sendMessageToQueue(record);
    }





	//消息入队列
    private void sendMessageToQueue(TaskRecord taskRecord) {
        CreateCodeJobDto createCodeJobDto = new CreateCodeJobDto();
        createCodeJobDto.setJobUid(taskRecord.getJobUid());
        //发送消息到队列
        compileCodeSender.sendMessage(createCodeJobDto);
        log.info("【消息入队列:{}】", createCodeJobDto);
    }






//消费者消费
 @RabbitListener(queues = CompileCodeConfig.COMPILE_CODE_QUEUE)
    public void handleCode(Message message, Channel channel) {
        TaskRecord taskRecord = null;
        try {
            taskRecord = recordMapper.selectOne(Wrappers.<TaskRecord>lambdaQuery().eq(TaskRecord::getJobUid, createCodeJobDto.getJobUid()).last("LIMIT 1"));
        } catch (Exception e) {
            try {
                log.info("消费失败,失败原因：{},失败记录id：{}", e.getMessage(), taskRecord.getId());
                //如果代码逻辑产生了异常，拒绝消息，入死信队列
                channel.basicReject(message.getMessageProperties().getDeliveryTag(), false);
            } catch (Exception ex) {
                log.info("信道异常");
                throw new RuntimeException(ex);
            }
        }
    }
```

**问题：**

**问题就出现消费者消费的这一行代码**

**` taskRecord = recordMapper.selectOne(Wrappers.<TaskRecord>lambdaQuery().eq(TaskRecord::getJobUid, `**

**执行该代码时，出现查询不到，但是我在提交任务的时候，已经执行过数据库更新语句了。**

**奇葩的是，这个问题是偶尔复现的，并不是每次都会出现这种情况。**

最后分析得知，我的事务注解，是添加到controller上面的，   @Transactional(rollbackFor = Exception.class)，造成的问题是，只有controller层所有的代码执行完毕后（除了异步操作），事务才能提交。

事务解析：mysql的默认事务隔离级别是重复读（**REPEATABLE_READ**），当一个事务进行修改操作，另一个事务进行查询时，如果第一个事务没有提交，那么查到的数据是前一个事务修改之前的原始数据。 

看代码，`compileCodeSender.sendMessage(createCodeJobDto);`这是发送到队列的代码，这是一个异步操作，此时我的事务还没有提交，并且这个操作之后，我还执行了` log.info("【消息入队列:{}】", createCodeJobDto);`这句代码（其实还有自动的事务提交操作），这句代码是同步执行的，也就是调用sendMessage之后执行。

此时问题就来了，如果消息发送到队列中之后，消费者先拿到消息，并通过job_uid进行查询（注意，此时事务还没有提交，数据库中该数据的job_uid还是null），就会出现在数据库查询为null，而程序中我并没有做非null的判断，就导致执行` log.info("消费失败,失败原因：{},失败记录id：{}", e.getMessage(), taskRecord.getId());`时，taskRecord为null，报错信道异常，程序一直被卡死。

**问题复现：**

为了更好的复现该问题，在`compileCodeSender.sendMessage(createCodeJobDto)；`调用之后，我睡眠3s，查看查询效果。

```java
   //消息入队列
        compileCodeSender.sendMessage(createCodeJobDto);
        log.info("【消息入队列:{}】", createCodeJobDto);
        try {
            log.info("主程序睡眠中");
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
```

![image-20220812213436075](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220812213436075.png)

**解决方式：**

1. 方式一：在向队列中发送消息先，先手动提交事务。

   ```java
       @Autowired
       DataSourceTransactionManager dataSourceTransactionManager;
       @Autowired
       TransactionDefinition transactionDefinition;
   
   
   //提交任务
       @Override
       public void submitTask(TaskFileSaveVO taskFileSaveVO) throws IOException {
       
           try{
                     //手动开启事务
               TransactionStatus transactionStatus  = dataSourceTransactionManager.getTransaction(transactionDefinition);
   
               TaskRecord record = judgeUncommitTaskRecord(taskFileSaveVO.getTaskId());
   
               record.setJobUid(fileUid);
   
               //更新record
               if (!recordService.updateById(record)) {
                   throw new ServerException("提交失败，请重试");
               }
   
               //消息入队列
                sendMessageToQueue(record,transactionStatus);
           }catch(Exception e){
                //出现异常，进行事务回滚。
               dataSourceTransactionManager.rollback(transactionStatus);
               throw new ServerException(e.getMessage());
           }
        
       }
   
   
   
   	//消息入队列
       private void sendMessageToQueue(TaskRecord taskRecord) {
           CreateCodeJobDto createCodeJobDto = new CreateCodeJobDto();
           createCodeJobDto.setJobUid(taskRecord.getJobUid());
          //手动提交事务
           dataSourceTransactionManager.commit(transactionStatus);
           taskRecord = recordMapper.selectOne(Wrappers.<TaskRecord>lambdaQuery().eq(TaskRecord::getJobUid, createCodeJobDto.getJobUid()).last("LIMIT 1"));
           log.info("程序中的查询：{}",taskRecord);
           log.info("事务提交成功");
           //消息入队列
           compileCodeSender.sendMessage(createCodeJobDto);
           log.info("【消息入队列:{}】", createCodeJobDto);
           try {
               log.info("主程序睡眠中");
               Thread.sleep(3000);
               log.info("主程序睡眠完毕");
           } catch (InterruptedException e) {
               throw new RuntimeException(e);
           }
       }
   
   ```

   ![image-20220813095958895](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220813095958895.png)

2. 方式二：不要再在controller中加事务注解，也不要在submitTask方法中调用sendMessageToQueue方法，而是在controller中分别进行这两个方法的调用，同时在submitTask方法上添加事务注解。

### 3. Job执行

#### 1. job流程解析

![image-20220804094300892](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220804094300892.png)

1. job的信息
   1. 命名空间：所有的任务都放在code-job的命名空间下 
   2. 任务时间上限：当前job任务所能存活的最长时间，如果超过了这个时间job创建的pod还没有停止，则会自动删除
   3. 任务完成后，job等待删除时间：默认情况下，job中pod运行完成后，job则会立即删除，在此设置等待时间，可用于之后排错。
2. pod的创建
   1. 基本属性
      1. pod的数量：一个任务即一个job，一个job只产生一个pod，运行完即删除pod。
      2. pod的名称：每一个任务都有一个唯一标识的路径uuid，使用这个uuid作为job的名称以及pod名称的前缀。
      3. pod的标签：代码运行过程中，需要获取某一任务的pod，通过标签筛选的方式，获取唯一的pod，因此pod的标签也复用uuid。
   2. 环境变量：（在容器外部写一些指令，供容器内部使用）
      1. 此处设置的环境变量，主要用于容器运行时，执行脚本的时候找到相应的code路径，以及将code输出到日志中。
      2. CODE_PATH：容器内代码文件的挂载路径。  用于容器启动时， cd 到code路径中
      3. LOG_PATH：容器内代码执行时，日志输出的地方
      4. COMMAND：保存用户输入的脚本/执行命令。如果用户使用的是脚本文件 ，脚本文件名称为run.sh 则用户传入的命令为sh run.sh
3. pod的容器：
   1. 镜像：根据语言的不同，设置不同的镜像。
   2. 资源限制：用于限制pod运行时，所能使用的最大内存，CPU以及磁盘空间
      1. 内存和cpu都可以按需进行设置
      2. 磁盘空间使用storageclass动态创建pv的方式，创建pod的时候，只需要指定好所需的pvc即可
   3. 文件处理：主要用于 code，log，脚本以及数据集的挂载。
      1. code：用户提交记录时，直接生成文件到minio中的指定文件夹下，不同人物以uuid做区分。
      2. log：和code同理。
      3. 脚本文件：内置的脚本文件，主要的作用是判断用户执行脚本的时候，用户的脚本是否运行成功。
         1. 原则上，拿执行Java代码为例，需要先编译，后运行。在启动容器的时候执行编译和运行Java文件的指令，如果编译成功，运行失败，此时容器会创建失败，自动删除，这是理想的情况；但是如果编译就失败，那么pod还是继续运行的，因为这个编译错误并不是容器造成的，容器此时还是正常运行的。
         2. 内置的脚本文件中，会判断用户执行的脚本指令，比如用户需要执行  javac Hello.java和java Hello 两条命令，用户执行时，如果监听到用户的指令发生了错误，那么直接exit1，表示失败，pod接收到1的指令后，就会任务命令执行失败，终止容器。
      4. 数据集：python进行算法任务训练时，需要一些数据集，数据集是在数据众包模块上传的，位置在minio中指定的路径下，启动pod的时候，需要将数据集也挂载在容器内部，这样才能使用。需要注意的是，数据集需要设置只读权限。
   4. command命令：启动容器时，执行的命令
      1. 启动容器时，直接使用预定好的脚本执行用户的命令。
4. pod的相位：（pod运行过程中的五种状态，通过监听这五种状态，来改变任务的状态）
   1. Pending：表示资源准备中，如拉镜像
   2. Running：运行中，代码处理中
   3. Succeeded：成功
   4. Failed：表示失败
   5. Unknown：未知异常
   6. 状态每变更一次，即修改一下任务的状态。

#### 2. 生成job的yaml

```yaml
apiVersion: batch/v1
kind: Job
metadata:														 # job的元信息
  labels:
    jobName: run-code-job-197aa951c82c4bf0ac4c013c20ea3223        # jobName标签，用于获取当前job对象
  name: run-code-job-197aa951c82c4bf0ac4c013c20ea3223    		  # job名称
  namespace: code-job          									  # 命名空间
spec:															   # job的资源设置		 
  ttlSecondsAfterFinished: 300   # 该属性用于确定在所有任务执行完成后，需要等待多少秒才可删除Job。s为单位，默认五分钟
  activeDeadlineSeconds: 604800  # 任务的执行上限时间，超过这个时间则自动停止任务。s为单位，默认一周
  backoffLimit: 0                                              	  # 容器创建失败的重启次数                                     
  template:                                                       # pod的模板
    metadata:													  # pod的原信息
      creationTimestamp: null
      labels:
        controller-uid: a18f55fc-cf01-4572-832d-a577a254fbff
        job-name: run-code-job-197aa951c82c4bf0ac4c013c20ea3223
        jobName: run-code-job-197aa951c82c4bf0ac4c013c20ea3223
    spec:														 # pod的资源设置 
      automountServiceAccountToken: false
      containers:
      - command:                                                    # pod的启动命令  默认执行sh /sh/run.sh （在run.sh中通过环境变量获取用户的启动命令CODE_COMMAND执行命令）
        - sh
        - /sh/run.sh                               
        env:              											# pod的环境变量（定义的变量可在pod内部使用）
        - name: CODE_PATH                                           # 代码路径
          value: /code
        - name: LOG_PATH											 # 日志路径
          value: /log/197aa951c82c4bf0ac4c013c20ea3223.log
        - name: CODE_COMMAND										# 用户的启动命令
          value: sh run.sh 											# 表示用户使用脚本启动
        image: python:3  											# 镜像名称
        imagePullPolicy: Always
        lifecycle:                                                 # 设置回调，目的时容器创建完成后，修改代码中的业务状态，后续因为不稳定废弃
          postStart:
            httpGet:
              host: sxpt.sjzc.edu.cn
              path: alg/k8s/call/postStart?jobName=run-code-job-197aa951c82c4bf0ac4c013c20ea3223&namespace=code-job&jobUid=197aa951c82c4bf0ac4c013c20ea3223
              port: 8080
              scheme: HTTPS
        name: run-code-job-container-197aa951c82c4bf0ac4c013c20ea3223
        resources:
          limits:   # 资源的限制设置
             cpu: "1"  # 最大一核
            memory: 1000Mi # 最大1000MB
          requests: # 资源请求的设置
            cpu: 100m   #CPU请求，容器启动时的初始可用数量，将用于docker run --cpu-shares参数
            memory: 100Mi #内存请求，容器启动时的初始可用内存
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:    # 挂载到容器内部的存储卷设置
        - mountPath: /sh  # 容器内路径
          name: shell-dir # 使用的引用Pod定义的共享存储卷的名称，要用volumes[]部分定义的卷名
        - mountPath: /work/dataset/mnist
          name: data-volume-mnist
        - mountPath: /code
          name: code-volume
        - mountPath: /log
          name: log-volume
      restartPolicy: Never
      volumes:   # 定义的卷名以及对应路径，用于容器内部数据卷的挂载
      - name: shell-dir    # 脚本目录
        nfs:
          path: /home/nfs/data/run_code_sh/
          server: sxweb.sjzc.edu.cn
      - name: code-volume  # 代码目录
        nfs:      
          path: /home/nfs/data/python/197aa951c82c4bf0ac4c013c20ea3223/code
          server: sxweb.sjzc.edu.cn
      - name: log-volume    # 日志目录
        nfs:          
          path: /home/nfs/data/python/197aa951c82c4bf0ac4c013c20ea3223/log
          server: sxweb.sjzc.edu.cn
      - name: data-volume-mnist  # 数据集目录
        nfs:
          path: /home/nfs/data/minio/train-platform/dataset/public-dataset/dev/mnist
          readOnly: true     # 表示只读
          server: sxweb.sjzc.edu.cn
```

#### 3. Java客户端实现

##### K8s配置

###### K8s客户端链接

```java
@Data
@Configuration
public class K8sConfig implements ApplicationContextAware {

    /**
     * nfs服务器ip
     */
    @Value("${k8s.nfs.server}")
    private String nfsServer;



    @Value("${k8s.connect-timeout}")
    private Integer connectTimeout;

    private ApplicationContext context;

    @Bean
    public ApiClient getClient() throws IOException {
        ClassPathResource resource = new ClassPathResource("k8s/config");
        //获取客户端
        InputStream stream = resource.getStream();
        ApiClient client = ClientBuilder.kubeconfig(KubeConfig.loadKubeConfig(new InputStreamReader(stream))).build();
        client.setReadTimeout(connectTimeout);
        io.kubernetes.client.openapi.Configuration.setDefaultApiClient(client);
        return client;
    }


    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        context = applicationContext;
    }


}
```

**配置文件所在路径**

![image-20220822145106723](https://mynotepicbed.oss-cn-beijing.aliyuncs.com/img/image-20220822145106723.png)

###### K8s默认的一些配置

```java
package com.train.algorithm.k8s.config;

import lombok.Data;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.stereotype.Component;

/**
 * @description k8s 运行代码job 配置
 */
@Data
@Component
@ConfigurationProperties(prefix = "k8s.job")
public class K8sRunCodeConfig {

    /**
     * postStart 回调路径
     */
    private String callBackPath;

    /**
     * postStart 回调地址ip
     */
    private String callBackHost;

    /**
     * 回调端口
     */
    private Integer callBackPort;

    /**
     * 容器内代码路径
     */
    private String codePath;

    /**
     * 容器内日志路径
     */
    private String logPath;

    /**
     * 容器内数据集路径
     */
    private String dataPath;

    /**
     * job命名空间
     */
    private String namespace;

    /**
     * 在线编程job的筛选标签
     */
    private String jobLabel;


    /**
     * 在线编程job的最大数量
     */
    private Integer jobMaxNum;



}

```

##### 实体

###### **消息体：用户自定义的一些数据，发送至消息队列**

```java
@Data
@Accessors(chain = true)
public class CreateCodeJobDto {

    /**
     * 任务唯一id
     */
    @NotBlank
    private String jobUid;

    /**
     *  代码文件位置（绝对路径）
     */
    @NotBlank
    private String codePath;

    /**
     * 日志文件位置 （绝对路径）
     */
    @NotBlank
    private String logPath;

    /**
     *  key：数据集标识，value 数据集路径（容器外）
     */
    private Map<String,String> dataListMap;


    /**
     * 容器运行命令
     */
    private String command;

    /**
     * 版本号 (可以不传，会使用默认版本号)
     */
    private String version;
    /**
     * 代码类型
     */
    @NotNull
    private CodeType codeType;

    public String getCommand() {
        // 如果没有设置命令使用内置命令
        if (StrUtil.isBlank(command)) {
            command = codeType.getCommand();
        }
        return command;
    }
}
```

###### **语言的版本，默认命令**

```java
@Getter
@AllArgsConstructor
public enum CodeType {
    /**
     * python
     */
    PYTHON(0,"sh /sh/python.sh","python:3.7"),

    JAVA(-1,"sh /sh/java.sh","dquintela/openjdk-8-jdk-alpine"),

    /**
     * R 语言
     */
    R(1,"sh /sh/R.sh","r-base"),

    /**
     * scala
     */
    SCALA(2,"sh /sh/scala.sh","1427421650/scala-image");

    /**
     * 类型编号
     */
    private final Integer index;

    /**
     * 运行命令
     */
    private final String command;

    /**
     * 镜像名
     */
    private final String imageName;

    public static CodeType valueOf(Integer index) {
        Map<Integer, CodeType> map = Arrays.stream(CodeType.values()).collect(Collectors.toMap(CodeType::getIndex, o -> o));
        return map.get(index);
    }
}
```

###### **K8s的相位，即运行周期**

```java
@Getter
@AllArgsConstructor
public enum PhaseConstant {

    /**
     * PENDING
     */
    PENDING(2,"Pending"),
    /**
     * running
     */
    RUNNING(2,"Running"),
    /**
     * Succeeded
     */
    SUCCEEDED (3, "Succeeded"),
    /**
     * Failed
     */
    FAILED(4,"Failed"),
    /**
     * Unknown
     */
    UNKNOWN (4,"Unknown");

    /**
     * 对应任务状态
     */
    private final Integer status;

    private final String name;

    public static PhaseConstant findByName(String name){
        Map<String, PhaseConstant> map = Arrays.stream(values()).collect(Collectors.toMap(PhaseConstant::getName, o -> o));
        return map.get(name);
    }
}
```

###### 其他实体

**环境变量**

```java
@Data
@Accessors(chain = true)
public class K8sEnv {

    @NotBlank
    private String name;

    @NotBlank
    private String value;
}

```

**数据卷**

```java
@Data
@Accessors(chain = true)
public class Volume {
    /**
     * 卷名
     */
    private String name = "";

    /**
     * 共享的卷名
     */
    private String path = "";

    /**
     * 是否设置为只读
     */
    private Boolean readOnly = false;

}

```

**数据卷常量**

```java
public class VolumeConstant {

    public static final String  CODE = "code-volume";
    public static final String  LOG = "log-volume";
    public static final String  DATA = "data-volume";


}
```

**挂载卷**

```java
@Data
@Accessors(chain = true)
public class VolumeMount {
    /**
     * 挂载的卷名
     */
    private String name = "";

    /**
     * 挂载路径
     */
    private String path = "";

    /**
     * 是否设置为只读
     */
    private Boolean readOnly = false;

}
```

**K8sjob的属性实体，所有需要设置的属性**

```java
package com.train.algorithm.k8s;

import com.train.algorithm.k8s.entity.K8sEnv;
import com.train.algorithm.k8s.entity.Volume;
import com.train.algorithm.k8s.entity.VolumeMount;
import lombok.Data;
import lombok.experimental.Accessors;

import javax.validation.constraints.NotBlank;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * @description
 * @date 2022/6/18 9:18
 */
@Data
@Accessors(chain = true)
public class K8sJobDto {

    public static final String JOB_PREFIX = "run-code-job-";

    public static final String CONTAINER_PREFIX = "run-code-job-container-";
    /**
     * job唯一标识，加上前缀后生成job名
     */
    @NotBlank
    private String jobId;

    /**
     * job名
     */
    private String jobName;

    /**
     * 镜像名字
     */
    @NotBlank
    private String imageName;

    /**
     * 命名空间
     */
    private String namespace = "default";

    /**
     * 挂载
     */
    @NotBlank
    private List<VolumeMount> volumeMounts;

    /**
     * 共享卷
     */
    private List<Volume> volumes;

    /**
     * label
     */
    private Map<String, String> labels;

    /**
     * 环境变量
     */
    private List<K8sEnv> envs;

    /**
     * 运行启动时命令
     *
     */
    private String command;

    /**
     * 回调参数
     */
    private Map<String,Object> callbackParams;


    /**
     * 容器开始前回调路径
     */
    private String callBackBasePath;


    public Map<String, String> getLabels() {
        if (labels == null) {
            labels = new HashMap<>();
            labels.put("jobName",jobName);
        }
        return labels;
    }

    public String getJobName() {
        if (getJobId()!=null && jobName == null) {
            jobName = JOB_PREFIX + jobId;
        }
        return jobName;
    }

}

```

##### 创建job

###### **外部调用接口，处理消息**

```java
public void createCodeJob(@Valid CreateCodeJobDto createCodeJobDto) {
    // redis中插入任务标识，防止创建过程中删除
    if (!redisService.hasKey(createCodeJobDto.getJobUid())) {
        redisService.setCacheObject(createCodeJobDto.getJobUid(),true);
    }
    log.info("【开始创建codejob】jobuid:{}",createCodeJobDto.getJobUid());
    K8sJobDto k8sJobDto = new K8sJobDto();
    // set uid 后name自动生成 直接调用k8sJobDto.getJobName() 获取名字
    k8sJobDto.setJobId(createCodeJobDto.getJobUid());
    Map<String, Object> params = new HashMap<>();
    params.put("jobName",k8sJobDto.getJobName());
    params.put("namespace",runCodeConfig.getNamespace());
    params.put("jobUid",createCodeJobDto.getJobUid());
    String imageName = createCodeJobDto.getCodeType().getImageName();
    if (StrUtil.isNotBlank(createCodeJobDto.getVersion())) {
        String[] split = imageName.split(":");
        imageName = imageName.replace(split[1], createCodeJobDto.getVersion());
    }
    // 设置环境变量
    List<K8sEnv> envList = new ArrayList<>();
    // 将容器内代码路径放到环境变量中，容器创建好后会进入用户的代码目录下
    envList.add(new K8sEnv().setName("CODE_PATH").setValue(runCodeConfig.getCodePath()));
    // 将容器内日志路径放到环境变量中，代码执行结果会输出到该目录下 详见（run.sh 文件）
    // 生成日志文件全路径 (日志文件名 = 日志路径 + jobName + 后缀)
    String logFullPath = runCodeConfig.getLogPath() + "/"+createCodeJobDto.getJobUid()+ ".log";
    envList.add(new K8sEnv().setName("LOG_PATH").setValue(logFullPath));
    envList.add(new K8sEnv().setName("CODE_COMMAND").setValue(createCodeJobDto.getCommand()));
    k8sJobDto.setEnvs(envList);
    //共享卷列表
    List<Volume> volumeList = new ArrayList<>();
    // 挂载路径
    List<VolumeMount> volumeMounts = new ArrayList<>();
    volumeList.add(new Volume().setName(VolumeConstant.CODE).setPath(createCodeJobDto.getCodePath()));
    volumeList.add(new Volume().setName(VolumeConstant.LOG).setPath(createCodeJobDto.getLogPath()));
    if (CollectionUtil.isNotEmpty(createCodeJobDto.getDataListMap())) {
        Map<String, String> dataListMap = createCodeJobDto.getDataListMap();
        dataListMap.forEach((dataName,dataPath)->{
            String dataFullPath = minioConfig.getBaseUrl() + "/"+dataPath;
            String dataPathVolumeName = VolumeConstant.DATA+"-"+dataName;
            volumeList.add(new Volume().setName(dataPathVolumeName).setPath(dataFullPath).setReadOnly(true));
            volumeMounts.add(new VolumeMount().setName(dataPathVolumeName).setPath(runCodeConfig.getDataPath()+"/"+dataName).setReadOnly(true));
        });
    }
    k8sJobDto.setVolumes(volumeList);
    volumeMounts.add(new VolumeMount().setName(VolumeConstant.CODE).setPath(runCodeConfig.getCodePath()));
    volumeMounts.add(new VolumeMount().setName(VolumeConstant.LOG).setPath(runCodeConfig.getLogPath()));
    k8sJobDto.setVolumeMounts(volumeMounts);
    k8sJobDto.setImageName(imageName)
            .setNamespace(runCodeConfig.getNamespace())
            .setCallBackBasePath(runCodeConfig.getCallBackPath())
            .setCallbackParams(params);
    try {
        // 此处判断job标识是否存在，如果不存在说明该任务已经终止,不再继续往下执行
        if(!isRunning(createCodeJobDto.getJobUid())) {
            return;
        }
        taskRecordService.updateTaskStatusToRun(k8sJobDto.getJobId(), TaskStatusEnum.TASK_EXEC.getStatus());
        // 创建job容器成功后开启监听
        if (this.createJob(k8sJobDto)) {
            watchPod(runCodeConfig.getNamespace(), k8sJobDto.getJobName(), k8sJobDto.getJobId());
        }
    } catch (ApiException e){
        // 更新状态
        taskRecordService.updateTaskStatus(k8sJobDto.getJobId(), TaskStatusEnum.TASK_FAIL.getStatus());
        log.error("【创建容器失败】，错误信息：{}，jobId:{}",e.getMessage(),k8sJobDto.getJobId());
    } /*catch (InterruptedException e) {
        throw new RuntimeException(e);
    }*/
}
```

###### **创建Job**

```java
    public boolean createJob(K8sJobDto jobDto) throws ApiException {
        log.info("【开始创建job容器】,jobUid：{}",jobDto.getJobId());
        V1Job v1Job = getV1JobInstance();
        BatchV1Api batchV1Api = getBachV1ApiInstance();
        // job名称
        String jobName = jobDto.getJobName();
        //容器名称
        String containerName = K8sJobDto.CONTAINER_PREFIX + jobDto.getJobId();
        // 设置metadata
        V1ObjectMeta meta = v1Job.getMetadata();
        assert meta != null;
        meta.setName(jobName);
        meta.setLabels(jobDto.getLabels());
        meta.setNamespace(jobDto.getNamespace());
        v1Job.setMetadata(meta);

        //v1JobSpec
        V1JobSpec jobSpec = v1Job.getSpec();
        //template
        assert jobSpec != null;
        V1PodTemplateSpec template = jobSpec.getTemplate();
        V1ObjectMeta podMeta = new V1ObjectMeta();
        podMeta.setLabels(jobDto.getLabels());
        template.setMetadata(podMeta);
        V1PodSpec spec = template.getSpec();
        assert spec != null;
        V1Container v1Container =  spec.getContainers().get(0);
        v1Container.setName(containerName);
        v1Container.setImage(jobDto.getImageName());

        // 配置env
        List<V1EnvVar> envList = new ArrayList<>();
        for (K8sEnv env : jobDto.getEnvs()) {
            V1EnvVar v1EnvVar = new V1EnvVar();
            v1EnvVar.setName(env.getName());
            v1EnvVar.setValue(env.getValue());
            envList.add(v1EnvVar);
        }
        v1Container.setEnv(envList);

        //设置 lifecycle 回调
     /*   V1Lifecycle lifecycle  = new V1LifecycleBuilder().build();
        V1Handler v1Handler = new V1Handler();
        V1HTTPGetAction v1HTTPGetAction = new V1HTTPGetAction();
        v1HTTPGetAction.setHost(runCodeConfig.getCallBackHost());
        String path = buildPath(jobDto.getCallBackBasePath(), jobDto.getCallbackParams());
        v1HTTPGetAction.setPath(path);
        v1HTTPGetAction.setPort(new IntOrString(runCodeConfig.getCallBackPort()));
        v1HTTPGetAction.setScheme("HTTP");
        v1Handler.setHttpGet(v1HTTPGetAction);
        lifecycle.setPostStart(v1Handler);
        v1Container.setLifecycle(lifecycle);*/

        // 创建共享nfs储存卷
        List<V1Volume> volumes = spec.getVolumes();
        if (CollectionUtil.isEmpty(volumes)) {
            volumes = new ArrayList<>();
        }
        // 设置共享目录
        for (Volume volume : jobDto.getVolumes()) {
            V1Volume v1Volume = new V1Volume();
            v1Volume.setName(volume.getName());
            V1NFSVolumeSource nfsVolume = new V1NFSVolumeSource();
            nfsVolume.setPath(volume.getPath());
            nfsVolume.setServer(k8sConfig.getNfsServer());
            nfsVolume.setReadOnly(volume.getReadOnly());
            v1Volume.setNfs(nfsVolume);
            volumes.add(v1Volume);
        }
        spec.setVolumes(volumes);
        template.setSpec(spec);

        //容器与共享卷进行挂载
        List<V1VolumeMount> volumeMounts =  v1Container.getVolumeMounts();
        if (CollectionUtil.isEmpty(volumeMounts)) {
            volumeMounts = new ArrayList<>();
        }
        for (VolumeMount volumeMount : jobDto.getVolumeMounts()) {
            V1VolumeMount v1VolumeMount = new V1VolumeMount();
            v1VolumeMount.setName(volumeMount.getName());
            v1VolumeMount.setMountPath(volumeMount.getPath());
//            v1VolumeMount.setReadOnly(volumeMount.getReadOnly());
            volumeMounts.add(v1VolumeMount);
        }
        v1Container.setVolumeMounts(volumeMounts);

        //设置命令
        v1Container.setCommand(Arrays.asList("sh","/sh/run.sh"));
//        v1Container.setArgs(Arrays.asList(jobDto.getArgs()));
        jobSpec.setTemplate(template);
        v1Job.setSpec(jobSpec);
        //创建前判断任务是否还在运行状态
        if (!isRunning(jobDto.getJobId())) {
            log.info("【未创建job】任务状态已停止 jobName:{},namespace:{}",jobName,jobDto.getNamespace());
            return false;
        }
        V1Job job = batchV1Api.createNamespacedJob(jobDto.getNamespace(), v1Job, "false", null, null);
        log.info("【创建job成功】jobName:{},namespace:{}",jobName,jobDto.getNamespace());
        return true;
    }
```

###### 开启Job监听

监听pod的相位，更新任务状态

```java
@Async
public void watchPod(String namespace,String jobName,String jobUid)  {
    log.info("【开启job监听】job名称:{}，命名空间:{}",jobName,namespace);
    // watch前判断是否已经终止
    if (!isRunning(jobUid)){
        return;
    }
    String labelName = "jobName="+jobName;
    Call call;
    CoreV1Api coreV1Api = getCoreApiInstance();
    try {
        call = coreV1Api.listNamespacedPodCall(namespace, null, null, null,null,labelName,
                null, null, null, true, null);
    } catch (ApiException e) {
        log.error("【job监听失败】pod资源已删除或不存在, job：{},namespace:{}", jobName, namespace);
        throw new ServiceException("pod资源已删除或不存在");
    }
    Set<String> table = new HashSet<>();
    try (Watch<V1Pod> watch = Watch.createWatch(
            apiClient,
            call,
            new TypeToken<Watch.Response<V1Pod>>() {
            }.getType())) {
        for (Watch.Response<V1Pod> item : watch) {
            //每次监听都查询 job标识是否存在
            if (!isRunning(jobUid)) {
                // 标识被删除，说明任务被终止，停止监听，删除pod
                stopCodejob(jobUid);
                watch.close();
                break;
            }
            String podName = Objects.requireNonNull(item.object.getMetadata()).getName();
            String type = item.type;
            String phase = Objects.requireNonNull(item.object.getStatus()).getPhase();
            // 去重 避免重复执行
            if (table.contains(type + phase)) {
                continue;
            }
            table.add(type + phase);
            log.info("type:{}，phase:{},", type, phase);
            Integer status = judgePhase(phase, namespace, labelName);
            //根据job_uid 更新状态
            taskRecordService.updateTaskStatusToRun(jobUid,status);
        }
    } catch (Exception e) {
        log.error("【监听容器异常】错误信息:{}", e.getMessage());
    } finally {
        //监听结束，删除资源
        stopCodejob(jobUid);
        log.info("【watch 监听结束】 jobName：{},namespace:{}", jobName, namespace);
    }
}

	//判断job是否还在运行
    private boolean isRunning(String jobUid) {
        return redisService.hasKey(jobUid);
    }

	//停止job
    public void stopCodejob(String jobUid) {
        // 删除标识运行的key
        if (redisService.hasKey(jobUid)) {
            redisService.deleteObject(jobUid);
        }
        String jobName = JOB_PREFIX + jobUid;
        try {
            deleteJob(runCodeConfig.getNamespace(),jobName);
        } catch (Exception e) {
            log.error("【停止job失败】job名称 :{}",jobName);
        }
    }

	//pod的相位判断，更新pod状态
    private Integer judgePhase(String phase, String namespace, String labelName) throws IOException, ApiException {
        String logs;
        PhaseConstant phaseEnum = PhaseConstant.findByName(phase);
        switch (phaseEnum) {
            case PENDING:
                log.info("【容器正在启动...】");
                break;
            case RUNNING:
                log.info("【容器运行中...】");
                break;
            case SUCCEEDED:
                logs =  getPodLogs(namespace, labelName);
                log.info("【容器运行成功...】\n 运行结果：{}",logs);
                break;
            case FAILED:
                logs = getPodLogs(namespace, labelName);
                log.info("【容器运行失败...】\n 错误日志：{}", logs);
                break;
            case UNKNOWN:
                log.info("【容器通信错误...】");
                break;
            default:
                log.info("【未知状态...】");
        }
        return phaseEnum.getStatus();
    }
```

###### 方法汇总

```java
package com.train.algorithm.k8s;

import cn.hutool.core.collection.CollectionUtil;
import cn.hutool.core.util.StrUtil;
import com.google.gson.reflect.TypeToken;
import com.train.algorithm.k8s.config.K8sConfig;
import com.train.algorithm.k8s.config.K8sRunCodeConfig;
import com.train.algorithm.k8s.entity.K8sEnv;
import com.train.algorithm.k8s.entity.Volume;
import com.train.algorithm.k8s.entity.VolumeConstant;
import com.train.algorithm.k8s.entity.VolumeMount;
import com.train.algorithm.service.ITaskRecordService;
import com.train.algorithm.utils.enums.TaskStatusEnum;
import com.train.common.core.exception.ServiceException;
import com.train.common.minio.MinioConfig;
import com.train.common.redis.service.RedisService;
import io.kubernetes.client.PodLogs;
import io.kubernetes.client.openapi.ApiClient;
import io.kubernetes.client.openapi.ApiException;
import io.kubernetes.client.openapi.apis.BatchV1Api;
import io.kubernetes.client.openapi.apis.CoreV1Api;
import io.kubernetes.client.openapi.models.*;
import io.kubernetes.client.util.Watch;
import io.kubernetes.client.util.Yaml;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import okhttp3.Call;
import org.apache.tomcat.util.http.fileupload.util.Streams;
import org.springframework.core.io.DefaultResourceLoader;
import org.springframework.core.io.ResourceLoader;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Component;

import javax.validation.Valid;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.Reader;
import java.util.*;

/**
 * @author zhq
 * @description k8s操作类
 * @date 2022/7/13 10:23
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class K8sService {

    private final K8sRunCodeConfig runCodeConfig;

    private final ITaskRecordService taskRecordService;

    private final K8sConfig k8sConfig;

    private final MinioConfig minioConfig;

    private final ApiClient apiClient;

    private final RedisService redisService;

    public CoreV1Api getCoreApiInstance() {
        return new CoreV1Api(apiClient);
    }

    public BatchV1Api getBachV1ApiInstance() {
        return new BatchV1Api(apiClient);
    }

    public static final String JOB_PREFIX = "run-code-job-";

    public V1Job getV1JobInstance(){
        try {
            ResourceLoader resourceLoader =new DefaultResourceLoader();

            InputStream inputStream = resourceLoader.getResource("k8s/template/test_pod.yaml").getInputStream();
            Reader reader = new InputStreamReader(inputStream);
            //指定管理器类型
            Yaml.addModelMap("batch/v1","Job", V1Job.class);
            //对象映射
            return (V1Job)Yaml.load(reader);
        } catch (IOException e) {
            log.error("【读取k8s配置文件失败】错误信息：{}",e.getMessage());
            throw new RuntimeException("文件读取失败");
        }
    }

    public void createCodeJob(@Valid CreateCodeJobDto createCodeJobDto) {
        // redis中插入任务标识，防止创建过程中删除
        if (!redisService.hasKey(createCodeJobDto.getJobUid())) {
            redisService.setCacheObject(createCodeJobDto.getJobUid(),true);
        }
        log.info("【开始创建codejob】jobuid:{}",createCodeJobDto.getJobUid());
        K8sJobDto k8sJobDto = new K8sJobDto();
        // set uid 后name自动生成 直接调用k8sJobDto.getJobName() 获取名字
        k8sJobDto.setJobId(createCodeJobDto.getJobUid());
        Map<String, Object> params = new HashMap<>();
        params.put("jobName",k8sJobDto.getJobName());
        params.put("namespace",runCodeConfig.getNamespace());
        params.put("jobUid",createCodeJobDto.getJobUid());
        String imageName = createCodeJobDto.getCodeType().getImageName();
        if (StrUtil.isNotBlank(createCodeJobDto.getVersion())) {
            String[] split = imageName.split(":");
            imageName = imageName.replace(split[1], createCodeJobDto.getVersion());
        }
        // 设置环境变量
        List<K8sEnv> envList = new ArrayList<>();
        // 将容器内代码路径放到环境变量中，容器创建好后会进入用户的代码目录下
        envList.add(new K8sEnv().setName("CODE_PATH").setValue(runCodeConfig.getCodePath()));
        // 将容器内日志路径放到环境变量中，代码执行结果会输出到该目录下 详见（run.sh 文件）
        // 生成日志文件全路径 (日志文件名 = 日志路径 + jobName + 后缀)
        String logFullPath = runCodeConfig.getLogPath() + "/"+createCodeJobDto.getJobUid()+ ".log";
        envList.add(new K8sEnv().setName("LOG_PATH").setValue(logFullPath));
        envList.add(new K8sEnv().setName("CODE_COMMAND").setValue(createCodeJobDto.getCommand()));
        k8sJobDto.setEnvs(envList);
        //共享卷列表
        List<Volume> volumeList = new ArrayList<>();
        // 挂载路径
        List<VolumeMount> volumeMounts = new ArrayList<>();
        volumeList.add(new Volume().setName(VolumeConstant.CODE).setPath(createCodeJobDto.getCodePath()));
        volumeList.add(new Volume().setName(VolumeConstant.LOG).setPath(createCodeJobDto.getLogPath()));
        if (CollectionUtil.isNotEmpty(createCodeJobDto.getDataListMap())) {
            Map<String, String> dataListMap = createCodeJobDto.getDataListMap();
            dataListMap.forEach((dataName,dataPath)->{
                String dataFullPath = minioConfig.getBaseUrl() + "/"+dataPath;
                String dataPathVolumeName = VolumeConstant.DATA+"-"+dataName;
                volumeList.add(new Volume().setName(dataPathVolumeName).setPath(dataFullPath).setReadOnly(true));
                volumeMounts.add(new VolumeMount().setName(dataPathVolumeName).setPath(runCodeConfig.getDataPath()+"/"+dataName).setReadOnly(true));
            });
        }
        k8sJobDto.setVolumes(volumeList);
        volumeMounts.add(new VolumeMount().setName(VolumeConstant.CODE).setPath(runCodeConfig.getCodePath()));
        volumeMounts.add(new VolumeMount().setName(VolumeConstant.LOG).setPath(runCodeConfig.getLogPath()));
        k8sJobDto.setVolumeMounts(volumeMounts);
        k8sJobDto.setImageName(imageName)
                .setNamespace(runCodeConfig.getNamespace())
                .setCallBackBasePath(runCodeConfig.getCallBackPath())
                .setCallbackParams(params);
        try {
            // 此处判断job标识是否存在，如果不存在说明该任务已经终止,不再继续往下执行
            if(!isRunning(createCodeJobDto.getJobUid())) {
                return;
            }
            taskRecordService.updateTaskStatusToRun(k8sJobDto.getJobId(), TaskStatusEnum.TASK_EXEC.getStatus());
            // 创建job容器成功后开启监听
            if (this.createJob(k8sJobDto)) {
                watchPod(runCodeConfig.getNamespace(), k8sJobDto.getJobName(), k8sJobDto.getJobId());
            }
        } catch (ApiException e){
            // 更新状态
            taskRecordService.updateTaskStatus(k8sJobDto.getJobId(), TaskStatusEnum.TASK_FAIL.getStatus());
            log.error("【创建容器失败】，错误信息：{}，jobId:{}",e.getMessage(),k8sJobDto.getJobId());
        } /*catch (InterruptedException e) {
            throw new RuntimeException(e);
        }*/
    }

    public boolean createJob(K8sJobDto jobDto) throws ApiException {
        log.info("【开始创建job容器】,jobUid：{}",jobDto.getJobId());
        V1Job v1Job = getV1JobInstance();
        BatchV1Api batchV1Api = getBachV1ApiInstance();
        // job名称
        String jobName = jobDto.getJobName();
        //容器名称
        String containerName = K8sJobDto.CONTAINER_PREFIX + jobDto.getJobId();
        // 设置metadata
        V1ObjectMeta meta = v1Job.getMetadata();
        assert meta != null;
        meta.setName(jobName);
        meta.setLabels(jobDto.getLabels());
        meta.setNamespace(jobDto.getNamespace());
        v1Job.setMetadata(meta);

        //v1JobSpec
        V1JobSpec jobSpec = v1Job.getSpec();
        //template
        assert jobSpec != null;
        V1PodTemplateSpec template = jobSpec.getTemplate();
        V1ObjectMeta podMeta = new V1ObjectMeta();
        podMeta.setLabels(jobDto.getLabels());
        template.setMetadata(podMeta);
        V1PodSpec spec = template.getSpec();
        assert spec != null;
        V1Container v1Container =  spec.getContainers().get(0);
        v1Container.setName(containerName);
        v1Container.setImage(jobDto.getImageName());

        // 配置env
        List<V1EnvVar> envList = new ArrayList<>();
        for (K8sEnv env : jobDto.getEnvs()) {
            V1EnvVar v1EnvVar = new V1EnvVar();
            v1EnvVar.setName(env.getName());
            v1EnvVar.setValue(env.getValue());
            envList.add(v1EnvVar);
        }
        v1Container.setEnv(envList);

        //设置 lifecycle 回调
     /*   V1Lifecycle lifecycle  = new V1LifecycleBuilder().build();
        V1Handler v1Handler = new V1Handler();
        V1HTTPGetAction v1HTTPGetAction = new V1HTTPGetAction();
        v1HTTPGetAction.setHost(runCodeConfig.getCallBackHost());
        String path = buildPath(jobDto.getCallBackBasePath(), jobDto.getCallbackParams());
        v1HTTPGetAction.setPath(path);
        v1HTTPGetAction.setPort(new IntOrString(runCodeConfig.getCallBackPort()));
        v1HTTPGetAction.setScheme("HTTP");
        v1Handler.setHttpGet(v1HTTPGetAction);
        lifecycle.setPostStart(v1Handler);
        v1Container.setLifecycle(lifecycle);*/

        // 创建共享nfs储存卷
        List<V1Volume> volumes = spec.getVolumes();
        if (CollectionUtil.isEmpty(volumes)) {
            volumes = new ArrayList<>();
        }
        // 设置共享目录
        for (Volume volume : jobDto.getVolumes()) {
            V1Volume v1Volume = new V1Volume();
            v1Volume.setName(volume.getName());
            V1NFSVolumeSource nfsVolume = new V1NFSVolumeSource();
            nfsVolume.setPath(volume.getPath());
            nfsVolume.setServer(k8sConfig.getNfsServer());
            nfsVolume.setReadOnly(volume.getReadOnly());
            v1Volume.setNfs(nfsVolume);
            volumes.add(v1Volume);
        }
        spec.setVolumes(volumes);
        template.setSpec(spec);

        //容器与共享卷进行挂载
        List<V1VolumeMount> volumeMounts =  v1Container.getVolumeMounts();
        if (CollectionUtil.isEmpty(volumeMounts)) {
            volumeMounts = new ArrayList<>();
        }
        for (VolumeMount volumeMount : jobDto.getVolumeMounts()) {
            V1VolumeMount v1VolumeMount = new V1VolumeMount();
            v1VolumeMount.setName(volumeMount.getName());
            v1VolumeMount.setMountPath(volumeMount.getPath());
//            v1VolumeMount.setReadOnly(volumeMount.getReadOnly());
            volumeMounts.add(v1VolumeMount);
        }
        v1Container.setVolumeMounts(volumeMounts);

        //设置命令
        v1Container.setCommand(Arrays.asList("sh","/sh/run.sh"));
//        v1Container.setArgs(Arrays.asList(jobDto.getArgs()));
        jobSpec.setTemplate(template);
        v1Job.setSpec(jobSpec);
        //创建前判断任务是否还在运行状态
        if (!isRunning(jobDto.getJobId())) {
            log.info("【未创建job】任务状态已停止 jobName:{},namespace:{}",jobName,jobDto.getNamespace());
            return false;
        }
        V1Job job = batchV1Api.createNamespacedJob(jobDto.getNamespace(), v1Job, "false", null, null);
        log.info("【创建job成功】jobName:{},namespace:{}",jobName,jobDto.getNamespace());
        return true;
    }

    /**
     * description: 查询任务是否在运行
     *
     * @param jobUid job标识
     * @return boolean
     * @date 2022/8/12 11:04
     */
    private boolean isRunning(String jobUid) {
        return redisService.hasKey(jobUid);
    }

    private String buildPath(String basePath,Map<String,Object> params) {
        StringBuilder pathBuilder = new StringBuilder(basePath);
        int size = params.size();
        int i = 0;
        for (String key : params.keySet()) {
            if (i == 0) {
                pathBuilder.append("?");
            }
            Object value = params.get(key);
            pathBuilder.append(key).append("=").append(value);
            if (i < size -1) {
                pathBuilder.append("&");
            }
            i++;
        }
        return pathBuilder.toString();
    }


    @Async
    public void watchPod(String namespace,String jobName,String jobUid)  {
        log.info("【开启job监听】job名称:{}，命名空间:{}",jobName,namespace);
        // watch前判断是否已经终止
        if (!isRunning(jobUid)){
            return;
        }
        String labelName = "jobName="+jobName;
        Call call;
        CoreV1Api coreV1Api = getCoreApiInstance();
        try {
            call = coreV1Api.listNamespacedPodCall(namespace, null, null, null,null,labelName,
                    null, null, null, true, null);
        } catch (ApiException e) {
            log.error("【job监听失败】pod资源已删除或不存在, job：{},namespace:{}", jobName, namespace);
            throw new ServiceException("pod资源已删除或不存在");
        }
        Set<String> table = new HashSet<>();
        try (Watch<V1Pod> watch = Watch.createWatch(
                apiClient,
                call,
                new TypeToken<Watch.Response<V1Pod>>() {
                }.getType())) {
            for (Watch.Response<V1Pod> item : watch) {
                //每次监听都查询 job标识是否存在
                if (!isRunning(jobUid)) {
                    // 标识被删除，说明任务被终止，停止监听，删除pod
                    stopCodejob(jobUid);
                    watch.close();
                    break;
                }
                String podName = Objects.requireNonNull(item.object.getMetadata()).getName();
                String type = item.type;
                String phase = Objects.requireNonNull(item.object.getStatus()).getPhase();
                // 去重 避免重复执行
                if (table.contains(type + phase)) {
                    continue;
                }
                table.add(type + phase);
                log.info("type:{}，phase:{},", type, phase);
                Integer status = judgePhase(phase, namespace, labelName);
                //根据job_uid 更新状态
                taskRecordService.updateTaskStatusToRun(jobUid,status);
            }
        } catch (Exception e) {
            log.error("【监听容器异常】错误信息:{}", e.getMessage());
        } finally {
            //监听结束，删除资源
            stopCodejob(jobUid);
            log.info("【watch 监听结束】 jobName：{},namespace:{}", jobName, namespace);
        }
    }

    /**
     * description: 判断容器状态
     *
     * @author: zhq
     * @param phase 相位
     * @param namespace 命名空间
     * @param labelName 标签
     * @date 2022/7/14 10:37
     */
    private Integer judgePhase(String phase, String namespace, String labelName) throws IOException, ApiException {
        String logs;
        PhaseConstant phaseEnum = PhaseConstant.findByName(phase);
        switch (phaseEnum) {
            case PENDING:
                log.info("【容器正在启动...】");
                break;
            case RUNNING:
                log.info("【容器运行中...】");
                break;
            case SUCCEEDED:
                logs =  getPodLogs(namespace, labelName);
                log.info("【容器运行成功...】\n 运行结果：{}",logs);
                break;
            case FAILED:
                logs = getPodLogs(namespace, labelName);
                log.info("【容器运行失败...】\n 错误日志：{}", logs);
                break;
            case UNKNOWN:
                log.info("【容器通信错误...】");
                break;
            default:
                log.info("【未知状态...】");
        }
        return phaseEnum.getStatus();
    }
    /**
     * description: 删除命名空间下的job
     *
     * @author: zhq
     * @param nameSpace 命名空间
     * @param jobName job名
     * @date 2022/7/13 14:43
     */
    public void deleteJob(String nameSpace, String jobName) {
        BatchV1Api batchV1Api = getBachV1ApiInstance();
        try {
            batchV1Api.deleteNamespacedJob(jobName, nameSpace, "true", null, null, null, "Foreground", null);
        } catch (Exception e)
        {
            if (e.getCause() instanceof IllegalStateException) {
                IllegalStateException ise = (IllegalStateException) e.getCause();
                if (ise.getMessage() != null && ise.getMessage().contains("Expected a string but was BEGIN_OBJECT")) {
                    log.info("Catching exception because of issue https://github.com/kubernetes/kubernetes/issues/65121");
                }
                return;
            }
            final String NOT_FOUND = "Not Found";
            if (e.getMessage().equals(NOT_FOUND) ) {
                log.error("【删除任务失败，未找到该任务】,任务名：{},命名空间：{}",jobName,nameSpace);
                throw new ServiceException("【删除任务失败，未找到该任务】");
            }
            log.error("【删除任务失败，未知错误】,任务名：{},命名空间：{}，错误信息:{}",jobName,nameSpace,e.getMessage());
            throw new ServiceException("【删除任务失败，未知错误】错误信息："+e.getMessage());
        }

    }


    /**
     * description: 停止job
     *
     * @author: zhq
     * @param jobUid job 唯一id
     * @date 2022/7/21 22:08
     */
    public void stopCodejob(String jobUid) {
        // 删除标识运行的key
        if (redisService.hasKey(jobUid)) {
            redisService.deleteObject(jobUid);
        }
        String jobName = JOB_PREFIX + jobUid;
        try {
            deleteJob(runCodeConfig.getNamespace(),jobName);
        } catch (Exception e) {
            log.error("【停止job失败】job名称 :{}",jobName);
        }
    }

    /**
     * description:  获取算法任务job
     *
     * @param jobUid    jobUid
     * @return void
     * @date 2022/7/30 21:41
     */
    public V1JobList getCodeJob(String jobUid) {
        String jobName = JOB_PREFIX + jobUid;
        try {
            return listNamespacesJob(runCodeConfig.getNamespace(),jobName);
        } catch (Exception e) {
            log.error("【未查询到该job】jobName:{}",jobName);
            return null;
        }
    }

    /**
     * description: 根据namespace和label名获取pod
     *
     * @author: zhq
     * @param namespace 命名空间
     * @param label 标签 key=value的形式
     * @return io.kubernetes.client.openapi.models.V1PodList
     * @date 2022/7/13 14:40
     */
    public V1PodList listNamespacesPod(String namespace,String label) throws ApiException {
        CoreV1Api coreV1Api = getCoreApiInstance();
        return coreV1Api.listNamespacedPod(namespace, null, null, null,
                null, label, null, null, null, null);
    }



    public String getPodLogs(String namespace, String label) throws ApiException, IOException {
        V1Pod v1Pod = listNamespacesPod(namespace, label).getItems().get(0);
        PodLogs podLogs = new PodLogs();
        return Streams.asString(podLogs.streamNamespacedPodLog(v1Pod));
    }

    /**
     * description: 获取命名空间下的job
     *
     * @param namespace 命名空间
     * @param jobName job名
     * @return io.kubernetes.client.openapi.models.V1JobList
     * @date 2022/7/13 14:42
     */
    public  V1JobList listNamespacesJob(String namespace, String jobName) throws Exception {
        BatchV1Api batchV1Api = getBachV1ApiInstance();
        V1JobList v1JobList = null;
        try {
            v1JobList = batchV1Api.listNamespacedJob(namespace, "true", null, null, "metadata.name=" + jobName, null, null, null, 5000, null);
        } catch (Exception e) {
            if (e.getCause() instanceof IllegalStateException) {
                IllegalStateException ise = (IllegalStateException) e.getCause();
                if (ise.getMessage() != null && ise.getMessage().contains("Expected a string but was BEGIN_OBJECT")) {
                    log.info("Catching exception because of issue https://github.com/kubernetes/kubernetes/issues/65121");
                    return v1JobList;
                } else {
                    throw new Exception(e.toString());
                }
            } else {
                throw new Exception(e.toString());
            }
        }
        return v1JobList;
    }

//    /**
//     * description: 拷贝宿主机文件到 pod中
//     *
//     * @author: zhq
//     * @param namespace 命名空间
//     * @param podName pod 名
//     * @param sourcePath copy 源位置
//     * @param targetPath copy 目标位置
//     * @date 2022/7/14 16:05
//     */
//    public void copyFileToPod(String namespace,String podName,String sourcePath,String targetPath) {
//        Copy copy = new Copy(apiClient);
//        Path path1 = Paths.get("/nfs", "data", "javaFile");
//        Path path2 = Paths.get("/code_path");
//        try {
//            copy.copyFileToPod(namespace,podName,null, path1,path2);
//        } catch (ApiException | IOException e) {
//            throw new RuntimeException(e);
//        }
//
//    }
//    /**
//     * description: 创建命名空间
//     *
//     * @author: zhq
//     * @param namespace 命名空间名字
//     * @return io.kubernetes.client.openapi.models.V1Namespace
//     * @date 2022/7/18 9:57
//     */
//    public void createNamespace(String namespace) throws ApiException {
//        CoreV1Api coreV1Api = getCoreApiInstance();
//        V1Namespace v1Namespace = new V1NamespaceBuilder()
//                .withNewMetadata()
//                .withName(namespace)
//                .endMetadata()
//                .build();
//        V1Namespace ns = coreV1Api.createNamespace(v1Namespace, null, null, null);
//    }

}
```

# 5. 其他业务

## 1. 配置接口请求的日志打印

需求：记录每次的接口请求。

解决方式：

1. 设立拦截器，在拦截器中打印接口信息  

2. 配置过滤器，使用自定义的request替代本身的request

   1. 原因：

      打印日志时，需要获取请求体中的内容，但是在部分接口中也需要获取请求体中的内容。

      请求体中的内容是通过流进行读取的，如果在拦截器中读一次，读完此时流记录文档读取的位置是请求体的最后一个位置，在接口中再进行读取时，会出现读取不到的错误。因为流的内容只能读取一次。

   2. 解决方式：

      创建自定义的request，在过滤器中拦截request，并读取其内容到自定义的request，在自定义的request中创建body变量，保存请求体信息，从而可以在拦截器和方法中读取body。

### 过滤器配置

使用自定义request封装请求的request。

```java
@Component("myRequestFilter")
public class RequestFilter implements Filter {
    @Override
    public void doFilter(ServletRequest req, ServletResponse res, FilterChain filterChain) throws IOException, ServletException {
        HttpServletRequest request = (HttpServletRequest)req;
        HttpServletResponse response = (HttpServletResponse)res;
        RequestWrapper requestWrapper  = new RequestWrapper(request);
        if(requestWrapper == null){
            filterChain.doFilter(request,response);
        }else {
            filterChain.doFilter(requestWrapper,response);
        }
    }

    @Override
    public void destroy() {

    }
}
```

**自定义request**

```java
package com.train.common.log.apilog;

import javax.servlet.ReadListener;
import javax.servlet.ServletInputStream;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletRequestWrapper;
import java.io.*;

public class RequestWrapper extends HttpServletRequestWrapper {
    private final String body;

    /**
     * @param request
     */
    public RequestWrapper(HttpServletRequest request) throws IOException {
        super(request);
        StringBuilder sb = new StringBuilder();
        InputStream ins = request.getInputStream();
        BufferedReader isr = null;
        try {
            if (ins != null) {
                isr = new BufferedReader(new InputStreamReader(ins));
                char[] charBuffer = new char[128];
                int readCount = 0;
                while ((readCount = isr.read(charBuffer)) != -1) {
                    sb.append(charBuffer, 0, readCount);
                }
            } else {
                sb.append("");
            }
        } catch (IOException e) {
            throw e;
        } finally {
            if (isr != null) {
                isr.close();
            }
        }

        sb.toString();
        body = sb.toString();
    }

    public String getBody() {
        return this.body;
    }


    @Override
    public BufferedReader getReader() throws IOException {
        return new BufferedReader(new InputStreamReader(this.getInputStream()));
    }

    @Override
    public ServletInputStream getInputStream() throws IOException {
        final ByteArrayInputStream byteArrayIns = new ByteArrayInputStream(body.getBytes());
        ServletInputStream servletIns = new ServletInputStream() {
            @Override
            public boolean isFinished() {
                return false;
            }

            @Override
            public boolean isReady() {
                return false;
            }

            @Override
            public void setReadListener(ReadListener readListener) {

            }

            @Override
            public int read() throws IOException {
                return byteArrayIns.read();
            }
        };
        return servletIns;
    }
}

```

**设置过滤器的过滤范围**

```java
@Configuration
public class FilterConfig {
    @Autowired
    private RequestFilter requestFilter;
    /**
     * 注入crosFilter
     * @return
     */
    @Bean
    public FilterRegistrationBean requestFilter() {
        FilterRegistrationBean registration = new FilterRegistrationBean();
        registration.setFilter(requestFilter);
        registration.addUrlPatterns("/*");
        registration.setName("requestFilter");
        //设置优先级别
        registration.setOrder(1);
        return registration;
    }

}
```

### 拦截器配置

拦截信息：打印接口请求日志

```java
@Slf4j
@Component("logHandlerInterceptor")
public class LogHandlerInterceptor implements HandlerInterceptor {
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        RequestWrapper requestWrapper = new RequestWrapper(request);
        String requestURI = requestWrapper.getRequestURI();
        String reqMethod = requestWrapper.getMethod();
        String reqBody = requestWrapper.getBody();
        String reqParam = requestWrapper.getQueryString();
        log.info(StringUtils.format("【" + reqMethod + " " + requestURI + "】操作人id：{},  请求参数：{}, 请求体：{} ", SecurityUtils.getUserId(), reqParam, reqBody));
        // 返回 true 才会继续执行，返回 false 则取消当前请求
        return true;
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
//        log.info("执行完方法之后进执行(Controller方法调用之后)，但是此时还没进行视图渲染");
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
//        log.info("整个请求都处理完咯，DispatcherServlet也渲染了对应的视图咯，此时我可以做一些清理的工作了");
    }
}

```

**设置拦截器拦截地址**

```java
@Configuration
public class WebConfig implements WebMvcConfigurer {
    @Autowired
    private LogHandlerInterceptor interceptor;

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        // 添加拦截器，配置拦截地址
        registry.addInterceptor(interceptor).addPathPatterns("/**");
    }

}
```

## 2. 使用注解实现自定义接口请求日志

创建注解：

```java
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
public @interface OperatorLog {
    String operate() default "";
}
```

定义切面：

```java
@Aspect
@Component
@Slf4j
public class OperatorLogAspect {
 
    日志格式
//     log.error(StrUtil.format("【删除用户失败】角色权限不足，不能删除。操作人id：{}，预删除用户id：{}", SecurityUtils.getCurrentUserId(), id));
//     log.info(StrUtil.format("【导出岗位数据 /api/job/download】操作人id：{}，岗位查询条件 criteria：{}", SecurityUtils.getCurrentUserId(),
//    criteria));


    //定义切点
    @Pointcut("@annotation(com.train.common.log.annotation.OperatorLog)")
    public void recordPointCut() {
    }

    //环绕通知  可在方法的执行中调用
    @Around("recordPointCut()")
    public Object around(ProceedingJoinPoint joinPoint)  {
        //1.获取方法中
        MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature();
        //2.获取日志注解参数值
        OperatorLog logAnnotation = methodSignature.getMethod().getAnnotation(OperatorLog.class);
        String logMessage = logAnnotation.operate();
        //3.获取请求参数
        //获取所有参数名称
        String[] parameterNames = methodSignature.getParameterNames();
        //获取所有参数值
        Object[] args = joinPoint.getArgs();
        //4.request信息
        RequestAttributes ra = RequestContextHolder.getRequestAttributes();
        ServletRequestAttributes sra = (ServletRequestAttributes) ra;
        HttpServletRequest request = sra.getRequest();
//        StringBuffer requestURL = request.getRequestURL();
        String requestURI = request.getRequestURI();
        StringBuilder logBuilder = new StringBuilder();
        logBuilder.append("【" + logMessage + " "+ requestURI + "】操作人id:{}, 提交参数 :");
        if (parameterNames.length == 0) {
            logBuilder.append("（系统提示：该接口不需要参数）");
        } else {
            for (String paramName : parameterNames) {
                logBuilder.append(paramName + ":{},");
            }
            logBuilder.deleteCharAt(logBuilder.length() - 1);
        }
        log.info(String.format(logBuilder.toString()), SecurityUtils.getUserId(),args);
        return null;
    }


    private String getElRes(String spELString, ProceedingJoinPoint joinPoint) {
        if (spELString == "" || spELString == null) return null;
        // 通过joinPoint获取被注解方法
        MethodSignature methodSignature = (MethodSignature) joinPoint.getSignature();
        Method method = methodSignature.getMethod();

        //创建解析器
        SpelExpressionParser parser = new SpelExpressionParser();
        //获取表达式
        Expression expression = parser.parseExpression(spELString);
        //设置解析上下文(有哪些占位符，以及每种占位符的值)
        EvaluationContext context = new StandardEvaluationContext();
        //获取参数值
        Object[] args = joinPoint.getArgs();
        //获取运行时参数的名称
        DefaultParameterNameDiscoverer discoverer = new DefaultParameterNameDiscoverer();
        String[] parameterNames = discoverer.getParameterNames(method);
        for (int i = 0; i < parameterNames.length; i++) {
            context.setVariable(parameterNames[i], args[i]);
        }
        //解析,获取替换后的结果
        String result = expression.getValue(context).toString();
        return result;
    }

}
```

使用：

```java
    @OperatorLog(operate = "提交任务")
    @PostMapping("/task/code-file/submit")
    public AjaxResult<Object> submitTask(@Validated({TaskFileGroup.submit.class}) @NotNull(message = "TaskFileSaveVO不能未null") @RequestBody TaskFileSaveVO saveFile) throws IOException {
        taskFilesService.submitTask(saveFile);
        return AjaxResult.success();
    }
```

## 3. 工厂和策略模式优化代码

[(131条消息) 策略模式和工厂模式搭配使用_Hekliu的博客-CSDN博客](https://blog.csdn.net/liu59412/article/details/119531047?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-119531047-blog-109231542.pc_relevant_multi_platform_whitelistv3&spm=1001.2101.3001.4242.1&utm_relevant_index=3)

